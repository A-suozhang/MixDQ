{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the distribution of the weight and the original activation of SDXL-Turbo (the input of a certain layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Union\n",
    "import json\n",
    "from pytorch_lightning import seed_everything\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch.cuda import amp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, UNet2DModel, UNet2DConditionModel, LCMScheduler\n",
    "from sdxl_pipeline import StableDiffusionXLPipeline\n",
    "from qdiff.utils import DataSaverHook, StopForwardException\n",
    "from qdiff.models.quant_layer import QuantLayer\n",
    "from qdiff.models.quant_model import QuantModel\n",
    "from qdiff.models.quant_block import BaseQuantBlock\n",
    "\n",
    "from qdiff.models.quant_block_forward_func import convert_model_split, convert_transformer_storable, set_shortcut_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_id: str=\"Lykon/dreamshaper-7\", cache_dir: str=\"/share/public/diffusion_quant/huggingface/hub\", type: str=\"lcm_lora\"):\n",
    "    print(f\"the weight is from {model_id}\")\n",
    "    # pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\")\n",
    "    if 'xl' in type:\n",
    "        pipe = StableDiffusionXLPipeline.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "    else:\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "\n",
    "    # print(type(model))\n",
    "    if 'lcm' in type:\n",
    "        pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "    if 'lora' in type:\n",
    "        # load and fuse lcm lora\n",
    "        adapter_id = \"latent-consistency/lcm-lora-sdv1-5\"\n",
    "        pipe.load_lora_weights(adapter_id)\n",
    "        pipe.fuse_lora()\n",
    "\n",
    "    model = pipe.unet\n",
    "\n",
    "    # convert_model_split(model)\n",
    "    convert_transformer_storable(model)\n",
    "    \n",
    "    model.cuda(4)\n",
    "    model.eval()\n",
    "    return model, pipe\n",
    "\n",
    "model, pipe = get_model(model_id=\"stabilityai/sdxl-turbo\", type=\"sdxl_turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_out = torch.load(\"../error_func/sensitivity_log/unet_out_error/sensitive_layers_list_w4a32_5.pt\")\n",
    "len(sensitive_out)\n",
    "sensitive_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_weight = torch.load(\"../error_func/sensitivity_log/weight_error/sensitive_layers_w4a32_5_sqnr.pt\")\n",
    "(sensitive_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_layers = []\n",
    "for layer in sensitive_out:\n",
    "    if layer in sensitive_weight:\n",
    "        sensitive_layers.append(layer)\n",
    "\n",
    "print(len(sensitive_layers))\n",
    "sensitive_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. the distribution of the activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_acts = torch.load(\"../error_func/sensitivity_log/act_error/sensitive_layers_w8a8_5_sqnr.pt\")\n",
    "sensitive_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_coco_text_and_image(json_file):\n",
    "    info = json.load(open(json_file, 'r'))\n",
    "    annotation_list = info[\"annotations\"]\n",
    "    image_caption_dict = {}\n",
    "    for annotation_dict in annotation_list:\n",
    "        if annotation_dict[\"image_id\"] in image_caption_dict.keys():\n",
    "            image_caption_dict[annotation_dict[\"image_id\"]].append(annotation_dict[\"caption\"])\n",
    "        else:\n",
    "            image_caption_dict[annotation_dict[\"image_id\"]] = [annotation_dict[\"caption\"]]\n",
    "    captions = list(image_caption_dict.values())\n",
    "    image_ids = list(image_caption_dict.keys())\n",
    "\n",
    "    active_captions = []\n",
    "    for texts in captions:\n",
    "        active_captions.append(texts[0])\n",
    "\n",
    "    image_paths = []\n",
    "    for image_id in image_ids:\n",
    "        image_paths.append(\"/share/public/diffusion_quant/coco/coco/val2014/\"+f\"COCO_val2014_{image_id:012}.jpg\")\n",
    "    return active_captions, image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for get the input of the certain module\n",
    "def find_module_by_name(model, name):\n",
    "    for module_name, module in model.named_modules():\n",
    "        if module_name == name:\n",
    "            return module\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'conv_in'  # 'up_blocks.2.resnets.2.conv_shortcut'\n",
    "module = find_module_by_name(model, name)\n",
    "module  # display the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSaverHook:\n",
    "    \"\"\"\n",
    "    Forward hook that stores the input and output of a block\n",
    "    \"\"\"\n",
    "    def __init__(self, store_input=False, store_output=False, stop_forward=False):\n",
    "        self.store_input = store_input\n",
    "        self.store_output = store_output\n",
    "        self.stop_forward = stop_forward\n",
    "\n",
    "        self.input_store = None\n",
    "        self.output_store = None\n",
    "\n",
    "    def __call__(self, module, input_batch, output_batch):\n",
    "        if self.store_input:\n",
    "            self.input_store = input_batch \n",
    "        if self.store_output:\n",
    "            self.output_store = output_batch \n",
    "        if self.stop_forward:\n",
    "            raise StopForwardException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetLayerInpOut_SDXL:\n",
    "    def __init__(self, model: QuantModel, layer: Union[QuantLayer, BaseQuantBlock, nn.Module],\n",
    "                 device: torch.device, asym: bool = False, act_quant: bool = False):\n",
    "        self.model = model\n",
    "        self.layer = layer\n",
    "        self.asym = asym\n",
    "        # self.device = device\n",
    "        self.act_quant = act_quant\n",
    "        self.data_saver = DataSaverHook(store_input=True, store_output=True, stop_forward=False)\n",
    "\n",
    "    def __call__(self, x, timesteps, context=None, added_conds=None):\n",
    "        self.model.eval()\n",
    "        # self.model.set_quant_state(False, False)\n",
    "\n",
    "        handle = self.layer.register_forward_hook(self.data_saver)  \n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                _ = self.model(x, timesteps, context, added_cond_kwargs=added_conds)\n",
    "            except StopForwardException:\n",
    "                pass\n",
    "\n",
    "        handle.remove()\n",
    "\n",
    "        if len(self.data_saver.input_store) > 1 and len(self.data_saver.input_store) < 7 and torch.is_tensor(self.data_saver.input_store[1]):\n",
    "            return (self.data_saver.input_store[0].detach(),  \n",
    "                self.data_saver.input_store[1].detach())\n",
    "        elif len(self.data_saver.input_store) == 7:\n",
    "            # 针对QuantTransformerBlock 有7个输入（待优化）\n",
    "            input_tuple = []\n",
    "            for input in self.data_saver.input_store:\n",
    "                if input == None:\n",
    "                    input_tuple.append(input)\n",
    "                else:\n",
    "                    input_tuple.append(input.detach())\n",
    "            return tuple(input_tuple)  # difference\n",
    "        else:\n",
    "            return self.data_saver.input_store[0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_sdxl_turbo(prompt, pipe):\n",
    "    print(\"#######################################################################\")\n",
    "    # disable guidance_scale by passing 0\n",
    "    image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0)[0].images\n",
    "    return image\n",
    "\n",
    "\n",
    "def sample(prompt, unet, pipe, batch_size, quant_inference = False, is_fp16 = False):\n",
    "    torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    generator = torch.manual_seed(42)  # Seed generator to create the initial latent noise\n",
    "    total = len(prompt)\n",
    "    image_folder = './act_distribution'\n",
    "    # n = 16  # 按批量推理\n",
    "    num = total // batch_size\n",
    "    assert num==1, \"num==1 should be true\"\n",
    "    img_id = 0\n",
    "    logger.info(f\"starting from image {img_id}\")\n",
    "    # total_n_samples = max_images\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "    pipe.to(unet.device)\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(\n",
    "            range(num), desc=\"Generating activations for plotting.\"\n",
    "        ):\n",
    "            with amp.autocast(enabled=False):\n",
    "                image = inference_sdxl_turbo(prompt[batch_size*i:batch_size*(i+1)], pipe)\n",
    "\n",
    "            # for j in range(batch_size):\n",
    "            #     image[j].save(f\"/home/fangtongcheng/diffuser-dev/analysis_tools/distribution/act_distribution_img/{img_id}.png\")\n",
    "            #     img_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(model, module, pipe):\n",
    "    data_saver = DataSaverHook(store_input=True, store_output=True, stop_forward=False)\n",
    "    handle = module.register_forward_hook(data_saver) \n",
    "    \n",
    "    json_file = \"/share/public/diffusion_quant/coco/coco/annotations/captions_val2014.json\"\n",
    "    prompt_list, image_path = prepare_coco_text_and_image(json_file=json_file)\n",
    "    prompts = prompt_list[0:8]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sample(prompts, model, pipe, batch_size=8)\n",
    "    handle.remove()\n",
    "\n",
    "    if len(data_saver.input_store) > 1 and len(data_saver.input_store) < 7 and torch.is_tensor(data_saver.input_store[1]):\n",
    "        # the input of the ResnetBlock2D contains two tensors\n",
    "        return (data_saver.input_store[0].detach(), \n",
    "        data_saver.input_store[1].detach()), data_saver.output_store.detach()\n",
    "    elif len(data_saver.input_store) == 7:\n",
    "        # 针对QuantTransformerBlock 有7个输入（待优化）\n",
    "        input_tuple = []\n",
    "        for input in data_saver.input_store:\n",
    "            if input == None:\n",
    "                input_tuple.append(input)\n",
    "            else:\n",
    "                input_tuple.append(input.detach())\n",
    "        return tuple(input_tuple), data_saver.output_store.detach()\n",
    "    else:\n",
    "        return data_saver.input_store[0].detach(), data_saver.output_store.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'conv_in'  # 'up_blocks.2.resnets.2.conv_shortcut'\n",
    "module = find_module_by_name(model, name)\n",
    "module  # display the module\n",
    "\n",
    "input_data, output_data = get_data(model, module, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "def plot_activation_3d(input_data, name, color_top, type='plotly'):\n",
    "    # color_top: the value represented by the top of the color bar\n",
    "    # 将权重张量转换为numpy数组，并取绝对值\n",
    "    inputs_np = np.abs(input_data.detach().cpu().numpy())\n",
    "\n",
    "    if len(inputs_np.shape)==4:\n",
    "        # 获取输入通道和输出通道的数量\n",
    "        batch_size, in_channels = inputs_np.shape[0:2]\n",
    "        x_data = batch_size\n",
    "        y_data = in_channels\n",
    "        # 在H、W维度上取均值\n",
    "        inputs_np = inputs_np.mean(axis=(2, 3))\n",
    "        # reshape成（out_channel，in_channel）维度的张量\n",
    "        inputs_np = inputs_np.reshape(batch_size, in_channels)\n",
    "        x_label = \"Batch Size\"\n",
    "    elif len(inputs_np.shape)==3:\n",
    "        token_length = inputs_np.shape[1]\n",
    "        in_channels = inputs_np.shape[2]\n",
    "        x_data = token_length\n",
    "        y_data = in_channels\n",
    "        inputs_np = inputs_np.mean(axis=(0))  # along batch dim\n",
    "        # reshape成（out_channel，in_channel）维度的张量\n",
    "        inputs_np = inputs_np.reshape(token_length, in_channels)\n",
    "        x_label = \"Tokens\"\n",
    "    else:\n",
    "        # TODO: 处理只有两个维度的输入\n",
    "        batch_size = inputs_np.shape[0]\n",
    "        in_channels = input_data.shape[1]\n",
    "        x_data = batch_size\n",
    "        y_data = in_channels\n",
    "        inputs_np = inputs_np.reshape(batch_size, in_channels)\n",
    "        x_label = \"Batch Size\"\n",
    "        \n",
    "    # 创建X，Y\n",
    "    _x = np.arange(x_data)\n",
    "    _y = np.arange(y_data)\n",
    "    _X, _Y = np.meshgrid(_x, _y)\n",
    "\n",
    "    _X = _X.T\n",
    "    _Y = _Y.T\n",
    "\n",
    "    if type == 'matplotlib':\n",
    "        # 创建一个新的图形和3D子图\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        # ax = plt.axes(projection='3d')\n",
    "        \n",
    "        # 绘制3D表面\n",
    "        surf = ax.plot_surface(_X, _Y, inputs_np, cmap='coolwarm', vmin=np.min(inputs_np), vmax=color_top)\n",
    "    \n",
    "        # 设置轴标签\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel('Input Channels')\n",
    "        ax.set_zlabel('Absolute Activations')\n",
    "    \n",
    "        ax.set_zlim([-np.max(np.abs(inputs_np)), np.max(np.abs(inputs_np))])\n",
    "        print(np.max(np.abs(inputs_np)))\n",
    "        # 添加颜色条\n",
    "        fig.colorbar(surf)\n",
    "        # 调整视图角度\n",
    "        ax.view_init(elev=20, azim=20)\n",
    "        # 显示图形\n",
    "        plt.title('the input data of '+name)\n",
    "        # 保存图像到文件\n",
    "        plt.savefig(f'./distribution_plot/act/Transformer2d_model/3d_distribution/3d_acts_{name}.png')\n",
    "        plt.show()\n",
    "    elif type == 'plotly':\n",
    "        fig = go.Figure()\n",
    "        colormap_span = 3\n",
    "        surf = go.Surface(x=_X, y=_Y, z=inputs_np, colorscale='viridis', cmin=np.min(inputs_np), \\\n",
    "                  cmax=np.max(inputs_np),opacity=0.5)\n",
    "        fig.add_trace(surf)\n",
    "        \n",
    "        # Set z-limits\n",
    "        # fig.update_layout(scene=dict(zaxis=dict(range=[-np.max(np.abs(inputs_np)), np.max(np.abs(inputs_np))])),\n",
    "        #                   width=800, height=800,xaxis_title=x_label,yaxis_title='input channels'  # Set the figure size\n",
    "        #                  )\n",
    "        fig.update_layout(scene=dict(zaxis=dict()),\n",
    "                          width=800, height=800,xaxis_title=x_label,yaxis_title='input channels'  # Set the figure size\n",
    "                         )\n",
    "        # Add color bar\n",
    "        fig.update_layout()\n",
    "        \n",
    "        # Show the plot\n",
    "        iplot(fig)\n",
    "\n",
    "\n",
    "def plot_activation_pdf(input_data, channel_type = None, view_channel = 1, name=''):\n",
    "    '''\n",
    "    channel_type: 选择在哪一个维度去看数据分布PDF, 现阶段没用到, 直接看整个张量的数据分布\n",
    "    view_channel: 选择在某一个channel去看数据分布PDF, 现阶段没用到, 直接看整个张量的数据分布\n",
    "    '''\n",
    "    # if channel_type=='output_channel':\n",
    "    #     tensor = input_data[view_channel].reshape(-1)\n",
    "    # elif channel_type=='input_channel':\n",
    "    #     tensor = input_data[:,view_channel].reshape(-1)  # view不能处理内存不连续的张量\n",
    "    # else:\n",
    "    # 假设您的张量是 tensor\n",
    "    tensor = input_data.reshape(-1)\n",
    "\n",
    "    # 将张量转换为numpy数组\n",
    "    numpy_array = tensor.cpu().numpy()\n",
    "\n",
    "    # freq = (np.ones_like(numpy_array) / len(numpy_array))\n",
    "    # 使用matplotlib的hist函数绘制分布图\n",
    "    if  channel_type is not None:\n",
    "        label= (name+': '+channel_type+'.'+str(view_channel)) \n",
    "    else:\n",
    "        label = name\n",
    "\n",
    "    plt.hist(numpy_array, bins=3000, label=label)  \n",
    "    # 'auto'会自动选择最佳的bins数量\n",
    "\n",
    "    plt.title(f'the distribution of the input data of the {name}')\n",
    "    plt.xlabel('value')\n",
    "    plt.ylabel('freq')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(f'./distribution_plot/act/Transformer2d_model/pdf_distribution/pdf_acts_{name}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_activation_box(input_data, channel_type='input_channel', name=''):\n",
    "    # 假设您的张量是 tensor\n",
    "    tensor = input_data.cpu()  # 这是一个4阶张量，第0阶和第1阶分别代表输出通道和输入通道\n",
    "\n",
    "    if len(tensor.shape)==4:\n",
    "        if channel_type == 'input_channel':\n",
    "            channels = [tensor[:, j].numpy().flatten() for j in range(tensor.shape[1])]\n",
    "        else:\n",
    "            raise RuntimeError(\"the channel_type is not the 'input_channel'\")\n",
    "        x_label = \"channel_index\"\n",
    "    elif len(tensor.shape)==3:\n",
    "        if channel_type == 'input_channel':\n",
    "            channels = [tensor[:,:,j].numpy().flatten() for j in range(tensor.shape[2])]\n",
    "            x_label = \"channel_index\"\n",
    "        elif channel_type == 'tokens':\n",
    "            channels = [tensor[:,j].numpy().flatten() for j in range(tensor.shape[1])]\n",
    "            x_label = \"token_index\"\n",
    "        else:\n",
    "            raise RuntimeError(\"the channel_type is not the 'input_channel'\")\n",
    "        \n",
    "    else:\n",
    "        if channel_type == 'input_channel':\n",
    "            channels = [tensor[:, j].numpy().flatten() for j in range(tensor.shape[1])]\n",
    "        else:\n",
    "            raise RuntimeError(\"the channel_type is not the 'input_channel'\")\n",
    "        x_label = \"time_emb_channel_index\"\n",
    "\n",
    "    plt.figure(figsize=(22, 10))\n",
    "\n",
    "    # 使用matplotlib的boxplot函数绘制箱状图\n",
    "    bplot = plt.boxplot(channels, patch_artist=True, notch=True, vert=1)\n",
    "\n",
    "    colors = ['pink', 'lightblue', 'lightgreen']\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    # 添加图例\n",
    "    plt.legend([bplot[\"boxes\"][0]], [name+': '+channel_type], loc='upper right')\n",
    "\n",
    "    plt.title(f'box-plot of the input_data of the {name}')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('range')\n",
    "    plt.savefig(f'./distribution_plot/act/Transformer2d_model/box_distribution/box_acts_{name}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_activation_channel(input_data, channel_type, name):\n",
    "    # 假设你的四维张量是tensor\n",
    "    # tensor.shape = (batch_size, height, width, num_channels)\n",
    "\n",
    "    # 计算每个输出通道的元素均值\n",
    "    inputs_np = (input_data.detach().cpu().numpy())\n",
    "    print(input_data.shape)\n",
    "    if len(input_data.shape)==4:\n",
    "        mean_values = inputs_np.mean(axis=(0, 2, 3))\n",
    "        xs = np.arange(input_data.shape[1])\n",
    "        x_label = \"channel_index\"\n",
    "    elif len(input_data.shape)==3:\n",
    "        if channel_type == 'input_channel':\n",
    "            mean_values = inputs_np.mean(axis=(0, 1))\n",
    "            xs = np.arange(input_data.shape[2])\n",
    "            x_label = \"channel_index\"\n",
    "        elif channel_type == 'tokens':\n",
    "            mean_values = inputs_np.mean(axis=(0, 2))\n",
    "            xs = np.arange(input_data.shape[1])\n",
    "            x_label = \"token_index\"\n",
    "    elif len(input_data)==2:\n",
    "        # 创建输出通道的索引\n",
    "        mean_values = inputs_np.mean(axis=(0))\n",
    "        xs = np.arange(input_data.shape[1])\n",
    "        x_label = \"channel_index\"\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    # 绘制分布图\n",
    "    print(inputs_np.max())\n",
    "    plt.bar(xs, mean_values)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('range')\n",
    "    plt.title('the input data of'+name)\n",
    "    plt.savefig(f'./distribution_plot/act/Transformer2d_model/channel_distribution/channel_acts_{name}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k'  # 'up_blocks.2.resnets.2.conv_shortcut'\n",
    "module = find_module_by_name(model, name)\n",
    "module  # display the module\n",
    "\n",
    "input_data, output_data = get_data(model, module, pipe)\n",
    "\n",
    "input_data = input_data[:,:1,:].permute([1,0,2])\n",
    "diff = input_data - input_data[:,0,:].unsqueeze(1)\n",
    "print(diff)\n",
    "\n",
    "if type(input_data) is not tuple:\n",
    "    plot_activation_3d(input_data, name, color_top=0.9)\n",
    "elif len(input_data)==2:\n",
    "    # the input of the resnet\n",
    "    plot_activation_3d(input_data[0], name+'0', color_top=1.2)\n",
    "    plot_activation_3d(input_data[1], name+'0', color_top=1.2)  # time embedding\n",
    "else:\n",
    "    # the input of the cross attention or self attention\n",
    "    # TODO: 定位哪些attention是需要cross attention的\n",
    "    plot_activation_3d(input_data[0], name+'1', color_top=1.2)\n",
    "    # input_data[2]==None if self attention\n",
    "    plot_activation_3d(input_data[2], name+'1', color_top=1.2)  # text embdding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分布图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(input_data) is not tuple:\n",
    "    plot_activation_pdf(input_data, channel_type = None, view_channel = 1, name=name)\n",
    "elif len(input_data)==2:\n",
    "    # the input of the resnet\n",
    "    plot_activation_pdf(input_data[0], channel_type = None, view_channel = 1, name=name+'0')\n",
    "    plot_activation_pdf(input_data[1], channel_type = None, view_channel = 1, name=name+'1')\n",
    "else:\n",
    "    # the input of the cross attention or self attention\n",
    "    # TODO: 定位哪些attention是需要cross attention的\n",
    "    plot_activation_pdf(input_data[0], channel_type = None, view_channel = 1, name=name+'0')\n",
    "    # input_data[2]==None if self attention\n",
    "    plot_activation_pdf(input_data[2], channel_type = None, view_channel = 1, name=name+'1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 箱状图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(input_data) is not tuple:\n",
    "    plot_activation_box(input_data, channel_type = 'input_channel', name=name)\n",
    "elif len(input_data)==2:\n",
    "    # the input of the resnet\n",
    "    plot_activation_box(input_data[0], channel_type = 'input_channel', name=name+'0')\n",
    "    plot_activation_box(input_data[1], channel_type = 'input_channel', name=name+'1')\n",
    "else:\n",
    "    # the input of the cross attention or self attention\n",
    "    # TODO: 定位哪些attention是需要cross attention的\n",
    "    plot_activation_box(input_data[0], channel_type = 'input_channel', name=name+'0')\n",
    "    # input_data[2]==None if self attention\n",
    "    plot_activation_box(input_data[2], channel_type = 'input_channel', name=name+'1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不同通道之间的数值差异可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(input_data) is not tuple:\n",
    "    plot_activation_channel(input_data, channel_type = 'input_channel', name=name)\n",
    "elif len(input_data)==2:\n",
    "    # the input of the resnet\n",
    "    plot_activation_channel(input_data[0], channel_type = 'input_channel', name=name+'0')\n",
    "    plot_activation_channel(input_data[1], channel_type = 'input_channel', name=name+'1')\n",
    "else:\n",
    "    # the input of the cross attention or self attention\n",
    "    # TODO: 定位哪些attention是需要cross attention的\n",
    "    plot_activation_channel(input_data[0], channel_type = 'input_channel', name=name+'0')\n",
    "    # input_data[2]==None if self attention\n",
    "    plot_activation_channel(input_data[2], channel_type = 'input_channel', name=name+'1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the distribution of the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_out_attention = []\n",
    "for name in sensitive_out:\n",
    "    if 'attention' in name:\n",
    "        sensitive_out_attention.append(name)\n",
    "sensitive_out_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_id = sensitive_layers[12]+'.weight'  # 观察哪一层的权重\n",
    "# weight_id = sensitive_out_attention[16]+'.weight'\n",
    "weight_id = \"up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v\"+'.weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model, layer_name):\n",
    "    for name, module in model.named_parameters():\n",
    "        print(module.data.shape)\n",
    "        if name == layer_name:\n",
    "            return module.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_weights(model, weight_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "def plot_weight_3d(weights, weight_id, color_top):\n",
    "    # 将权重张量转换为numpy数组，并取绝对值\n",
    "    weights_np = np.abs(weights.cpu().numpy())  # !!!\n",
    "\n",
    "    # 获取输入通道和输出通道的数量\n",
    "    out_channels, in_channels = weights_np.shape[0:2]\n",
    "\n",
    "    if len(weights_np.shape)==4:\n",
    "        # if conv: 在H、W维度上取均值\n",
    "        weights_np = weights_np.mean(axis=(2, 3))\n",
    "        # reshape成（out_channel，in_channel）维度的张量\n",
    "        weights_np = weights_np.reshape(out_channels, in_channels)\n",
    "\n",
    "\n",
    "    # 创建一个新的图形和3D子图\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    # ax = plt.axes(projection='3d')\n",
    "\n",
    "    # 创建X，Y\n",
    "    _x = np.arange(out_channels)\n",
    "    _y = np.arange(in_channels)\n",
    "    _X, _Y = np.meshgrid(_x, _y)\n",
    "\n",
    "    _X = _X.T\n",
    "    _Y = _Y.T\n",
    "\n",
    "    # 绘制3D表面\n",
    "    weights_np = weights_np\n",
    "    cs = weights_np\n",
    "    surf = ax.plot_surface(_X, _Y, weights_np, cmap='coolwarm', vmin=np.min(weights_np), vmax=color_top)\n",
    "    # points = ax.scatter3D(_X, _Y, weights_np, c=cs, s=0.5, cmap='coolwarm', vmin=np.min(weights_np), vmax=np.max(weights_np))\n",
    "\n",
    "    # # 创建一个自定义的归一化对象\n",
    "    # norm = colors.Normalize(vmin=np.min(weights_np), vmax=np.max(weights_np), clip=True)\n",
    "    # # 绘制3D表面\n",
    "    # surf = ax.plot_surface(_X, _Y, weights_np, cmap='coolwarm', norm=norm)\n",
    "\n",
    "\n",
    "    # 设置轴标签\n",
    "    ax.set_xlabel('Output Channels')\n",
    "    ax.set_ylabel('Input Channels')\n",
    "    ax.set_zlabel('Absolute Weights')\n",
    "\n",
    "    # ax.set_zlim([np.min(weights_np), np.max(weights_np)])\n",
    "    ax.set_zlim([-np.max(np.abs(weights_np)), np.max(np.abs(weights_np))])\n",
    "    print(np.max(np.abs(weights_np)))\n",
    "\n",
    "    # 添加颜色条\n",
    "    # fig.colorbar(points)\n",
    "    fig.colorbar(surf)\n",
    "\n",
    "    # 保存图像到文件\n",
    "    plt.savefig(f'./distribution_plot/weight/transformer2d_model/3d/3d_weight_{weight_id}.png')\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_weight_pdf(weights, channel_type=None, view_channel = 1, weight_id=''):\n",
    "    '''\n",
    "    channel_type: 是否选择逐channel去看分布\n",
    "    view_channel: 看第几个channel\n",
    "    '''\n",
    "    weights = weights.cpu()\n",
    "    # linear or conv\n",
    "    if channel_type=='output_channel':\n",
    "        tensor = weights[view_channel].reshape(-1)\n",
    "    elif channel_type=='input_channel':\n",
    "        tensor = weights[:,view_channel].reshape(-1)  # view不能处理内存不连续的张量\n",
    "    else:\n",
    "        # 假设您的张量是 tensor\n",
    "        tensor = weights.reshape(-1)\n",
    "\n",
    "    # 将张量转换为numpy数组\n",
    "    numpy_array = tensor.numpy()\n",
    "\n",
    "    # 使用matplotlib的hist函数绘制分布图\n",
    "    plt.hist(numpy_array, bins='auto', label=weight_id+': '+channel_type+'.'+str(view_channel) if  channel_type is not None else weight_id)  \n",
    "    # 'auto'会自动选择最佳的bins数量\n",
    "\n",
    "    plt.title('distribution')\n",
    "    plt.xlabel('value')\n",
    "    plt.ylabel('freq')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.savefig(f'./distribution_plot/weight//transformer2d_model/pdf/pdf_weight_{weight_id}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_weight_box(weights, channel_type = 'output_channel', weight_id=''):\n",
    "    # 假设您的张量是 tensor\n",
    "    weights = weights.cpu()\n",
    "    tensor = weights  # 这是一个4阶张量，第0阶和第1阶分别代表输出通道和输入通道\n",
    "\n",
    "    if channel_type == 'output_channel':\n",
    "        channels = [tensor[i].numpy().flatten() for i in range(tensor.shape[0])]\n",
    "    elif channel_type == 'input_channel':\n",
    "        channels = [tensor[:, j].numpy().flatten() for j in range(tensor.shape[1])]\n",
    "\n",
    "    plt.figure(figsize=(22, 10))\n",
    "\n",
    "    # 使用matplotlib的boxplot函数绘制箱状图\n",
    "    flierprops = dict(marker='o', markersize=2)\n",
    "    bplot = plt.boxplot(channels, patch_artist=True, notch=True, vert=1, flierprops=flierprops)\n",
    "\n",
    "    colors = ['pink', 'lightblue', 'lightgreen']\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    # 添加图例\n",
    "    plt.legend([bplot[\"boxes\"][0]], [weight_id+': '+channel_type], loc='upper right')\n",
    "\n",
    "    plt.title('box-plot')\n",
    "    plt.xlabel('channel_index')\n",
    "    plt.ylabel('range')\n",
    "\n",
    "    plt.savefig(f'./distribution/distribution_plot/weight//transformer2d_model/box/box_weight_{weight_id}.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weight_3d(weights, weight_id, color_top=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分布图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weight_pdf(weights, weight_id=weight_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 箱状图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weight_box(weights, channel_type='output_channel', weight_id=weight_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the comparison between the sdxl-turbo and the original sdxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_non_turbo = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "model = get_model(model_id=model_id_non_turbo, type=\"sdxl\")\n",
    "weight_id_non_turbo = weight_id  # 观察哪一层的权重\n",
    "weights_non_turbo = get_weights(model, weight_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 是否选择逐channel去看分布\n",
    "channel_type = None\n",
    "# 看第几个channel\n",
    "view_channel = 1\n",
    "\n",
    "if channel_type=='output_channel':\n",
    "    flat_tensor1 = weights[view_channel].reshape(-1)\n",
    "    flat_tensor2 = weights_non_turbo[view_channel].reshape(-1)\n",
    "elif channel_type=='input_channel':\n",
    "    flat_tensor1 = weights[:,view_channel].reshape(-1)  # view不能处理内存不连续的张量\n",
    "    flat_tensor2 = weights_non_turbo[:,view_channel].reshape(-1)  # view不能处理内存不连续的张量\n",
    "else:\n",
    "    # 假设您的张量是 tensor\n",
    "    flat_tensor1 = weights.reshape(-1)\n",
    "    flat_tensor2 = weights_non_turbo.reshape(-1)\n",
    "\n",
    "# 将张量转换为numpy数组\n",
    "numpy_array1 = flat_tensor1.numpy()\n",
    "numpy_array2 = flat_tensor2.numpy()\n",
    "\n",
    "# 使用matplotlib的hist函数绘制分布图，设置weights参数\n",
    "plt.hist(numpy_array2, bins=3000, alpha=0.5, label='sdxl_'+weight_id_non_turbo+': '+channel_type+'.'+str(view_channel) if  channel_type is not None else 'sdxl_'+weight_id_non_turbo)\n",
    "plt.hist(numpy_array1, bins=3000, alpha=0.5, label='sdxl_turbo_'+weight_id+': '+channel_type+'.'+str(view_channel) if  channel_type is not None else 'sdxl_turbo_'+weight_id)\n",
    "\n",
    "\n",
    "# 设置y轴的刻度为对数刻度\n",
    "plt.yscale('log')\n",
    "plt.title('distribution')\n",
    "plt.xlabel('value')\n",
    "plt.ylabel('freq')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算张量各种属性：信息熵、方差、离群点占比等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_weight_info(weights):\n",
    "# 假设您的张量是 tensor\n",
    "    tensor = weights.reshape(-1)\n",
    "\n",
    "    # 将张量转换为numpy数组\n",
    "    numpy_array = tensor.numpy()\n",
    "\n",
    "    # 计算熵\n",
    "    counts, _ = np.histogram(numpy_array, bins=3000)\n",
    "    p = counts / counts.sum()\n",
    "    p = p+1e-10\n",
    "    entropy = -np.sum(p * np.log(p))\n",
    "\n",
    "    # 计算离群值的分布程度\n",
    "    # 基于四分位数范围（IQR）的离群值检测方法\n",
    "    q1, q2 = np.percentile(numpy_array, [95, 5])\n",
    "    iqr = q1 - q2\n",
    "    threshold = 1.5 * iqr\n",
    "    outliers = numpy_array[(numpy_array < (q1 - threshold)) | (numpy_array > (q2 + threshold))]\n",
    "    outlier_count = len(outliers) / len(numpy_array)\n",
    "\n",
    "    # 计算方差\n",
    "    variance = np.var(numpy_array)\n",
    "\n",
    "    print(f'entropy: {entropy}')\n",
    "    print(f'outlier_percent: {outlier_count*1e3}x1^(-3)')\n",
    "    print(f'variance: {variance*1e5}x10^(-5)')\n",
    "    return entropy, outlier_count, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_weight_info(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_info(model):\n",
    "    weight_names = []\n",
    "    entropys = []\n",
    "    variances = []\n",
    "    outlier_freqs = []\n",
    "    for name, module in model.named_parameters():\n",
    "        print(module.data.shape)\n",
    "        # print(line, type(line))\n",
    "        weight_names.append(name)\n",
    "        entropy, variance, outlier_freq = compute_weight_info(module.data)\n",
    "        entropys.append(entropy)\n",
    "        variances.append(variance)\n",
    "        outlier_freqs.append(outlier_freq)\n",
    "    return weight_names, entropys, variances, outlier_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_names, entropys, variances, outlier_freqs = get_weights_info(model)\n",
    "# 使用matplotlib来绘制折线图\n",
    "plt.figure(figsize=(80, 6))\n",
    "plt.plot(weight_names, entropys, marker='o')\n",
    "plt.xlabel('weight of layers')\n",
    "plt.ylabel('entropys')\n",
    "plt.title('entropys for weights of different layers')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=90, fontsize=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80, 8))\n",
    "plt.plot(weight_names, entropys, marker='o')\n",
    "plt.xlabel('Blocks')\n",
    "plt.ylabel('SQNR (dB)')\n",
    "plt.title('SQNR for different blocks')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=90, fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80, 8))\n",
    "plt.plot(weight_names, entropys, marker='o')\n",
    "plt.xlabel('Blocks')\n",
    "plt.ylabel('SQNR (dB)')\n",
    "plt.title('SQNR for different blocks')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=60, fontsize=6)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "894a96bdd4d71ba244c894bd3db6ec4d87f63b70aaf1f1eeda20f706b75ea482"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
