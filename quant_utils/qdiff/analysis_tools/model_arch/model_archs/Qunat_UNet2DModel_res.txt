: <class 'qdiff.quant_model.QuantModel'>
model: <class 'diffusers.models.unet_2d.UNet2DModel'>
model.conv_in: <class 'qdiff.quant_layer.QuantModule'>
model.conv_in.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.conv_in.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.conv_in.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.time_proj: <class 'diffusers.models.embeddings.Timesteps'>
model.time_embedding: <class 'diffusers.models.embeddings.TimestepEmbedding'>
model.time_embedding.linear_1: <class 'qdiff.quant_layer.QuantModule'>
model.time_embedding.linear_1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.time_embedding.linear_1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.time_embedding.linear_1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.time_embedding.act: <class 'torch.nn.modules.activation.SiLU'>
model.time_embedding.linear_2: <class 'qdiff.quant_layer.QuantModule'>
model.time_embedding.linear_2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.time_embedding.linear_2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.time_embedding.linear_2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.0: <class 'diffusers.models.unet_2d_blocks.DownBlock2D'>
model.down_blocks.0.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.0.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.down_blocks.0.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.0.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.0.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.0.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.0.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.0.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.0.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.0.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.0.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.0.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.0.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.down_blocks.0.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.0.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.0.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.0.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.0.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.0.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.0.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.0.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.0.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.0.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.0.downsamplers: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.0.downsamplers.0: <class 'diffusers.models.resnet.Downsample2D'>
model.down_blocks.0.downsamplers.0.conv: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.0.downsamplers.0.conv.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.downsamplers.0.conv.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.0.downsamplers.0.conv.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1: <class 'diffusers.models.unet_2d_blocks.AttnDownBlock2D'>
model.down_blocks.1.attentions: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.1.attentions.0: <class 'diffusers.models.attention_processor.Attention'>
model.down_blocks.1.attentions.0.group_norm: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.1.attentions.0.to_q: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.attentions.0.to_q.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.0.to_q.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.0.to_q.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.attentions.0.to_k: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.attentions.0.to_k.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.0.to_k.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.0.to_k.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.attentions.0.to_v: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.attentions.0.to_v.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.0.to_v.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.0.to_v.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.attentions.0.to_out: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.1.attentions.0.to_out.0: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.attentions.0.to_out.0.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.0.to_out.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.0.to_out.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.attentions.0.to_out.1: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.1.attentions.1: <class 'diffusers.models.attention_processor.Attention'>
model.down_blocks.1.attentions.1.group_norm: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.1.attentions.1.to_q: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.attentions.1.to_q.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.1.to_q.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.1.to_q.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.attentions.1.to_k: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.attentions.1.to_k.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.1.to_k.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.1.to_k.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.attentions.1.to_v: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.attentions.1.to_v.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.1.to_v.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.1.to_v.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.attentions.1.to_out: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.1.attentions.1.to_out.0: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.attentions.1.to_out.0.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.1.to_out.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.attentions.1.to_out.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.attentions.1.to_out.1: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.1.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.1.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.down_blocks.1.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.1.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.1.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.1.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.resnets.0.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.resnets.0.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.0.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.down_blocks.1.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.1.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.1.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.1.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.1.downsamplers: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.1.downsamplers.0: <class 'diffusers.models.resnet.Downsample2D'>
model.down_blocks.1.downsamplers.0.conv: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.1.downsamplers.0.conv.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.downsamplers.0.conv.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.1.downsamplers.0.conv.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2: <class 'diffusers.models.unet_2d_blocks.DownBlock2D'>
model.down_blocks.2.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.2.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.down_blocks.2.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.2.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.2.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.2.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.2.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.2.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.2.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.down_blocks.2.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.2.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.2.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.2.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.2.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.2.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.2.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.2.downsamplers: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.2.downsamplers.0: <class 'diffusers.models.resnet.Downsample2D'>
model.down_blocks.2.downsamplers.0.conv: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.2.downsamplers.0.conv.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.downsamplers.0.conv.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.2.downsamplers.0.conv.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.3: <class 'diffusers.models.unet_2d_blocks.DownBlock2D'>
model.down_blocks.3.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.down_blocks.3.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.down_blocks.3.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.3.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.3.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.3.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.3.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.3.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.3.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.3.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.3.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.3.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.3.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.down_blocks.3.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.3.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.3.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.3.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.3.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.3.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.down_blocks.3.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.down_blocks.3.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.down_blocks.3.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.down_blocks.3.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.down_blocks.3.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.0: <class 'diffusers.models.unet_2d_blocks.UpBlock2D'>
model.up_blocks.0.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.0.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.0.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.0.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.0.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.0.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.0.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.0.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.0.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.0.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.0.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.0.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.0.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.1.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.1.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.1.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.2: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.0.resnets.2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.2.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.0.resnets.2.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.2.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.2.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.2.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.2.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.0.resnets.2.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.0.resnets.2.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.2.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.resnets.2.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.resnets.2.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.resnets.2.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.0.upsamplers: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.0.upsamplers.0: <class 'diffusers.models.resnet.Upsample2D'>
model.up_blocks.0.upsamplers.0.conv: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.0.upsamplers.0.conv.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.upsamplers.0.conv.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.0.upsamplers.0.conv.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1: <class 'diffusers.models.unet_2d_blocks.UpBlock2D'>
model.up_blocks.1.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.1.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.1.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.1.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.1.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.1.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.0.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.0.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.0.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.1.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.1.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.1.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.1.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.1.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.1.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.1.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.2: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.1.resnets.2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.2.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.1.resnets.2.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.2.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.2.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.2.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.2.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.1.resnets.2.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.1.resnets.2.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.2.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.resnets.2.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.resnets.2.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.resnets.2.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.1.upsamplers: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.1.upsamplers.0: <class 'diffusers.models.resnet.Upsample2D'>
model.up_blocks.1.upsamplers.0.conv: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.1.upsamplers.0.conv.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.upsamplers.0.conv.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.1.upsamplers.0.conv.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2: <class 'diffusers.models.unet_2d_blocks.AttnUpBlock2D'>
model.up_blocks.2.attentions: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.2.attentions.0: <class 'diffusers.models.attention_processor.Attention'>
model.up_blocks.2.attentions.0.group_norm: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.attentions.0.to_q: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.0.to_q.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.0.to_q.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.0.to_q.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.0.to_k: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.0.to_k.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.0.to_k.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.0.to_k.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.0.to_v: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.0.to_v.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.0.to_v.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.0.to_v.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.0.to_out: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.2.attentions.0.to_out.0: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.0.to_out.0.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.0.to_out.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.0.to_out.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.0.to_out.1: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.2.attentions.1: <class 'diffusers.models.attention_processor.Attention'>
model.up_blocks.2.attentions.1.group_norm: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.attentions.1.to_q: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.1.to_q.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.1.to_q.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.1.to_q.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.1.to_k: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.1.to_k.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.1.to_k.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.1.to_k.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.1.to_v: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.1.to_v.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.1.to_v.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.1.to_v.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.1.to_out: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.2.attentions.1.to_out.0: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.1.to_out.0.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.1.to_out.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.1.to_out.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.1.to_out.1: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.2.attentions.2: <class 'diffusers.models.attention_processor.Attention'>
model.up_blocks.2.attentions.2.group_norm: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.attentions.2.to_q: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.2.to_q.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.2.to_q.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.2.to_q.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.2.to_k: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.2.to_k.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.2.to_k.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.2.to_k.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.2.to_v: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.2.to_v.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.2.to_v.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.2.to_v.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.2.to_out: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.2.attentions.2.to_out.0: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.attentions.2.to_out.0.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.2.to_out.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.attentions.2.to_out.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.attentions.2.to_out.1: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.2.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.2.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.2.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.2.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.0.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.0.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.0.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.2.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.2.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.1.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.1.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.1.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.2: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.2.resnets.2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.2.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.resnets.2.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.2.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.2.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.2.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.2.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.2.resnets.2.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.2.resnets.2.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.2.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.resnets.2.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.resnets.2.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.resnets.2.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.2.upsamplers: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.2.upsamplers.0: <class 'diffusers.models.resnet.Upsample2D'>
model.up_blocks.2.upsamplers.0.conv: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.2.upsamplers.0.conv.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.upsamplers.0.conv.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.2.upsamplers.0.conv.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3: <class 'diffusers.models.unet_2d_blocks.UpBlock2D'>
model.up_blocks.3.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.up_blocks.3.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.3.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.3.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.3.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.3.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.0.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.0.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.0.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.3.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.3.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.3.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.3.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.1.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.1.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.1.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.2: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.up_blocks.3.resnets.2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.2.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.3.resnets.2.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.2.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.2.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.2.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.2.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.up_blocks.3.resnets.2.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.up_blocks.3.resnets.2.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.2.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.up_blocks.3.resnets.2.conv_shortcut: <class 'qdiff.quant_layer.QuantModule'>
model.up_blocks.3.resnets.2.conv_shortcut.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.conv_shortcut.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.up_blocks.3.resnets.2.conv_shortcut.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block: <class 'diffusers.models.unet_2d_blocks.UNetMidBlock2D'>
model.mid_block.attentions: <class 'torch.nn.modules.container.ModuleList'>
model.mid_block.attentions.0: <class 'diffusers.models.attention_processor.Attention'>
model.mid_block.attentions.0.group_norm: <class 'torch.nn.modules.normalization.GroupNorm'>
model.mid_block.attentions.0.to_q: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.attentions.0.to_q.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.attentions.0.to_q.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.attentions.0.to_q.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.attentions.0.to_k: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.attentions.0.to_k.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.attentions.0.to_k.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.attentions.0.to_k.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.attentions.0.to_v: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.attentions.0.to_v.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.attentions.0.to_v.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.attentions.0.to_v.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.attentions.0.to_out: <class 'torch.nn.modules.container.ModuleList'>
model.mid_block.attentions.0.to_out.0: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.attentions.0.to_out.0.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.attentions.0.to_out.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.attentions.0.to_out.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.attentions.0.to_out.1: <class 'torch.nn.modules.dropout.Dropout'>
model.mid_block.resnets: <class 'torch.nn.modules.container.ModuleList'>
model.mid_block.resnets.0: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.mid_block.resnets.0.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.0.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.resnets.0.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.mid_block.resnets.0.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.resnets.0.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.0.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.0.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.resnets.0.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.resnets.0.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.0.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.0.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.resnets.0.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.mid_block.resnets.0.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.mid_block.resnets.0.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.resnets.0.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.0.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.0.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.resnets.1: <class 'qdiff.quant_block.QuantResnetBlock2D'>
model.mid_block.resnets.1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.resnets.1.norm1: <class 'torch.nn.modules.normalization.GroupNorm'>
model.mid_block.resnets.1.conv1: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.resnets.1.conv1.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.1.conv1.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.1.conv1.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.resnets.1.time_emb_proj: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.resnets.1.time_emb_proj.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.1.time_emb_proj.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.1.time_emb_proj.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.mid_block.resnets.1.norm2: <class 'torch.nn.modules.normalization.GroupNorm'>
model.mid_block.resnets.1.dropout: <class 'torch.nn.modules.dropout.Dropout'>
model.mid_block.resnets.1.conv2: <class 'qdiff.quant_layer.QuantModule'>
model.mid_block.resnets.1.conv2.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.1.conv2.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.mid_block.resnets.1.conv2.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
model.conv_norm_out: <class 'torch.nn.modules.normalization.GroupNorm'>
model.conv_act: <class 'torch.nn.modules.activation.SiLU'>
model.conv_out: <class 'qdiff.quant_layer.QuantModule'>
model.conv_out.weight_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.conv_out.act_quantizer: <class 'qdiff.quant_layer.UniformAffineQuantizer'>
model.conv_out.activation_function: <class 'qdiff.quant_layer.StraightThrough'>
