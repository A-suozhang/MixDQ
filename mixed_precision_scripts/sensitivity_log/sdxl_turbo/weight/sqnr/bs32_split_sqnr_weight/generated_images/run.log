02/28/2024 00:50:51 - INFO - qdiff.utils -   inferecne with the quantized weight
02/28/2024 00:51:07 - INFO - qdiff.models.quant_model -   
 --------------- refactoring quant layers --------------- 

02/28/2024 00:51:07 - INFO - qdiff.models.quant_model -   
 --------------- refactoring quant blocks --------------- 

02/28/2024 00:51:08 - INFO - __main__ -   QuantModel(
  (model): UNet2DConditionModel(
    (conv_in): QuantLayer(
      4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
      (activation_function): StraightThrough()
    )
    (time_proj): Timesteps()
    (time_embedding): TimestepEmbedding(
      (linear_1): QuantLayer(
        in_features=320, out_features=1280, bias=True
        (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
        (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
        (activation_function): StraightThrough()
      )
      (act): SiLU()
      (linear_2): QuantLayer(
        in_features=1280, out_features=1280, bias=True
        (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
        (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
        (activation_function): StraightThrough()
      )
    )
    (add_time_proj): Timesteps()
    (add_embedding): TimestepEmbedding(
      (linear_1): QuantLayer(
        in_features=2816, out_features=1280, bias=True
        (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
        (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
        (activation_function): StraightThrough()
      )
      (act): SiLU()
      (linear_2): QuantLayer(
        in_features=1280, out_features=1280, bias=True
        (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
        (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
        (activation_function): StraightThrough()
      )
    )
    (down_blocks): ModuleList(
      (0): DownBlock2D(
        (resnets): ModuleList(
          (0-1): 2 x QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=320, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
          )
        )
        (downsamplers): ModuleList(
          (0): Downsample2D(
            (conv): QuantLayer(
              320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
      )
      (1): CrossAttnDownBlock2D(
        (attentions): ModuleList(
          (0-1): 2 x Transformer2DModel(
            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
            (proj_in): QuantLayer(
              in_features=640, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (transformer_blocks): ModuleList(
              (0-1): 2 x QuantTransformerBlock(
                (activation_function): StraightThrough()
                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (attn1): Attention(
                  (to_q): QuantLayer(
                    in_features=640, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_k): QuantLayer(
                    in_features=640, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_v): QuantLayer(
                    in_features=640, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_out): ModuleList(
                    (0): QuantLayer(
                      in_features=640, out_features=640, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                    (1): Dropout(p=0.0, inplace=False)
                  )
                  (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                )
                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (attn2): Attention(
                  (to_q): QuantLayer(
                    in_features=640, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_k): QuantLayer(
                    in_features=2048, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_v): QuantLayer(
                    in_features=2048, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_out): ModuleList(
                    (0): QuantLayer(
                      in_features=640, out_features=640, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                    (1): Dropout(p=0.0, inplace=False)
                  )
                  (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                )
                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): QuantLayer(
                        in_features=640, out_features=5120, bias=True
                        (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                        (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                        (activation_function): StraightThrough()
                      )
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): QuantLayer(
                      in_features=2560, out_features=640, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                  )
                )
              )
            )
            (proj_out): QuantLayer(
              in_features=640, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
        (resnets): ModuleList(
          (0): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              320, 640, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
          (1): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
          )
        )
        (downsamplers): ModuleList(
          (0): Downsample2D(
            (conv): QuantLayer(
              640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
      )
      (2): CrossAttnDownBlock2D(
        (attentions): ModuleList(
          (0-1): 2 x Transformer2DModel(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): QuantLayer(
              in_features=1280, out_features=1280, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (transformer_blocks): ModuleList(
              (0-9): 10 x QuantTransformerBlock(
                (activation_function): StraightThrough()
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (attn1): Attention(
                  (to_q): QuantLayer(
                    in_features=1280, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_k): QuantLayer(
                    in_features=1280, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_v): QuantLayer(
                    in_features=1280, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_out): ModuleList(
                    (0): QuantLayer(
                      in_features=1280, out_features=1280, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                    (1): Dropout(p=0.0, inplace=False)
                  )
                  (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                )
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (attn2): Attention(
                  (to_q): QuantLayer(
                    in_features=1280, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_k): QuantLayer(
                    in_features=2048, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_v): QuantLayer(
                    in_features=2048, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_out): ModuleList(
                    (0): QuantLayer(
                      in_features=1280, out_features=1280, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                    (1): Dropout(p=0.0, inplace=False)
                  )
                  (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                )
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): QuantLayer(
                        in_features=1280, out_features=10240, bias=True
                        (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                        (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                        (activation_function): StraightThrough()
                      )
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): QuantLayer(
                      in_features=5120, out_features=1280, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                  )
                )
              )
            )
            (proj_out): QuantLayer(
              in_features=1280, out_features=1280, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
        (resnets): ModuleList(
          (0): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=1280, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              640, 1280, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
          (1): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=1280, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
          )
        )
      )
    )
    (up_blocks): ModuleList(
      (0): CrossAttnUpBlock2D(
        (attentions): ModuleList(
          (0-2): 3 x Transformer2DModel(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): QuantLayer(
              in_features=1280, out_features=1280, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (transformer_blocks): ModuleList(
              (0-9): 10 x QuantTransformerBlock(
                (activation_function): StraightThrough()
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (attn1): Attention(
                  (to_q): QuantLayer(
                    in_features=1280, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_k): QuantLayer(
                    in_features=1280, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_v): QuantLayer(
                    in_features=1280, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_out): ModuleList(
                    (0): QuantLayer(
                      in_features=1280, out_features=1280, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                    (1): Dropout(p=0.0, inplace=False)
                  )
                  (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                )
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (attn2): Attention(
                  (to_q): QuantLayer(
                    in_features=1280, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_k): QuantLayer(
                    in_features=2048, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_v): QuantLayer(
                    in_features=2048, out_features=1280, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_out): ModuleList(
                    (0): QuantLayer(
                      in_features=1280, out_features=1280, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                    (1): Dropout(p=0.0, inplace=False)
                  )
                  (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                )
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): QuantLayer(
                        in_features=1280, out_features=10240, bias=True
                        (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                        (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                        (activation_function): StraightThrough()
                      )
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): QuantLayer(
                      in_features=5120, out_features=1280, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                  )
                )
              )
            )
            (proj_out): QuantLayer(
              in_features=1280, out_features=1280, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
        (resnets): ModuleList(
          (0-1): 2 x QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=1280, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              2560, 1280, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
          (2): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=1280, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              1920, 1280, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
        (upsamplers): ModuleList(
          (0): Upsample2D(
            (conv): QuantLayer(
              1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
      )
      (1): CrossAttnUpBlock2D(
        (attentions): ModuleList(
          (0-2): 3 x Transformer2DModel(
            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
            (proj_in): QuantLayer(
              in_features=640, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (transformer_blocks): ModuleList(
              (0-1): 2 x QuantTransformerBlock(
                (activation_function): StraightThrough()
                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (attn1): Attention(
                  (to_q): QuantLayer(
                    in_features=640, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_k): QuantLayer(
                    in_features=640, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_v): QuantLayer(
                    in_features=640, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_out): ModuleList(
                    (0): QuantLayer(
                      in_features=640, out_features=640, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                    (1): Dropout(p=0.0, inplace=False)
                  )
                  (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                )
                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (attn2): Attention(
                  (to_q): QuantLayer(
                    in_features=640, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_k): QuantLayer(
                    in_features=2048, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_v): QuantLayer(
                    in_features=2048, out_features=640, bias=False
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (to_out): ModuleList(
                    (0): QuantLayer(
                      in_features=640, out_features=640, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                    (1): Dropout(p=0.0, inplace=False)
                  )
                  (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                )
                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): QuantLayer(
                        in_features=640, out_features=5120, bias=True
                        (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                        (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                        (activation_function): StraightThrough()
                      )
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): QuantLayer(
                      in_features=2560, out_features=640, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                  )
                )
              )
            )
            (proj_out): QuantLayer(
              in_features=640, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
        (resnets): ModuleList(
          (0): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              1920, 640, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
          (1): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              1280, 640, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
          (2): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=640, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              960, 640, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
        (upsamplers): ModuleList(
          (0): Upsample2D(
            (conv): QuantLayer(
              640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
      )
      (2): UpBlock2D(
        (resnets): ModuleList(
          (0): QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=320, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              960, 320, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
          (1-2): 2 x QuantResnetBlock2D(
            (activation_function): StraightThrough()
            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)
            (conv1): QuantLayer(
              640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (time_emb_proj): QuantLayer(
              in_features=1280, out_features=320, bias=True
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): QuantLayer(
              320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
            (nonlinearity): SiLU()
            (conv_shortcut): QuantLayer(
              640, 320, kernel_size=(1, 1), stride=(1, 1)
              (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
              (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              (activation_function): StraightThrough()
            )
          )
        )
      )
    )
    (mid_block): UNetMidBlock2DCrossAttn(
      (attentions): ModuleList(
        (0): Transformer2DModel(
          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
          (proj_in): QuantLayer(
            in_features=1280, out_features=1280, bias=True
            (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
            (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
            (activation_function): StraightThrough()
          )
          (transformer_blocks): ModuleList(
            (0-9): 10 x QuantTransformerBlock(
              (activation_function): StraightThrough()
              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attn1): Attention(
                (to_q): QuantLayer(
                  in_features=1280, out_features=1280, bias=False
                  (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                  (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (activation_function): StraightThrough()
                )
                (to_k): QuantLayer(
                  in_features=1280, out_features=1280, bias=False
                  (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                  (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (activation_function): StraightThrough()
                )
                (to_v): QuantLayer(
                  in_features=1280, out_features=1280, bias=False
                  (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                  (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (activation_function): StraightThrough()
                )
                (to_out): ModuleList(
                  (0): QuantLayer(
                    in_features=1280, out_features=1280, bias=True
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (1): Dropout(p=0.0, inplace=False)
                )
                (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              )
              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attn2): Attention(
                (to_q): QuantLayer(
                  in_features=1280, out_features=1280, bias=False
                  (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                  (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (activation_function): StraightThrough()
                )
                (to_k): QuantLayer(
                  in_features=2048, out_features=1280, bias=False
                  (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                  (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (activation_function): StraightThrough()
                )
                (to_v): QuantLayer(
                  in_features=2048, out_features=1280, bias=False
                  (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                  (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                  (activation_function): StraightThrough()
                )
                (to_out): ModuleList(
                  (0): QuantLayer(
                    in_features=1280, out_features=1280, bias=True
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                  (1): Dropout(p=0.0, inplace=False)
                )
                (act_quantizer_q): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                (act_quantizer_k): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                (act_quantizer_v): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
              )
              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (ff): FeedForward(
                (net): ModuleList(
                  (0): GEGLU(
                    (proj): QuantLayer(
                      in_features=1280, out_features=10240, bias=True
                      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                      (activation_function): StraightThrough()
                    )
                  )
                  (1): Dropout(p=0.0, inplace=False)
                  (2): QuantLayer(
                    in_features=5120, out_features=1280, bias=True
                    (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
                    (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
                    (activation_function): StraightThrough()
                  )
                )
              )
            )
          )
          (proj_out): QuantLayer(
            in_features=1280, out_features=1280, bias=True
            (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
            (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
            (activation_function): StraightThrough()
          )
        )
      )
      (resnets): ModuleList(
        (0-1): 2 x QuantResnetBlock2D(
          (activation_function): StraightThrough()
          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)
          (conv1): QuantLayer(
            1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
            (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
            (activation_function): StraightThrough()
          )
          (time_emb_proj): QuantLayer(
            in_features=1280, out_features=1280, bias=True
            (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
            (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
            (activation_function): StraightThrough()
          )
          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): QuantLayer(
            1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
            (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
            (activation_function): StraightThrough()
          )
          (nonlinearity): SiLU()
        )
      )
    )
    (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)
    (conv_act): SiLU()
    (conv_out): QuantLayer(
      320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
      (weight_quantizer): WeightQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=True, round_mode=nearest)
      (act_quantizer): ActQuantizer(bit=8, scale_method=min_max, symmetric=False, channel_wise=False, round_mode=nearest_ste)
      (activation_function): StraightThrough()
    )
  )
)
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 1280!
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 1280!
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 1280!
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 1280!
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 640!
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 640!
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 640!
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 320!
02/28/2024 00:51:08 - INFO - qdiff.models.quant_layer -   split at 320!
02/28/2024 00:51:09 - INFO - __main__ -   quant_error_unet_output!
02/28/2024 00:51:10 - INFO - __main__ -   Verify the correctness
02/28/2024 00:51:15 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79302dB 

02/28/2024 00:51:15 - INFO - __main__ -   
the bit width is 2!

02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.conv_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.time_embedding.linear_1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.time_embedding.linear_2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.add_embedding.linear_1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.add_embedding.linear_2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.0.downsamplers.0.conv.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.1.downsamplers.0.conv.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.0.upsamplers.0.conv.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.1.upsamplers.0.conv.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv_shortcut.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.proj_in.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.proj_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.conv1.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.time_emb_proj.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.conv2.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - qdiff.models.quant_model -   model.conv_out.weight_quantizer: weight_quant=2
02/28/2024 00:51:15 - INFO - __main__ -   ################# Start to quantize the layers one by one #################
02/28/2024 00:51:15 - INFO - __main__ -   model.conv_in: weight_quant=True, act_quant=False
02/28/2024 00:51:22 - INFO - __main__ -   MSE:581.24390x10^(-5),	SQNR:22.16029dB 

02/28/2024 00:51:22 - INFO - __main__ -   model.time_embedding.linear_1: weight_quant=True, act_quant=False
02/28/2024 00:51:28 - INFO - __main__ -   MSE:37.66663x10^(-5),	SQNR:34.28415dB 

02/28/2024 00:51:28 - INFO - __main__ -   model.time_embedding.linear_2: weight_quant=True, act_quant=False
02/28/2024 00:51:37 - INFO - __main__ -   MSE:15.16032x10^(-5),	SQNR:38.11588dB 

02/28/2024 00:51:37 - INFO - __main__ -   model.add_embedding.linear_1: weight_quant=True, act_quant=False
02/28/2024 00:51:43 - INFO - __main__ -   MSE:91.70232x10^(-5),	SQNR:30.20950dB 

02/28/2024 00:51:43 - INFO - __main__ -   model.add_embedding.linear_2: weight_quant=True, act_quant=False
02/28/2024 00:51:50 - INFO - __main__ -   MSE:25.10444x10^(-5),	SQNR:35.83687dB 

02/28/2024 00:51:50 - INFO - __main__ -   model.down_blocks.0.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 00:51:56 - INFO - __main__ -   MSE:198.16847x10^(-5),	SQNR:26.92548dB 

02/28/2024 00:51:56 - INFO - __main__ -   model.down_blocks.0.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 00:52:03 - INFO - __main__ -   MSE:102.45105x10^(-5),	SQNR:29.70731dB 

02/28/2024 00:52:03 - INFO - __main__ -   model.down_blocks.0.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 00:52:09 - INFO - __main__ -   MSE:270.40140x10^(-5),	SQNR:25.48697dB 

02/28/2024 00:52:09 - INFO - __main__ -   model.down_blocks.0.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 00:52:16 - INFO - __main__ -   MSE:31.54397x10^(-5),	SQNR:34.91075dB 

02/28/2024 00:52:16 - INFO - __main__ -   model.down_blocks.0.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 00:52:22 - INFO - __main__ -   MSE:10.93326x10^(-5),	SQNR:39.67854dB 

02/28/2024 00:52:22 - INFO - __main__ -   model.down_blocks.0.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 00:52:29 - INFO - __main__ -   MSE:98.86457x10^(-5),	SQNR:29.88834dB 

02/28/2024 00:52:29 - INFO - __main__ -   model.down_blocks.0.downsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 00:52:35 - INFO - __main__ -   MSE:50.98691x10^(-5),	SQNR:32.76027dB 

02/28/2024 00:52:35 - INFO - __main__ -   model.down_blocks.1.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 00:52:42 - INFO - __main__ -   MSE:25.21914x10^(-5),	SQNR:35.94135dB 

02/28/2024 00:52:42 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 00:52:48 - INFO - __main__ -   MSE:0.54887x10^(-5),	SQNR:52.51305dB 

02/28/2024 00:52:48 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 00:52:54 - INFO - __main__ -   MSE:0.65283x10^(-5),	SQNR:51.74783dB 

02/28/2024 00:52:54 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 00:53:00 - INFO - __main__ -   MSE:6.62611x10^(-5),	SQNR:41.61765dB 

02/28/2024 00:53:00 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:53:07 - INFO - __main__ -   MSE:5.17445x10^(-5),	SQNR:42.74865dB 

02/28/2024 00:53:07 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 00:53:12 - INFO - __main__ -   MSE:0.12801x10^(-5),	SQNR:58.89434dB 

02/28/2024 00:53:12 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 00:53:18 - INFO - __main__ -   MSE:0.72094x10^(-5),	SQNR:51.58782dB 

02/28/2024 00:53:19 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 00:53:24 - INFO - __main__ -   MSE:0.82134x10^(-5),	SQNR:51.03484dB 

02/28/2024 00:53:24 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:53:30 - INFO - __main__ -   MSE:0.52821x10^(-5),	SQNR:52.76923dB 

02/28/2024 00:53:30 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 00:53:36 - INFO - __main__ -   MSE:10.60996x10^(-5),	SQNR:39.61040dB 

02/28/2024 00:53:36 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 00:53:42 - INFO - __main__ -   MSE:5.85031x10^(-5),	SQNR:42.28162dB 

02/28/2024 00:53:42 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 00:53:49 - INFO - __main__ -   MSE:0.48365x10^(-5),	SQNR:53.48350dB 

02/28/2024 00:53:49 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 00:53:57 - INFO - __main__ -   MSE:0.84187x10^(-5),	SQNR:50.76762dB 

02/28/2024 00:53:57 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 00:54:02 - INFO - __main__ -   MSE:19.88715x10^(-5),	SQNR:36.84061dB 

02/28/2024 00:54:02 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:54:07 - INFO - __main__ -   MSE:3.40839x10^(-5),	SQNR:44.66294dB 

02/28/2024 00:54:07 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 00:54:14 - INFO - __main__ -   MSE:0.03603x10^(-5),	SQNR:64.53627dB 

02/28/2024 00:54:14 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 00:54:19 - INFO - __main__ -   MSE:0.10375x10^(-5),	SQNR:59.98341dB 

02/28/2024 00:54:19 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 00:54:26 - INFO - __main__ -   MSE:0.12909x10^(-5),	SQNR:59.21982dB 

02/28/2024 00:54:26 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:54:31 - INFO - __main__ -   MSE:0.08848x10^(-5),	SQNR:60.95114dB 

02/28/2024 00:54:31 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 00:54:38 - INFO - __main__ -   MSE:9.29649x10^(-5),	SQNR:40.17000dB 

02/28/2024 00:54:38 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 00:54:45 - INFO - __main__ -   MSE:6.57010x10^(-5),	SQNR:41.84722dB 

02/28/2024 00:54:45 - INFO - __main__ -   model.down_blocks.1.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 00:54:51 - INFO - __main__ -   MSE:11.63268x10^(-5),	SQNR:39.21331dB 

02/28/2024 00:54:51 - INFO - __main__ -   model.down_blocks.1.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 00:54:57 - INFO - __main__ -   MSE:13.23164x10^(-5),	SQNR:38.60423dB 

02/28/2024 00:54:57 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 00:55:04 - INFO - __main__ -   MSE:0.22726x10^(-5),	SQNR:56.53422dB 

02/28/2024 00:55:04 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 00:55:10 - INFO - __main__ -   MSE:0.26982x10^(-5),	SQNR:55.80721dB 

02/28/2024 00:55:10 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 00:55:15 - INFO - __main__ -   MSE:3.34148x10^(-5),	SQNR:44.76247dB 

02/28/2024 00:55:15 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:55:21 - INFO - __main__ -   MSE:2.54728x10^(-5),	SQNR:46.21124dB 

02/28/2024 00:55:21 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 00:55:28 - INFO - __main__ -   MSE:0.00537x10^(-5),	SQNR:72.72099dB 

02/28/2024 00:55:28 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 00:55:32 - INFO - __main__ -   MSE:0.03594x10^(-5),	SQNR:64.46864dB 

02/28/2024 00:55:32 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 00:55:39 - INFO - __main__ -   MSE:0.11184x10^(-5),	SQNR:59.54997dB 

02/28/2024 00:55:39 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:55:44 - INFO - __main__ -   MSE:0.04731x10^(-5),	SQNR:63.15473dB 

02/28/2024 00:55:44 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 00:55:49 - INFO - __main__ -   MSE:5.03104x10^(-5),	SQNR:43.04344dB 

02/28/2024 00:55:49 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 00:55:56 - INFO - __main__ -   MSE:1.56532x10^(-5),	SQNR:48.47466dB 

02/28/2024 00:55:56 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 00:56:02 - INFO - __main__ -   MSE:0.09773x10^(-5),	SQNR:60.02120dB 

02/28/2024 00:56:02 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 00:56:09 - INFO - __main__ -   MSE:0.13089x10^(-5),	SQNR:58.72189dB 

02/28/2024 00:56:09 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 00:56:16 - INFO - __main__ -   MSE:8.45343x10^(-5),	SQNR:40.62749dB 

02/28/2024 00:56:16 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:56:22 - INFO - __main__ -   MSE:1.39992x10^(-5),	SQNR:48.46184dB 

02/28/2024 00:56:22 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 00:56:29 - INFO - __main__ -   MSE:0.00625x10^(-5),	SQNR:72.02004dB 

02/28/2024 00:56:29 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 00:56:35 - INFO - __main__ -   MSE:0.07133x10^(-5),	SQNR:61.59836dB 

02/28/2024 00:56:35 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 00:56:40 - INFO - __main__ -   MSE:0.08613x10^(-5),	SQNR:60.55493dB 

02/28/2024 00:56:40 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:56:46 - INFO - __main__ -   MSE:0.12065x10^(-5),	SQNR:59.41262dB 

02/28/2024 00:56:46 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 00:56:52 - INFO - __main__ -   MSE:4.78228x10^(-5),	SQNR:43.22148dB 

02/28/2024 00:56:52 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 00:56:57 - INFO - __main__ -   MSE:2.83812x10^(-5),	SQNR:45.56963dB 

02/28/2024 00:56:57 - INFO - __main__ -   model.down_blocks.1.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 00:57:04 - INFO - __main__ -   MSE:33.18523x10^(-5),	SQNR:34.72412dB 

02/28/2024 00:57:04 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 00:57:11 - INFO - __main__ -   MSE:74.51112x10^(-5),	SQNR:31.32023dB 

02/28/2024 00:57:11 - INFO - __main__ -   model.down_blocks.1.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 00:57:19 - INFO - __main__ -   MSE:15.71949x10^(-5),	SQNR:37.85599dB 

02/28/2024 00:57:19 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 00:57:25 - INFO - __main__ -   MSE:52.46592x10^(-5),	SQNR:32.71278dB 

02/28/2024 00:57:25 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 00:57:30 - INFO - __main__ -   MSE:35.09050x10^(-5),	SQNR:34.38512dB 

02/28/2024 00:57:31 - INFO - __main__ -   model.down_blocks.1.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 00:57:38 - INFO - __main__ -   MSE:32.02593x10^(-5),	SQNR:34.83252dB 

02/28/2024 00:57:38 - INFO - __main__ -   model.down_blocks.1.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 00:57:43 - INFO - __main__ -   MSE:5.18952x10^(-5),	SQNR:42.84831dB 

02/28/2024 00:57:43 - INFO - __main__ -   model.down_blocks.1.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 00:57:51 - INFO - __main__ -   MSE:44.14146x10^(-5),	SQNR:33.46579dB 

02/28/2024 00:57:51 - INFO - __main__ -   model.down_blocks.1.downsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 00:57:57 - INFO - __main__ -   MSE:75.31853x10^(-5),	SQNR:31.10974dB 

02/28/2024 00:57:57 - INFO - __main__ -   model.down_blocks.2.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 00:58:04 - INFO - __main__ -   MSE:19.61985x10^(-5),	SQNR:37.01836dB 

02/28/2024 00:58:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 00:58:10 - INFO - __main__ -   MSE:1.48447x10^(-5),	SQNR:48.57641dB 

02/28/2024 00:58:10 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 00:58:17 - INFO - __main__ -   MSE:1.55525x10^(-5),	SQNR:48.08263dB 

02/28/2024 00:58:17 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 00:58:23 - INFO - __main__ -   MSE:2.32662x10^(-5),	SQNR:46.35673dB 

02/28/2024 00:58:23 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:58:28 - INFO - __main__ -   MSE:4.20809x10^(-5),	SQNR:43.61672dB 

02/28/2024 00:58:28 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 00:58:35 - INFO - __main__ -   MSE:0.18590x10^(-5),	SQNR:57.32148dB 

02/28/2024 00:58:35 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 00:58:43 - INFO - __main__ -   MSE:1.63751x10^(-5),	SQNR:48.12601dB 

02/28/2024 00:58:43 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 00:58:49 - INFO - __main__ -   MSE:1.26056x10^(-5),	SQNR:48.96823dB 

02/28/2024 00:58:49 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:58:54 - INFO - __main__ -   MSE:0.80730x10^(-5),	SQNR:51.38111dB 

02/28/2024 00:58:54 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 00:59:01 - INFO - __main__ -   MSE:2.06138x10^(-5),	SQNR:46.68464dB 

02/28/2024 00:59:01 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 00:59:06 - INFO - __main__ -   MSE:2.99956x10^(-5),	SQNR:45.21395dB 

02/28/2024 00:59:06 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 00:59:15 - INFO - __main__ -   MSE:0.07562x10^(-5),	SQNR:61.33738dB 

02/28/2024 00:59:15 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 00:59:21 - INFO - __main__ -   MSE:0.09531x10^(-5),	SQNR:60.41715dB 

02/28/2024 00:59:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 00:59:28 - INFO - __main__ -   MSE:1.04853x10^(-5),	SQNR:49.77955dB 

02/28/2024 00:59:28 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:59:35 - INFO - __main__ -   MSE:0.60337x10^(-5),	SQNR:52.35850dB 

02/28/2024 00:59:35 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 00:59:42 - INFO - __main__ -   MSE:0.46968x10^(-5),	SQNR:55.85044dB 

02/28/2024 00:59:42 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 00:59:47 - INFO - __main__ -   MSE:3.98516x10^(-5),	SQNR:43.83867dB 

02/28/2024 00:59:47 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 00:59:53 - INFO - __main__ -   MSE:1.80364x10^(-5),	SQNR:47.37782dB 

02/28/2024 00:59:53 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 00:59:58 - INFO - __main__ -   MSE:1.82064x10^(-5),	SQNR:47.30396dB 

02/28/2024 00:59:59 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:00:06 - INFO - __main__ -   MSE:1.63986x10^(-5),	SQNR:47.67726dB 

02/28/2024 01:00:06 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:00:14 - INFO - __main__ -   MSE:2.74431x10^(-5),	SQNR:45.63820dB 

02/28/2024 01:00:14 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:00:21 - INFO - __main__ -   MSE:0.34649x10^(-5),	SQNR:55.04086dB 

02/28/2024 01:00:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:00:27 - INFO - __main__ -   MSE:0.16515x10^(-5),	SQNR:57.88838dB 

02/28/2024 01:00:27 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:00:34 - INFO - __main__ -   MSE:1.72352x10^(-5),	SQNR:47.90134dB 

02/28/2024 01:00:34 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:00:40 - INFO - __main__ -   MSE:1.90602x10^(-5),	SQNR:47.58699dB 

02/28/2024 01:00:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:00:45 - INFO - __main__ -   MSE:0.04891x10^(-5),	SQNR:65.55682dB 

02/28/2024 01:00:45 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:00:50 - INFO - __main__ -   MSE:0.53332x10^(-5),	SQNR:52.56255dB 

02/28/2024 01:00:50 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:00:56 - INFO - __main__ -   MSE:0.98068x10^(-5),	SQNR:50.08525dB 

02/28/2024 01:00:56 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:01:01 - INFO - __main__ -   MSE:1.08086x10^(-5),	SQNR:50.09019dB 

02/28/2024 01:01:01 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:01:09 - INFO - __main__ -   MSE:2.49718x10^(-5),	SQNR:45.90384dB 

02/28/2024 01:01:09 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:01:15 - INFO - __main__ -   MSE:3.43464x10^(-5),	SQNR:45.49251dB 

02/28/2024 01:01:15 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:01:22 - INFO - __main__ -   MSE:0.25429x10^(-5),	SQNR:55.99316dB 

02/28/2024 01:01:22 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:01:28 - INFO - __main__ -   MSE:0.28845x10^(-5),	SQNR:55.78673dB 

02/28/2024 01:01:28 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:01:34 - INFO - __main__ -   MSE:2.22857x10^(-5),	SQNR:46.55634dB 

02/28/2024 01:01:34 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:01:40 - INFO - __main__ -   MSE:1.19703x10^(-5),	SQNR:49.24505dB 

02/28/2024 01:01:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:01:47 - INFO - __main__ -   MSE:0.04007x10^(-5),	SQNR:64.16624dB 

02/28/2024 01:01:47 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:01:52 - INFO - __main__ -   MSE:0.35110x10^(-5),	SQNR:55.00646dB 

02/28/2024 01:01:52 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:01:59 - INFO - __main__ -   MSE:0.52510x10^(-5),	SQNR:52.96218dB 

02/28/2024 01:01:59 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:02:04 - INFO - __main__ -   MSE:0.47627x10^(-5),	SQNR:53.03699dB 

02/28/2024 01:02:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:02:11 - INFO - __main__ -   MSE:3.12087x10^(-5),	SQNR:45.18418dB 

02/28/2024 01:02:11 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:02:19 - INFO - __main__ -   MSE:2.79490x10^(-5),	SQNR:45.37821dB 

02/28/2024 01:02:19 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:02:25 - INFO - __main__ -   MSE:0.10011x10^(-5),	SQNR:60.03097dB 

02/28/2024 01:02:25 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:02:32 - INFO - __main__ -   MSE:0.08137x10^(-5),	SQNR:61.17260dB 

02/28/2024 01:02:32 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:02:38 - INFO - __main__ -   MSE:1.59689x10^(-5),	SQNR:48.11942dB 

02/28/2024 01:02:38 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:02:43 - INFO - __main__ -   MSE:0.93638x10^(-5),	SQNR:50.19912dB 

02/28/2024 01:02:43 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:02:50 - INFO - __main__ -   MSE:0.03465x10^(-5),	SQNR:65.86325dB 

02/28/2024 01:02:50 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:02:57 - INFO - __main__ -   MSE:0.10592x10^(-5),	SQNR:60.38177dB 

02/28/2024 01:02:57 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:03:04 - INFO - __main__ -   MSE:0.29087x10^(-5),	SQNR:55.57376dB 

02/28/2024 01:03:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:03:11 - INFO - __main__ -   MSE:0.22774x10^(-5),	SQNR:56.87289dB 

02/28/2024 01:03:11 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:03:16 - INFO - __main__ -   MSE:2.47865x10^(-5),	SQNR:45.98376dB 

02/28/2024 01:03:16 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:03:24 - INFO - __main__ -   MSE:1.81344x10^(-5),	SQNR:47.42479dB 

02/28/2024 01:03:24 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:03:30 - INFO - __main__ -   MSE:0.12026x10^(-5),	SQNR:59.08283dB 

02/28/2024 01:03:30 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:03:38 - INFO - __main__ -   MSE:0.12847x10^(-5),	SQNR:59.50695dB 

02/28/2024 01:03:38 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:03:44 - INFO - __main__ -   MSE:1.46305x10^(-5),	SQNR:48.24008dB 

02/28/2024 01:03:44 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:03:51 - INFO - __main__ -   MSE:0.67848x10^(-5),	SQNR:51.74443dB 

02/28/2024 01:03:51 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:03:59 - INFO - __main__ -   MSE:0.00132x10^(-5),	SQNR:78.62080dB 

02/28/2024 01:03:59 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:04:05 - INFO - __main__ -   MSE:0.01686x10^(-5),	SQNR:67.81304dB 

02/28/2024 01:04:05 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:04:11 - INFO - __main__ -   MSE:0.06725x10^(-5),	SQNR:61.80293dB 

02/28/2024 01:04:11 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:04:18 - INFO - __main__ -   MSE:0.04700x10^(-5),	SQNR:63.34955dB 

02/28/2024 01:04:18 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:04:23 - INFO - __main__ -   MSE:2.53688x10^(-5),	SQNR:45.81298dB 

02/28/2024 01:04:23 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:04:30 - INFO - __main__ -   MSE:1.73873x10^(-5),	SQNR:47.68158dB 

02/28/2024 01:04:30 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:04:36 - INFO - __main__ -   MSE:0.12657x10^(-5),	SQNR:59.84218dB 

02/28/2024 01:04:37 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:04:43 - INFO - __main__ -   MSE:0.09616x10^(-5),	SQNR:60.59293dB 

02/28/2024 01:04:43 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:04:50 - INFO - __main__ -   MSE:1.09350x10^(-5),	SQNR:49.61109dB 

02/28/2024 01:04:50 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:04:56 - INFO - __main__ -   MSE:0.36941x10^(-5),	SQNR:54.48166dB 

02/28/2024 01:04:56 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:05:02 - INFO - __main__ -   MSE:0.00062x10^(-5),	SQNR:81.90414dB 

02/28/2024 01:05:02 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:05:09 - INFO - __main__ -   MSE:0.00136x10^(-5),	SQNR:78.50179dB 

02/28/2024 01:05:09 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:05:14 - INFO - __main__ -   MSE:0.03606x10^(-5),	SQNR:64.48647dB 

02/28/2024 01:05:14 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:05:21 - INFO - __main__ -   MSE:0.01353x10^(-5),	SQNR:68.83128dB 

02/28/2024 01:05:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:05:27 - INFO - __main__ -   MSE:2.81450x10^(-5),	SQNR:45.72606dB 

02/28/2024 01:05:28 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:05:33 - INFO - __main__ -   MSE:1.46451x10^(-5),	SQNR:48.23649dB 

02/28/2024 01:05:34 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:05:41 - INFO - __main__ -   MSE:0.14147x10^(-5),	SQNR:58.94846dB 

02/28/2024 01:05:41 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:05:48 - INFO - __main__ -   MSE:0.08336x10^(-5),	SQNR:61.29452dB 

02/28/2024 01:05:48 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:05:53 - INFO - __main__ -   MSE:1.08725x10^(-5),	SQNR:49.62834dB 

02/28/2024 01:05:53 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:06:00 - INFO - __main__ -   MSE:0.47135x10^(-5),	SQNR:53.08699dB 

02/28/2024 01:06:00 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:06:06 - INFO - __main__ -   MSE:0.00086x10^(-5),	SQNR:80.51321dB 

02/28/2024 01:06:06 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:06:14 - INFO - __main__ -   MSE:0.00390x10^(-5),	SQNR:74.70389dB 

02/28/2024 01:06:14 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:06:21 - INFO - __main__ -   MSE:0.02252x10^(-5),	SQNR:66.73523dB 

02/28/2024 01:06:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:06:27 - INFO - __main__ -   MSE:0.02032x10^(-5),	SQNR:66.77941dB 

02/28/2024 01:06:27 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:06:36 - INFO - __main__ -   MSE:2.18425x10^(-5),	SQNR:46.44566dB 

02/28/2024 01:06:36 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:06:42 - INFO - __main__ -   MSE:1.55562x10^(-5),	SQNR:47.97934dB 

02/28/2024 01:06:42 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:06:49 - INFO - __main__ -   MSE:0.06956x10^(-5),	SQNR:61.94276dB 

02/28/2024 01:06:49 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:06:56 - INFO - __main__ -   MSE:0.05332x10^(-5),	SQNR:63.37389dB 

02/28/2024 01:06:56 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:07:02 - INFO - __main__ -   MSE:1.00575x10^(-5),	SQNR:50.03855dB 

02/28/2024 01:07:02 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:07:08 - INFO - __main__ -   MSE:0.34551x10^(-5),	SQNR:54.48145dB 

02/28/2024 01:07:08 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:07:14 - INFO - __main__ -   MSE:0.00079x10^(-5),	SQNR:81.07111dB 

02/28/2024 01:07:14 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:07:22 - INFO - __main__ -   MSE:0.00357x10^(-5),	SQNR:74.62007dB 

02/28/2024 01:07:22 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:07:28 - INFO - __main__ -   MSE:0.03495x10^(-5),	SQNR:65.28819dB 

02/28/2024 01:07:29 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:07:35 - INFO - __main__ -   MSE:0.01490x10^(-5),	SQNR:68.15691dB 

02/28/2024 01:07:35 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:07:43 - INFO - __main__ -   MSE:3.49888x10^(-5),	SQNR:44.43603dB 

02/28/2024 01:07:43 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:07:49 - INFO - __main__ -   MSE:2.06719x10^(-5),	SQNR:46.72866dB 

02/28/2024 01:07:49 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:07:57 - INFO - __main__ -   MSE:0.11250x10^(-5),	SQNR:59.36054dB 

02/28/2024 01:07:57 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:08:02 - INFO - __main__ -   MSE:0.07368x10^(-5),	SQNR:61.32837dB 

02/28/2024 01:08:02 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:08:07 - INFO - __main__ -   MSE:1.15333x10^(-5),	SQNR:49.53980dB 

02/28/2024 01:08:07 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:08:13 - INFO - __main__ -   MSE:0.52522x10^(-5),	SQNR:52.91832dB 

02/28/2024 01:08:13 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:08:20 - INFO - __main__ -   MSE:0.00344x10^(-5),	SQNR:74.89298dB 

02/28/2024 01:08:20 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:08:26 - INFO - __main__ -   MSE:0.01422x10^(-5),	SQNR:68.62872dB 

02/28/2024 01:08:26 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:08:33 - INFO - __main__ -   MSE:0.05367x10^(-5),	SQNR:62.75590dB 

02/28/2024 01:08:33 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:08:38 - INFO - __main__ -   MSE:0.05423x10^(-5),	SQNR:62.68053dB 

02/28/2024 01:08:38 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:08:44 - INFO - __main__ -   MSE:4.89420x10^(-5),	SQNR:43.06585dB 

02/28/2024 01:08:44 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:08:50 - INFO - __main__ -   MSE:3.11633x10^(-5),	SQNR:44.91991dB 

02/28/2024 01:08:50 - INFO - __main__ -   model.down_blocks.2.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 01:08:57 - INFO - __main__ -   MSE:26.59946x10^(-5),	SQNR:35.58888dB 

02/28/2024 01:08:57 - INFO - __main__ -   model.down_blocks.2.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 01:09:03 - INFO - __main__ -   MSE:35.40164x10^(-5),	SQNR:34.53639dB 

02/28/2024 01:09:03 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:09:10 - INFO - __main__ -   MSE:0.57857x10^(-5),	SQNR:52.27439dB 

02/28/2024 01:09:10 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:09:16 - INFO - __main__ -   MSE:0.77853x10^(-5),	SQNR:51.09207dB 

02/28/2024 01:09:16 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:09:22 - INFO - __main__ -   MSE:6.87127x10^(-5),	SQNR:41.60945dB 

02/28/2024 01:09:22 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:09:30 - INFO - __main__ -   MSE:7.84746x10^(-5),	SQNR:41.29434dB 

02/28/2024 01:09:30 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:09:38 - INFO - __main__ -   MSE:1.33409x10^(-5),	SQNR:49.40256dB 

02/28/2024 01:09:38 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:09:45 - INFO - __main__ -   MSE:18.22181x10^(-5),	SQNR:37.21751dB 

02/28/2024 01:09:45 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:09:51 - INFO - __main__ -   MSE:21.71312x10^(-5),	SQNR:36.71329dB 

02/28/2024 01:09:51 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:09:57 - INFO - __main__ -   MSE:13.16192x10^(-5),	SQNR:38.92390dB 

02/28/2024 01:09:57 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:10:04 - INFO - __main__ -   MSE:14.03689x10^(-5),	SQNR:38.45218dB 

02/28/2024 01:10:04 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:10:11 - INFO - __main__ -   MSE:10.63726x10^(-5),	SQNR:39.63028dB 

02/28/2024 01:10:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:10:18 - INFO - __main__ -   MSE:1.20122x10^(-5),	SQNR:49.91580dB 

02/28/2024 01:10:18 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:10:25 - INFO - __main__ -   MSE:0.91773x10^(-5),	SQNR:50.45085dB 

02/28/2024 01:10:25 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:10:31 - INFO - __main__ -   MSE:10.84213x10^(-5),	SQNR:39.55530dB 

02/28/2024 01:10:31 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:10:38 - INFO - __main__ -   MSE:11.84832x10^(-5),	SQNR:39.21211dB 

02/28/2024 01:10:38 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:10:45 - INFO - __main__ -   MSE:4.76616x10^(-5),	SQNR:43.88576dB 

02/28/2024 01:10:45 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:10:51 - INFO - __main__ -   MSE:34.58030x10^(-5),	SQNR:34.45564dB 

02/28/2024 01:10:51 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:10:58 - INFO - __main__ -   MSE:31.88727x10^(-5),	SQNR:34.90883dB 

02/28/2024 01:10:58 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:11:04 - INFO - __main__ -   MSE:19.75089x10^(-5),	SQNR:36.96874dB 

02/28/2024 01:11:04 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:11:10 - INFO - __main__ -   MSE:20.82829x10^(-5),	SQNR:36.63266dB 

02/28/2024 01:11:10 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:11:17 - INFO - __main__ -   MSE:18.38797x10^(-5),	SQNR:37.31137dB 

02/28/2024 01:11:18 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:11:24 - INFO - __main__ -   MSE:1.16543x10^(-5),	SQNR:49.43612dB 

02/28/2024 01:11:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:11:30 - INFO - __main__ -   MSE:0.93317x10^(-5),	SQNR:50.41012dB 

02/28/2024 01:11:30 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:11:37 - INFO - __main__ -   MSE:13.39726x10^(-5),	SQNR:38.54043dB 

02/28/2024 01:11:37 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:11:42 - INFO - __main__ -   MSE:10.54574x10^(-5),	SQNR:39.87245dB 

02/28/2024 01:11:42 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:11:49 - INFO - __main__ -   MSE:6.47077x10^(-5),	SQNR:42.45155dB 

02/28/2024 01:11:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:11:55 - INFO - __main__ -   MSE:10.69234x10^(-5),	SQNR:39.73771dB 

02/28/2024 01:11:55 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:12:01 - INFO - __main__ -   MSE:16.45429x10^(-5),	SQNR:37.91655dB 

02/28/2024 01:12:01 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:12:07 - INFO - __main__ -   MSE:13.67059x10^(-5),	SQNR:38.52156dB 

02/28/2024 01:12:07 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:12:12 - INFO - __main__ -   MSE:27.80893x10^(-5),	SQNR:35.48845dB 

02/28/2024 01:12:12 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:12:19 - INFO - __main__ -   MSE:25.37630x10^(-5),	SQNR:35.81993dB 

02/28/2024 01:12:19 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:12:25 - INFO - __main__ -   MSE:1.36500x10^(-5),	SQNR:48.57708dB 

02/28/2024 01:12:25 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:12:31 - INFO - __main__ -   MSE:0.81255x10^(-5),	SQNR:51.01136dB 

02/28/2024 01:12:31 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:12:39 - INFO - __main__ -   MSE:13.02892x10^(-5),	SQNR:38.78210dB 

02/28/2024 01:12:39 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:12:45 - INFO - __main__ -   MSE:7.01198x10^(-5),	SQNR:41.36399dB 

02/28/2024 01:12:45 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:12:52 - INFO - __main__ -   MSE:3.17672x10^(-5),	SQNR:45.76632dB 

02/28/2024 01:12:52 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:12:58 - INFO - __main__ -   MSE:7.53131x10^(-5),	SQNR:41.33801dB 

02/28/2024 01:12:58 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:13:05 - INFO - __main__ -   MSE:11.66044x10^(-5),	SQNR:39.35053dB 

02/28/2024 01:13:05 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:13:11 - INFO - __main__ -   MSE:13.55065x10^(-5),	SQNR:38.66507dB 

02/28/2024 01:13:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:13:17 - INFO - __main__ -   MSE:32.29809x10^(-5),	SQNR:34.72241dB 

02/28/2024 01:13:18 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:13:24 - INFO - __main__ -   MSE:27.95197x10^(-5),	SQNR:35.40031dB 

02/28/2024 01:13:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:13:30 - INFO - __main__ -   MSE:0.69436x10^(-5),	SQNR:51.43751dB 

02/28/2024 01:13:30 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:13:38 - INFO - __main__ -   MSE:0.80253x10^(-5),	SQNR:51.01981dB 

02/28/2024 01:13:38 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:13:46 - INFO - __main__ -   MSE:9.85657x10^(-5),	SQNR:40.14084dB 

02/28/2024 01:13:46 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:13:50 - INFO - __main__ -   MSE:5.65067x10^(-5),	SQNR:42.36980dB 

02/28/2024 01:13:50 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:13:57 - INFO - __main__ -   MSE:1.68529x10^(-5),	SQNR:48.66532dB 

02/28/2024 01:13:57 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:14:04 - INFO - __main__ -   MSE:2.08219x10^(-5),	SQNR:47.22007dB 

02/28/2024 01:14:04 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:14:09 - INFO - __main__ -   MSE:8.32573x10^(-5),	SQNR:40.91856dB 

02/28/2024 01:14:10 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:14:16 - INFO - __main__ -   MSE:7.80211x10^(-5),	SQNR:41.17184dB 

02/28/2024 01:14:16 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:14:22 - INFO - __main__ -   MSE:36.92570x10^(-5),	SQNR:34.30454dB 

02/28/2024 01:14:22 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:14:29 - INFO - __main__ -   MSE:23.57568x10^(-5),	SQNR:36.12370dB 

02/28/2024 01:14:29 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:14:36 - INFO - __main__ -   MSE:1.36746x10^(-5),	SQNR:48.63393dB 

02/28/2024 01:14:36 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:14:45 - INFO - __main__ -   MSE:1.57156x10^(-5),	SQNR:48.65175dB 

02/28/2024 01:14:45 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:14:51 - INFO - __main__ -   MSE:9.77125x10^(-5),	SQNR:40.01740dB 

02/28/2024 01:14:51 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:14:57 - INFO - __main__ -   MSE:5.23618x10^(-5),	SQNR:43.01177dB 

02/28/2024 01:14:57 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:15:05 - INFO - __main__ -   MSE:1.46172x10^(-5),	SQNR:49.01385dB 

02/28/2024 01:15:05 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:15:11 - INFO - __main__ -   MSE:4.35452x10^(-5),	SQNR:43.76529dB 

02/28/2024 01:15:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:15:17 - INFO - __main__ -   MSE:11.12516x10^(-5),	SQNR:39.87050dB 

02/28/2024 01:15:17 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:15:26 - INFO - __main__ -   MSE:8.04248x10^(-5),	SQNR:41.05119dB 

02/28/2024 01:15:26 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:15:32 - INFO - __main__ -   MSE:44.93084x10^(-5),	SQNR:33.32890dB 

02/28/2024 01:15:32 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:15:41 - INFO - __main__ -   MSE:29.78038x10^(-5),	SQNR:35.30342dB 

02/28/2024 01:15:41 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:15:47 - INFO - __main__ -   MSE:0.68850x10^(-5),	SQNR:51.61083dB 

02/28/2024 01:15:47 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:15:52 - INFO - __main__ -   MSE:1.18929x10^(-5),	SQNR:50.15331dB 

02/28/2024 01:15:52 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:15:59 - INFO - __main__ -   MSE:8.58272x10^(-5),	SQNR:40.57096dB 

02/28/2024 01:15:59 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:16:05 - INFO - __main__ -   MSE:5.14154x10^(-5),	SQNR:42.88310dB 

02/28/2024 01:16:05 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:16:10 - INFO - __main__ -   MSE:0.07961x10^(-5),	SQNR:60.82302dB 

02/28/2024 01:16:10 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:16:17 - INFO - __main__ -   MSE:0.53281x10^(-5),	SQNR:52.96408dB 

02/28/2024 01:16:17 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:16:24 - INFO - __main__ -   MSE:2.57964x10^(-5),	SQNR:45.96076dB 

02/28/2024 01:16:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:16:29 - INFO - __main__ -   MSE:3.17143x10^(-5),	SQNR:45.53416dB 

02/28/2024 01:16:29 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:16:36 - INFO - __main__ -   MSE:49.17898x10^(-5),	SQNR:32.95765dB 

02/28/2024 01:16:36 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:16:43 - INFO - __main__ -   MSE:27.26579x10^(-5),	SQNR:35.54822dB 

02/28/2024 01:16:43 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:16:49 - INFO - __main__ -   MSE:1.68643x10^(-5),	SQNR:47.64929dB 

02/28/2024 01:16:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:16:56 - INFO - __main__ -   MSE:1.44779x10^(-5),	SQNR:48.59110dB 

02/28/2024 01:16:56 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:17:01 - INFO - __main__ -   MSE:7.24573x10^(-5),	SQNR:41.32151dB 

02/28/2024 01:17:01 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:17:08 - INFO - __main__ -   MSE:4.65052x10^(-5),	SQNR:43.32420dB 

02/28/2024 01:17:08 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:17:14 - INFO - __main__ -   MSE:0.25180x10^(-5),	SQNR:57.57389dB 

02/28/2024 01:17:14 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:17:22 - INFO - __main__ -   MSE:0.40640x10^(-5),	SQNR:53.83113dB 

02/28/2024 01:17:22 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:17:28 - INFO - __main__ -   MSE:2.18735x10^(-5),	SQNR:46.64615dB 

02/28/2024 01:17:28 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:17:34 - INFO - __main__ -   MSE:2.51488x10^(-5),	SQNR:46.24490dB 

02/28/2024 01:17:34 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:17:42 - INFO - __main__ -   MSE:44.98341x10^(-5),	SQNR:33.28703dB 

02/28/2024 01:17:42 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:17:48 - INFO - __main__ -   MSE:22.08741x10^(-5),	SQNR:36.42188dB 

02/28/2024 01:17:48 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:17:53 - INFO - __main__ -   MSE:1.33385x10^(-5),	SQNR:48.76086dB 

02/28/2024 01:17:53 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:18:00 - INFO - __main__ -   MSE:1.91713x10^(-5),	SQNR:47.26909dB 

02/28/2024 01:18:00 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:18:06 - INFO - __main__ -   MSE:7.73883x10^(-5),	SQNR:41.04621dB 

02/28/2024 01:18:06 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:18:12 - INFO - __main__ -   MSE:5.37849x10^(-5),	SQNR:42.71876dB 

02/28/2024 01:18:12 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:18:20 - INFO - __main__ -   MSE:0.26438x10^(-5),	SQNR:59.55188dB 

02/28/2024 01:18:20 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:18:25 - INFO - __main__ -   MSE:0.48240x10^(-5),	SQNR:53.40849dB 

02/28/2024 01:18:25 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:18:31 - INFO - __main__ -   MSE:2.18737x10^(-5),	SQNR:46.53974dB 

02/28/2024 01:18:31 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:18:37 - INFO - __main__ -   MSE:1.31344x10^(-5),	SQNR:49.30155dB 

02/28/2024 01:18:37 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:18:44 - INFO - __main__ -   MSE:36.91409x10^(-5),	SQNR:34.22913dB 

02/28/2024 01:18:44 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:18:49 - INFO - __main__ -   MSE:16.68497x10^(-5),	SQNR:37.63482dB 

02/28/2024 01:18:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:18:57 - INFO - __main__ -   MSE:2.22288x10^(-5),	SQNR:46.46855dB 

02/28/2024 01:18:57 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:19:05 - INFO - __main__ -   MSE:2.21644x10^(-5),	SQNR:46.81304dB 

02/28/2024 01:19:05 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:19:11 - INFO - __main__ -   MSE:6.60370x10^(-5),	SQNR:41.87053dB 

02/28/2024 01:19:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:19:16 - INFO - __main__ -   MSE:3.17468x10^(-5),	SQNR:44.89987dB 

02/28/2024 01:19:16 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:19:23 - INFO - __main__ -   MSE:0.01312x10^(-5),	SQNR:69.84097dB 

02/28/2024 01:19:23 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:19:28 - INFO - __main__ -   MSE:0.04854x10^(-5),	SQNR:63.07971dB 

02/28/2024 01:19:28 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:19:34 - INFO - __main__ -   MSE:0.22862x10^(-5),	SQNR:56.33060dB 

02/28/2024 01:19:34 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:19:39 - INFO - __main__ -   MSE:0.19178x10^(-5),	SQNR:57.03957dB 

02/28/2024 01:19:39 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:19:47 - INFO - __main__ -   MSE:38.61615x10^(-5),	SQNR:34.04932dB 

02/28/2024 01:19:47 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:19:53 - INFO - __main__ -   MSE:14.67022x10^(-5),	SQNR:38.23420dB 

02/28/2024 01:19:53 - INFO - __main__ -   model.down_blocks.2.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 01:20:00 - INFO - __main__ -   MSE:35.80565x10^(-5),	SQNR:34.37781dB 

02/28/2024 01:20:00 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 01:20:06 - INFO - __main__ -   MSE:73.21149x10^(-5),	SQNR:31.20766dB 

02/28/2024 01:20:06 - INFO - __main__ -   model.down_blocks.2.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 01:20:12 - INFO - __main__ -   MSE:62.11810x10^(-5),	SQNR:31.89437dB 

02/28/2024 01:20:13 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 01:20:20 - INFO - __main__ -   MSE:95.91209x10^(-5),	SQNR:30.07802dB 

02/28/2024 01:20:20 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 01:20:26 - INFO - __main__ -   MSE:26.19008x10^(-5),	SQNR:35.78826dB 

02/28/2024 01:20:26 - INFO - __main__ -   model.down_blocks.2.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 01:20:34 - INFO - __main__ -   MSE:62.23377x10^(-5),	SQNR:31.98375dB 

02/28/2024 01:20:34 - INFO - __main__ -   model.down_blocks.2.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 01:20:41 - INFO - __main__ -   MSE:81.02921x10^(-5),	SQNR:30.80905dB 

02/28/2024 01:20:41 - INFO - __main__ -   model.down_blocks.2.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 01:20:50 - INFO - __main__ -   MSE:50.69130x10^(-5),	SQNR:32.88633dB 

02/28/2024 01:20:50 - INFO - __main__ -   model.up_blocks.0.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 01:20:56 - INFO - __main__ -   MSE:25.16358x10^(-5),	SQNR:35.87678dB 

02/28/2024 01:20:56 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:21:04 - INFO - __main__ -   MSE:1.81187x10^(-5),	SQNR:47.34097dB 

02/28/2024 01:21:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:21:11 - INFO - __main__ -   MSE:1.76748x10^(-5),	SQNR:47.44382dB 

02/28/2024 01:21:11 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:21:16 - INFO - __main__ -   MSE:7.79096x10^(-5),	SQNR:40.97245dB 

02/28/2024 01:21:16 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:21:22 - INFO - __main__ -   MSE:14.50320x10^(-5),	SQNR:38.32269dB 

02/28/2024 01:21:22 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:21:30 - INFO - __main__ -   MSE:0.05021x10^(-5),	SQNR:63.04280dB 

02/28/2024 01:21:30 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:21:36 - INFO - __main__ -   MSE:0.23320x10^(-5),	SQNR:56.24462dB 

02/28/2024 01:21:36 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:21:43 - INFO - __main__ -   MSE:1.24275x10^(-5),	SQNR:48.86406dB 

02/28/2024 01:21:43 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:21:50 - INFO - __main__ -   MSE:1.46885x10^(-5),	SQNR:48.28646dB 

02/28/2024 01:21:50 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:21:56 - INFO - __main__ -   MSE:9.89447x10^(-5),	SQNR:40.05874dB 

02/28/2024 01:21:56 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:22:02 - INFO - __main__ -   MSE:12.09684x10^(-5),	SQNR:38.99966dB 

02/28/2024 01:22:02 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:22:09 - INFO - __main__ -   MSE:1.82725x10^(-5),	SQNR:47.22932dB 

02/28/2024 01:22:09 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:22:15 - INFO - __main__ -   MSE:1.56418x10^(-5),	SQNR:48.01166dB 

02/28/2024 01:22:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:22:22 - INFO - __main__ -   MSE:8.67572x10^(-5),	SQNR:40.49313dB 

02/28/2024 01:22:22 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:22:27 - INFO - __main__ -   MSE:9.61293x10^(-5),	SQNR:40.07766dB 

02/28/2024 01:22:27 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:22:35 - INFO - __main__ -   MSE:0.19511x10^(-5),	SQNR:56.92907dB 

02/28/2024 01:22:35 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:22:40 - INFO - __main__ -   MSE:0.71927x10^(-5),	SQNR:51.69952dB 

02/28/2024 01:22:40 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:22:47 - INFO - __main__ -   MSE:2.62283x10^(-5),	SQNR:45.67278dB 

02/28/2024 01:22:47 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:22:52 - INFO - __main__ -   MSE:2.44679x10^(-5),	SQNR:45.93492dB 

02/28/2024 01:22:52 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:22:59 - INFO - __main__ -   MSE:13.29276x10^(-5),	SQNR:38.64881dB 

02/28/2024 01:22:59 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:23:06 - INFO - __main__ -   MSE:12.81865x10^(-5),	SQNR:38.82696dB 

02/28/2024 01:23:06 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:23:12 - INFO - __main__ -   MSE:1.44807x10^(-5),	SQNR:48.32819dB 

02/28/2024 01:23:12 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:23:20 - INFO - __main__ -   MSE:1.47614x10^(-5),	SQNR:48.16109dB 

02/28/2024 01:23:20 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:23:26 - INFO - __main__ -   MSE:8.06674x10^(-5),	SQNR:40.74398dB 

02/28/2024 01:23:26 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:23:32 - INFO - __main__ -   MSE:6.75130x10^(-5),	SQNR:41.59566dB 

02/28/2024 01:23:32 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:23:38 - INFO - __main__ -   MSE:0.48904x10^(-5),	SQNR:52.94863dB 

02/28/2024 01:23:38 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:23:45 - INFO - __main__ -   MSE:0.81109x10^(-5),	SQNR:51.14677dB 

02/28/2024 01:23:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:23:50 - INFO - __main__ -   MSE:2.80848x10^(-5),	SQNR:45.55283dB 

02/28/2024 01:23:50 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:23:56 - INFO - __main__ -   MSE:2.43857x10^(-5),	SQNR:46.08073dB 

02/28/2024 01:23:56 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:24:03 - INFO - __main__ -   MSE:13.82826x10^(-5),	SQNR:38.42031dB 

02/28/2024 01:24:03 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:24:10 - INFO - __main__ -   MSE:12.33456x10^(-5),	SQNR:38.96651dB 

02/28/2024 01:24:10 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:24:17 - INFO - __main__ -   MSE:1.66555x10^(-5),	SQNR:47.74568dB 

02/28/2024 01:24:17 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:24:23 - INFO - __main__ -   MSE:1.99238x10^(-5),	SQNR:47.17694dB 

02/28/2024 01:24:23 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:24:28 - INFO - __main__ -   MSE:7.19263x10^(-5),	SQNR:41.29715dB 

02/28/2024 01:24:28 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:24:35 - INFO - __main__ -   MSE:6.76618x10^(-5),	SQNR:41.57845dB 

02/28/2024 01:24:35 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:24:41 - INFO - __main__ -   MSE:0.13983x10^(-5),	SQNR:58.40422dB 

02/28/2024 01:24:41 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:24:47 - INFO - __main__ -   MSE:0.28440x10^(-5),	SQNR:55.36543dB 

02/28/2024 01:24:47 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:24:54 - INFO - __main__ -   MSE:1.43313x10^(-5),	SQNR:48.40106dB 

02/28/2024 01:24:54 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:24:59 - INFO - __main__ -   MSE:1.05737x10^(-5),	SQNR:49.71026dB 

02/28/2024 01:24:59 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:25:05 - INFO - __main__ -   MSE:16.15269x10^(-5),	SQNR:37.75367dB 

02/28/2024 01:25:05 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:25:11 - INFO - __main__ -   MSE:12.73633x10^(-5),	SQNR:38.78251dB 

02/28/2024 01:25:11 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:25:20 - INFO - __main__ -   MSE:1.19142x10^(-5),	SQNR:49.14283dB 

02/28/2024 01:25:20 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:25:26 - INFO - __main__ -   MSE:1.32573x10^(-5),	SQNR:48.73854dB 

02/28/2024 01:25:26 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:25:33 - INFO - __main__ -   MSE:6.54080x10^(-5),	SQNR:41.65501dB 

02/28/2024 01:25:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:25:39 - INFO - __main__ -   MSE:4.03700x10^(-5),	SQNR:43.79476dB 

02/28/2024 01:25:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:25:45 - INFO - __main__ -   MSE:0.06080x10^(-5),	SQNR:62.08992dB 

02/28/2024 01:25:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:25:51 - INFO - __main__ -   MSE:0.11282x10^(-5),	SQNR:59.50318dB 

02/28/2024 01:25:51 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:25:58 - INFO - __main__ -   MSE:0.68099x10^(-5),	SQNR:51.58161dB 

02/28/2024 01:25:58 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:26:04 - INFO - __main__ -   MSE:0.50404x10^(-5),	SQNR:52.86773dB 

02/28/2024 01:26:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:26:12 - INFO - __main__ -   MSE:15.83023x10^(-5),	SQNR:37.85208dB 

02/28/2024 01:26:12 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:26:19 - INFO - __main__ -   MSE:12.96114x10^(-5),	SQNR:38.70201dB 

02/28/2024 01:26:19 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:26:24 - INFO - __main__ -   MSE:1.30071x10^(-5),	SQNR:48.77650dB 

02/28/2024 01:26:25 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:26:31 - INFO - __main__ -   MSE:1.00081x10^(-5),	SQNR:49.87009dB 

02/28/2024 01:26:31 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:26:37 - INFO - __main__ -   MSE:4.21700x10^(-5),	SQNR:43.66073dB 

02/28/2024 01:26:37 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:26:43 - INFO - __main__ -   MSE:3.41447x10^(-5),	SQNR:44.53065dB 

02/28/2024 01:26:43 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:26:50 - INFO - __main__ -   MSE:0.02933x10^(-5),	SQNR:65.16161dB 

02/28/2024 01:26:50 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:26:57 - INFO - __main__ -   MSE:0.04599x10^(-5),	SQNR:63.22799dB 

02/28/2024 01:26:57 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:27:04 - INFO - __main__ -   MSE:0.38072x10^(-5),	SQNR:54.19939dB 

02/28/2024 01:27:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:27:10 - INFO - __main__ -   MSE:0.27410x10^(-5),	SQNR:55.45576dB 

02/28/2024 01:27:10 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:27:17 - INFO - __main__ -   MSE:15.98129x10^(-5),	SQNR:37.82204dB 

02/28/2024 01:27:17 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:27:24 - INFO - __main__ -   MSE:11.72301x10^(-5),	SQNR:39.14978dB 

02/28/2024 01:27:24 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:27:30 - INFO - __main__ -   MSE:1.02375x10^(-5),	SQNR:49.72803dB 

02/28/2024 01:27:30 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:27:37 - INFO - __main__ -   MSE:1.00322x10^(-5),	SQNR:49.84938dB 

02/28/2024 01:27:37 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:27:43 - INFO - __main__ -   MSE:3.32319x10^(-5),	SQNR:44.63873dB 

02/28/2024 01:27:43 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:27:48 - INFO - __main__ -   MSE:2.51902x10^(-5),	SQNR:45.86134dB 

02/28/2024 01:27:49 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:27:55 - INFO - __main__ -   MSE:0.00932x10^(-5),	SQNR:70.36359dB 

02/28/2024 01:27:55 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:28:01 - INFO - __main__ -   MSE:0.02580x10^(-5),	SQNR:65.84146dB 

02/28/2024 01:28:01 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:28:06 - INFO - __main__ -   MSE:0.20540x10^(-5),	SQNR:56.77921dB 

02/28/2024 01:28:06 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:28:13 - INFO - __main__ -   MSE:0.14936x10^(-5),	SQNR:58.08275dB 

02/28/2024 01:28:13 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:28:20 - INFO - __main__ -   MSE:16.87609x10^(-5),	SQNR:37.54509dB 

02/28/2024 01:28:20 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:28:25 - INFO - __main__ -   MSE:10.26032x10^(-5),	SQNR:39.72424dB 

02/28/2024 01:28:25 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:28:33 - INFO - __main__ -   MSE:1.01698x10^(-5),	SQNR:49.81280dB 

02/28/2024 01:28:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:28:39 - INFO - __main__ -   MSE:1.20458x10^(-5),	SQNR:49.03014dB 

02/28/2024 01:28:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:28:45 - INFO - __main__ -   MSE:2.59588x10^(-5),	SQNR:45.77694dB 

02/28/2024 01:28:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:28:51 - INFO - __main__ -   MSE:1.71024x10^(-5),	SQNR:47.48118dB 

02/28/2024 01:28:51 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:28:58 - INFO - __main__ -   MSE:0.00660x10^(-5),	SQNR:71.71016dB 

02/28/2024 01:28:58 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:29:05 - INFO - __main__ -   MSE:0.01518x10^(-5),	SQNR:68.39952dB 

02/28/2024 01:29:05 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:29:11 - INFO - __main__ -   MSE:0.12240x10^(-5),	SQNR:58.99145dB 

02/28/2024 01:29:12 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:29:17 - INFO - __main__ -   MSE:0.08028x10^(-5),	SQNR:60.86559dB 

02/28/2024 01:29:17 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:29:23 - INFO - __main__ -   MSE:16.23173x10^(-5),	SQNR:37.76149dB 

02/28/2024 01:29:23 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:29:29 - INFO - __main__ -   MSE:8.76123x10^(-5),	SQNR:40.40157dB 

02/28/2024 01:29:29 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:29:36 - INFO - __main__ -   MSE:1.10717x10^(-5),	SQNR:49.39381dB 

02/28/2024 01:29:36 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:29:42 - INFO - __main__ -   MSE:1.15119x10^(-5),	SQNR:49.20473dB 

02/28/2024 01:29:42 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:29:49 - INFO - __main__ -   MSE:2.09504x10^(-5),	SQNR:46.59927dB 

02/28/2024 01:29:49 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:29:55 - INFO - __main__ -   MSE:1.21141x10^(-5),	SQNR:49.01621dB 

02/28/2024 01:29:55 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:30:01 - INFO - __main__ -   MSE:0.00308x10^(-5),	SQNR:75.04787dB 

02/28/2024 01:30:01 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:30:07 - INFO - __main__ -   MSE:0.00724x10^(-5),	SQNR:71.22838dB 

02/28/2024 01:30:07 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:30:15 - INFO - __main__ -   MSE:0.05694x10^(-5),	SQNR:62.34906dB 

02/28/2024 01:30:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:30:21 - INFO - __main__ -   MSE:0.04266x10^(-5),	SQNR:63.63433dB 

02/28/2024 01:30:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:30:28 - INFO - __main__ -   MSE:13.36502x10^(-5),	SQNR:38.57299dB 

02/28/2024 01:30:28 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:30:35 - INFO - __main__ -   MSE:5.71665x10^(-5),	SQNR:42.25549dB 

02/28/2024 01:30:35 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:30:41 - INFO - __main__ -   MSE:0.92008x10^(-5),	SQNR:50.26492dB 

02/28/2024 01:30:41 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:30:47 - INFO - __main__ -   MSE:1.07952x10^(-5),	SQNR:49.56656dB 

02/28/2024 01:30:47 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:30:55 - INFO - __main__ -   MSE:1.79292x10^(-5),	SQNR:47.30075dB 

02/28/2024 01:30:55 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:31:01 - INFO - __main__ -   MSE:0.80964x10^(-5),	SQNR:50.72750dB 

02/28/2024 01:31:01 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:31:08 - INFO - __main__ -   MSE:0.00123x10^(-5),	SQNR:79.00075dB 

02/28/2024 01:31:08 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:31:13 - INFO - __main__ -   MSE:0.00285x10^(-5),	SQNR:75.36448dB 

02/28/2024 01:31:13 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:31:19 - INFO - __main__ -   MSE:0.02293x10^(-5),	SQNR:66.27451dB 

02/28/2024 01:31:19 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:31:24 - INFO - __main__ -   MSE:0.02462x10^(-5),	SQNR:65.96341dB 

02/28/2024 01:31:24 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:31:31 - INFO - __main__ -   MSE:12.75572x10^(-5),	SQNR:38.77224dB 

02/28/2024 01:31:31 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:31:40 - INFO - __main__ -   MSE:3.30724x10^(-5),	SQNR:44.64903dB 

02/28/2024 01:31:40 - INFO - __main__ -   model.up_blocks.0.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 01:31:46 - INFO - __main__ -   MSE:9.95791x10^(-5),	SQNR:39.84561dB 

02/28/2024 01:31:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 01:31:54 - INFO - __main__ -   MSE:15.72884x10^(-5),	SQNR:37.85093dB 

02/28/2024 01:31:54 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:32:01 - INFO - __main__ -   MSE:0.72029x10^(-5),	SQNR:51.28134dB 

02/28/2024 01:32:01 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:32:07 - INFO - __main__ -   MSE:0.60309x10^(-5),	SQNR:52.09858dB 

02/28/2024 01:32:07 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:32:15 - INFO - __main__ -   MSE:3.66821x10^(-5),	SQNR:44.22081dB 

02/28/2024 01:32:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:32:20 - INFO - __main__ -   MSE:7.30110x10^(-5),	SQNR:41.23177dB 

02/28/2024 01:32:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:32:27 - INFO - __main__ -   MSE:0.01613x10^(-5),	SQNR:67.75593dB 

02/28/2024 01:32:27 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:32:34 - INFO - __main__ -   MSE:0.14473x10^(-5),	SQNR:58.34002dB 

02/28/2024 01:32:34 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:32:39 - INFO - __main__ -   MSE:0.67708x10^(-5),	SQNR:51.53426dB 

02/28/2024 01:32:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:32:44 - INFO - __main__ -   MSE:0.45079x10^(-5),	SQNR:53.38728dB 

02/28/2024 01:32:44 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:32:53 - INFO - __main__ -   MSE:5.01405x10^(-5),	SQNR:42.82579dB 

02/28/2024 01:32:53 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:32:58 - INFO - __main__ -   MSE:7.20101x10^(-5),	SQNR:41.25670dB 

02/28/2024 01:32:58 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:33:06 - INFO - __main__ -   MSE:0.61329x10^(-5),	SQNR:51.97581dB 

02/28/2024 01:33:06 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:33:13 - INFO - __main__ -   MSE:0.40569x10^(-5),	SQNR:53.89466dB 

02/28/2024 01:33:13 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:33:19 - INFO - __main__ -   MSE:3.84791x10^(-5),	SQNR:43.96156dB 

02/28/2024 01:33:19 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:33:24 - INFO - __main__ -   MSE:4.08166x10^(-5),	SQNR:43.76297dB 

02/28/2024 01:33:24 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:33:32 - INFO - __main__ -   MSE:0.31352x10^(-5),	SQNR:55.12555dB 

02/28/2024 01:33:32 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:33:37 - INFO - __main__ -   MSE:1.59767x10^(-5),	SQNR:47.96836dB 

02/28/2024 01:33:37 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:33:43 - INFO - __main__ -   MSE:2.56851x10^(-5),	SQNR:45.76591dB 

02/28/2024 01:33:43 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:33:49 - INFO - __main__ -   MSE:1.73295x10^(-5),	SQNR:47.50404dB 

02/28/2024 01:33:49 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:33:57 - INFO - __main__ -   MSE:6.69495x10^(-5),	SQNR:41.65717dB 

02/28/2024 01:33:57 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:34:03 - INFO - __main__ -   MSE:6.37705x10^(-5),	SQNR:41.84508dB 

02/28/2024 01:34:03 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:34:11 - INFO - __main__ -   MSE:0.43802x10^(-5),	SQNR:53.41615dB 

02/28/2024 01:34:11 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:34:18 - INFO - __main__ -   MSE:0.40045x10^(-5),	SQNR:53.87922dB 

02/28/2024 01:34:18 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:34:24 - INFO - __main__ -   MSE:4.25136x10^(-5),	SQNR:43.57959dB 

02/28/2024 01:34:24 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:34:29 - INFO - __main__ -   MSE:2.63898x10^(-5),	SQNR:45.60543dB 

02/28/2024 01:34:29 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:34:37 - INFO - __main__ -   MSE:0.24859x10^(-5),	SQNR:56.07668dB 

02/28/2024 01:34:37 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:34:42 - INFO - __main__ -   MSE:1.19134x10^(-5),	SQNR:49.20400dB 

02/28/2024 01:34:42 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:34:48 - INFO - __main__ -   MSE:2.85049x10^(-5),	SQNR:45.28806dB 

02/28/2024 01:34:48 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:34:54 - INFO - __main__ -   MSE:1.63748x10^(-5),	SQNR:47.75072dB 

02/28/2024 01:34:54 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:34:59 - INFO - __main__ -   MSE:8.19052x10^(-5),	SQNR:40.70651dB 

02/28/2024 01:34:59 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:35:06 - INFO - __main__ -   MSE:6.03785x10^(-5),	SQNR:42.03224dB 

02/28/2024 01:35:06 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:35:14 - INFO - __main__ -   MSE:0.59863x10^(-5),	SQNR:52.08431dB 

02/28/2024 01:35:14 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:35:19 - INFO - __main__ -   MSE:0.46802x10^(-5),	SQNR:53.14175dB 

02/28/2024 01:35:19 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:35:26 - INFO - __main__ -   MSE:3.83041x10^(-5),	SQNR:44.01851dB 

02/28/2024 01:35:26 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:35:31 - INFO - __main__ -   MSE:2.59504x10^(-5),	SQNR:45.68980dB 

02/28/2024 01:35:31 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:35:37 - INFO - __main__ -   MSE:0.67926x10^(-5),	SQNR:52.74096dB 

02/28/2024 01:35:37 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:35:44 - INFO - __main__ -   MSE:0.55298x10^(-5),	SQNR:52.62374dB 

02/28/2024 01:35:44 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:35:51 - INFO - __main__ -   MSE:1.43440x10^(-5),	SQNR:48.31949dB 

02/28/2024 01:35:51 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:35:57 - INFO - __main__ -   MSE:1.27411x10^(-5),	SQNR:48.83960dB 

02/28/2024 01:35:57 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:36:04 - INFO - __main__ -   MSE:10.47223x10^(-5),	SQNR:39.61491dB 

02/28/2024 01:36:04 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:36:12 - INFO - __main__ -   MSE:6.84235x10^(-5),	SQNR:41.48497dB 

02/28/2024 01:36:12 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:36:18 - INFO - __main__ -   MSE:0.52708x10^(-5),	SQNR:52.60652dB 

02/28/2024 01:36:18 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:36:25 - INFO - __main__ -   MSE:0.38825x10^(-5),	SQNR:54.00922dB 

02/28/2024 01:36:25 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:36:32 - INFO - __main__ -   MSE:3.60572x10^(-5),	SQNR:44.24037dB 

02/28/2024 01:36:32 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:36:37 - INFO - __main__ -   MSE:1.93259x10^(-5),	SQNR:46.94943dB 

02/28/2024 01:36:37 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:36:43 - INFO - __main__ -   MSE:0.15308x10^(-5),	SQNR:58.19244dB 

02/28/2024 01:36:43 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:36:50 - INFO - __main__ -   MSE:0.22182x10^(-5),	SQNR:56.43816dB 

02/28/2024 01:36:50 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:36:55 - INFO - __main__ -   MSE:0.73265x10^(-5),	SQNR:51.21262dB 

02/28/2024 01:36:55 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:37:01 - INFO - __main__ -   MSE:0.50089x10^(-5),	SQNR:52.81539dB 

02/28/2024 01:37:01 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:37:09 - INFO - __main__ -   MSE:11.31963x10^(-5),	SQNR:39.27305dB 

02/28/2024 01:37:09 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:37:14 - INFO - __main__ -   MSE:6.79830x10^(-5),	SQNR:41.51723dB 

02/28/2024 01:37:14 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:37:19 - INFO - __main__ -   MSE:0.47924x10^(-5),	SQNR:53.10397dB 

02/28/2024 01:37:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:37:27 - INFO - __main__ -   MSE:0.44133x10^(-5),	SQNR:53.36538dB 

02/28/2024 01:37:27 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:37:33 - INFO - __main__ -   MSE:2.48748x10^(-5),	SQNR:45.89754dB 

02/28/2024 01:37:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:37:39 - INFO - __main__ -   MSE:1.66171x10^(-5),	SQNR:47.60702dB 

02/28/2024 01:37:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:37:48 - INFO - __main__ -   MSE:0.06872x10^(-5),	SQNR:61.54263dB 

02/28/2024 01:37:48 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:37:55 - INFO - __main__ -   MSE:0.16853x10^(-5),	SQNR:57.69727dB 

02/28/2024 01:37:55 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:38:02 - INFO - __main__ -   MSE:0.55935x10^(-5),	SQNR:52.40848dB 

02/28/2024 01:38:02 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:38:08 - INFO - __main__ -   MSE:0.35674x10^(-5),	SQNR:54.48486dB 

02/28/2024 01:38:08 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:38:14 - INFO - __main__ -   MSE:10.61924x10^(-5),	SQNR:39.55259dB 

02/28/2024 01:38:14 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:38:20 - INFO - __main__ -   MSE:5.69846x10^(-5),	SQNR:42.25148dB 

02/28/2024 01:38:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:38:28 - INFO - __main__ -   MSE:0.53373x10^(-5),	SQNR:52.54598dB 

02/28/2024 01:38:28 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:38:34 - INFO - __main__ -   MSE:0.42108x10^(-5),	SQNR:53.58209dB 

02/28/2024 01:38:34 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:38:41 - INFO - __main__ -   MSE:2.24389x10^(-5),	SQNR:46.30377dB 

02/28/2024 01:38:41 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:38:47 - INFO - __main__ -   MSE:1.54410x10^(-5),	SQNR:47.94646dB 

02/28/2024 01:38:47 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:38:53 - INFO - __main__ -   MSE:0.02575x10^(-5),	SQNR:65.75150dB 

02/28/2024 01:38:53 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:38:58 - INFO - __main__ -   MSE:0.08055x10^(-5),	SQNR:61.45931dB 

02/28/2024 01:38:58 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:39:06 - INFO - __main__ -   MSE:0.23081x10^(-5),	SQNR:56.18635dB 

02/28/2024 01:39:06 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:39:11 - INFO - __main__ -   MSE:0.17810x10^(-5),	SQNR:57.32935dB 

02/28/2024 01:39:11 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:39:16 - INFO - __main__ -   MSE:10.62280x10^(-5),	SQNR:39.54283dB 

02/28/2024 01:39:16 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:39:24 - INFO - __main__ -   MSE:5.66403x10^(-5),	SQNR:42.28994dB 

02/28/2024 01:39:24 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:39:30 - INFO - __main__ -   MSE:0.50215x10^(-5),	SQNR:52.83386dB 

02/28/2024 01:39:30 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:39:35 - INFO - __main__ -   MSE:0.33641x10^(-5),	SQNR:54.57688dB 

02/28/2024 01:39:35 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:39:42 - INFO - __main__ -   MSE:1.44673x10^(-5),	SQNR:48.22283dB 

02/28/2024 01:39:42 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:39:47 - INFO - __main__ -   MSE:1.12223x10^(-5),	SQNR:49.31773dB 

02/28/2024 01:39:48 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:39:53 - INFO - __main__ -   MSE:0.00504x10^(-5),	SQNR:72.84563dB 

02/28/2024 01:39:53 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:40:00 - INFO - __main__ -   MSE:0.01170x10^(-5),	SQNR:69.13426dB 

02/28/2024 01:40:00 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:40:06 - INFO - __main__ -   MSE:0.12991x10^(-5),	SQNR:58.70405dB 

02/28/2024 01:40:06 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:40:12 - INFO - __main__ -   MSE:0.09150x10^(-5),	SQNR:60.26114dB 

02/28/2024 01:40:12 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:40:19 - INFO - __main__ -   MSE:8.93558x10^(-5),	SQNR:40.29516dB 

02/28/2024 01:40:19 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:40:26 - INFO - __main__ -   MSE:4.61815x10^(-5),	SQNR:43.18511dB 

02/28/2024 01:40:26 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:40:32 - INFO - __main__ -   MSE:1.13982x10^(-5),	SQNR:49.31422dB 

02/28/2024 01:40:32 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:40:38 - INFO - __main__ -   MSE:0.85746x10^(-5),	SQNR:50.54660dB 

02/28/2024 01:40:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:40:46 - INFO - __main__ -   MSE:1.54753x10^(-5),	SQNR:47.90999dB 

02/28/2024 01:40:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:40:51 - INFO - __main__ -   MSE:1.22909x10^(-5),	SQNR:48.93038dB 

02/28/2024 01:40:51 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:40:58 - INFO - __main__ -   MSE:0.00212x10^(-5),	SQNR:76.57141dB 

02/28/2024 01:40:58 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:41:07 - INFO - __main__ -   MSE:0.00570x10^(-5),	SQNR:72.46442dB 

02/28/2024 01:41:07 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:41:13 - INFO - __main__ -   MSE:0.04758x10^(-5),	SQNR:63.13982dB 

02/28/2024 01:41:13 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:41:20 - INFO - __main__ -   MSE:0.03203x10^(-5),	SQNR:64.83839dB 

02/28/2024 01:41:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:41:27 - INFO - __main__ -   MSE:7.89126x10^(-5),	SQNR:40.83443dB 

02/28/2024 01:41:27 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:41:33 - INFO - __main__ -   MSE:3.30244x10^(-5),	SQNR:44.63380dB 

02/28/2024 01:41:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:41:40 - INFO - __main__ -   MSE:0.78944x10^(-5),	SQNR:50.88661dB 

02/28/2024 01:41:40 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:41:45 - INFO - __main__ -   MSE:0.63670x10^(-5),	SQNR:51.87623dB 

02/28/2024 01:41:45 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:41:52 - INFO - __main__ -   MSE:1.09830x10^(-5),	SQNR:49.40382dB 

02/28/2024 01:41:52 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:41:57 - INFO - __main__ -   MSE:0.62652x10^(-5),	SQNR:51.85390dB 

02/28/2024 01:41:57 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:42:05 - INFO - __main__ -   MSE:0.00216x10^(-5),	SQNR:76.61394dB 

02/28/2024 01:42:05 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:42:13 - INFO - __main__ -   MSE:0.00734x10^(-5),	SQNR:71.70952dB 

02/28/2024 01:42:13 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:42:20 - INFO - __main__ -   MSE:0.01531x10^(-5),	SQNR:68.11422dB 

02/28/2024 01:42:21 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:42:27 - INFO - __main__ -   MSE:0.01215x10^(-5),	SQNR:69.02959dB 

02/28/2024 01:42:27 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:42:33 - INFO - __main__ -   MSE:6.02076x10^(-5),	SQNR:42.01035dB 

02/28/2024 01:42:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:42:39 - INFO - __main__ -   MSE:1.78774x10^(-5),	SQNR:47.31723dB 

02/28/2024 01:42:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 01:42:47 - INFO - __main__ -   MSE:7.68549x10^(-5),	SQNR:40.98339dB 

02/28/2024 01:42:47 - INFO - __main__ -   model.up_blocks.0.attentions.2.proj_in: weight_quant=True, act_quant=False
02/28/2024 01:42:54 - INFO - __main__ -   MSE:13.07282x10^(-5),	SQNR:38.66999dB 

02/28/2024 01:42:54 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:43:01 - INFO - __main__ -   MSE:0.68490x10^(-5),	SQNR:51.51661dB 

02/28/2024 01:43:01 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:43:06 - INFO - __main__ -   MSE:0.51877x10^(-5),	SQNR:52.70171dB 

02/28/2024 01:43:06 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:43:12 - INFO - __main__ -   MSE:1.98389x10^(-5),	SQNR:46.86052dB 

02/28/2024 01:43:12 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:43:18 - INFO - __main__ -   MSE:3.78962x10^(-5),	SQNR:44.03207dB 

02/28/2024 01:43:18 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:43:24 - INFO - __main__ -   MSE:0.00163x10^(-5),	SQNR:77.69661dB 

02/28/2024 01:43:24 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:43:30 - INFO - __main__ -   MSE:0.00838x10^(-5),	SQNR:70.62325dB 

02/28/2024 01:43:30 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:43:36 - INFO - __main__ -   MSE:0.04073x10^(-5),	SQNR:63.75978dB 

02/28/2024 01:43:36 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:43:42 - INFO - __main__ -   MSE:0.02401x10^(-5),	SQNR:66.04823dB 

02/28/2024 01:43:42 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:43:49 - INFO - __main__ -   MSE:4.15486x10^(-5),	SQNR:43.64269dB 

02/28/2024 01:43:49 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:43:55 - INFO - __main__ -   MSE:3.99273x10^(-5),	SQNR:43.82901dB 

02/28/2024 01:43:55 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:44:04 - INFO - __main__ -   MSE:0.22866x10^(-5),	SQNR:56.25901dB 

02/28/2024 01:44:04 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:44:09 - INFO - __main__ -   MSE:0.25218x10^(-5),	SQNR:55.96261dB 

02/28/2024 01:44:09 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:44:16 - INFO - __main__ -   MSE:1.45894x10^(-5),	SQNR:48.19945dB 

02/28/2024 01:44:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:44:21 - INFO - __main__ -   MSE:1.41540x10^(-5),	SQNR:48.30802dB 

02/28/2024 01:44:21 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:44:30 - INFO - __main__ -   MSE:0.00466x10^(-5),	SQNR:73.14685dB 

02/28/2024 01:44:30 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:44:36 - INFO - __main__ -   MSE:0.01501x10^(-5),	SQNR:68.05356dB 

02/28/2024 01:44:36 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:44:43 - INFO - __main__ -   MSE:0.11791x10^(-5),	SQNR:59.10084dB 

02/28/2024 01:44:43 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:44:50 - INFO - __main__ -   MSE:0.08266x10^(-5),	SQNR:60.77828dB 

02/28/2024 01:44:50 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:44:55 - INFO - __main__ -   MSE:4.04584x10^(-5),	SQNR:43.79045dB 

02/28/2024 01:44:55 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:45:02 - INFO - __main__ -   MSE:2.85381x10^(-5),	SQNR:45.28933dB 

02/28/2024 01:45:02 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:45:09 - INFO - __main__ -   MSE:0.20139x10^(-5),	SQNR:56.78947dB 

02/28/2024 01:45:09 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:45:16 - INFO - __main__ -   MSE:0.25966x10^(-5),	SQNR:55.78469dB 

02/28/2024 01:45:16 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:45:23 - INFO - __main__ -   MSE:1.25898x10^(-5),	SQNR:48.82777dB 

02/28/2024 01:45:23 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:45:29 - INFO - __main__ -   MSE:1.03095x10^(-5),	SQNR:49.71584dB 

02/28/2024 01:45:29 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:45:34 - INFO - __main__ -   MSE:0.00637x10^(-5),	SQNR:72.39404dB 

02/28/2024 01:45:34 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:45:41 - INFO - __main__ -   MSE:0.01354x10^(-5),	SQNR:68.88168dB 

02/28/2024 01:45:41 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:45:47 - INFO - __main__ -   MSE:0.09221x10^(-5),	SQNR:60.19416dB 

02/28/2024 01:45:47 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:45:53 - INFO - __main__ -   MSE:0.06963x10^(-5),	SQNR:61.57881dB 

02/28/2024 01:45:53 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:46:00 - INFO - __main__ -   MSE:3.28489x10^(-5),	SQNR:44.67101dB 

02/28/2024 01:46:00 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:46:07 - INFO - __main__ -   MSE:2.41408x10^(-5),	SQNR:46.02990dB 

02/28/2024 01:46:07 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:46:13 - INFO - __main__ -   MSE:0.29183x10^(-5),	SQNR:55.24070dB 

02/28/2024 01:46:13 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:46:20 - INFO - __main__ -   MSE:0.26136x10^(-5),	SQNR:55.71675dB 

02/28/2024 01:46:21 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:46:27 - INFO - __main__ -   MSE:0.94085x10^(-5),	SQNR:50.15101dB 

02/28/2024 01:46:27 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:46:33 - INFO - __main__ -   MSE:0.77475x10^(-5),	SQNR:50.94087dB 

02/28/2024 01:46:33 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:46:40 - INFO - __main__ -   MSE:0.00455x10^(-5),	SQNR:73.82394dB 

02/28/2024 01:46:40 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:46:47 - INFO - __main__ -   MSE:0.00706x10^(-5),	SQNR:71.75186dB 

02/28/2024 01:46:47 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:46:53 - INFO - __main__ -   MSE:0.03597x10^(-5),	SQNR:64.32332dB 

02/28/2024 01:46:53 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:47:00 - INFO - __main__ -   MSE:0.03535x10^(-5),	SQNR:64.55005dB 

02/28/2024 01:47:00 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:47:07 - INFO - __main__ -   MSE:3.19772x10^(-5),	SQNR:44.77634dB 

02/28/2024 01:47:07 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:47:13 - INFO - __main__ -   MSE:2.39402x10^(-5),	SQNR:46.03479dB 

02/28/2024 01:47:13 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:47:22 - INFO - __main__ -   MSE:0.13615x10^(-5),	SQNR:58.56113dB 

02/28/2024 01:47:22 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:47:28 - INFO - __main__ -   MSE:0.13461x10^(-5),	SQNR:58.62242dB 

02/28/2024 01:47:28 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:47:33 - INFO - __main__ -   MSE:0.78545x10^(-5),	SQNR:50.86361dB 

02/28/2024 01:47:33 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:47:40 - INFO - __main__ -   MSE:0.48222x10^(-5),	SQNR:53.03221dB 

02/28/2024 01:47:40 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:47:47 - INFO - __main__ -   MSE:0.00151x10^(-5),	SQNR:78.04440dB 

02/28/2024 01:47:47 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:47:53 - INFO - __main__ -   MSE:0.00286x10^(-5),	SQNR:75.35756dB 

02/28/2024 01:47:53 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:48:02 - INFO - __main__ -   MSE:0.02092x10^(-5),	SQNR:66.65842dB 

02/28/2024 01:48:02 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:48:08 - INFO - __main__ -   MSE:0.01506x10^(-5),	SQNR:68.17603dB 

02/28/2024 01:48:08 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:48:14 - INFO - __main__ -   MSE:3.21142x10^(-5),	SQNR:44.77699dB 

02/28/2024 01:48:14 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:48:22 - INFO - __main__ -   MSE:2.22940x10^(-5),	SQNR:46.34403dB 

02/28/2024 01:48:22 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:48:29 - INFO - __main__ -   MSE:0.09660x10^(-5),	SQNR:60.01980dB 

02/28/2024 01:48:30 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:48:35 - INFO - __main__ -   MSE:0.08209x10^(-5),	SQNR:60.77012dB 

02/28/2024 01:48:35 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:48:41 - INFO - __main__ -   MSE:0.48993x10^(-5),	SQNR:52.93098dB 

02/28/2024 01:48:41 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:48:47 - INFO - __main__ -   MSE:0.38249x10^(-5),	SQNR:53.99349dB 

02/28/2024 01:48:47 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:48:53 - INFO - __main__ -   MSE:0.00102x10^(-5),	SQNR:79.74627dB 

02/28/2024 01:48:53 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:49:00 - INFO - __main__ -   MSE:0.00166x10^(-5),	SQNR:77.62579dB 

02/28/2024 01:49:00 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:49:08 - INFO - __main__ -   MSE:0.01337x10^(-5),	SQNR:68.55627dB 

02/28/2024 01:49:08 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:49:13 - INFO - __main__ -   MSE:0.01138x10^(-5),	SQNR:69.36256dB 

02/28/2024 01:49:13 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:49:20 - INFO - __main__ -   MSE:3.07830x10^(-5),	SQNR:44.94395dB 

02/28/2024 01:49:20 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:49:27 - INFO - __main__ -   MSE:1.93443x10^(-5),	SQNR:46.98402dB 

02/28/2024 01:49:27 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:49:33 - INFO - __main__ -   MSE:0.11450x10^(-5),	SQNR:59.24048dB 

02/28/2024 01:49:34 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:49:41 - INFO - __main__ -   MSE:0.12596x10^(-5),	SQNR:58.83723dB 

02/28/2024 01:49:41 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:49:47 - INFO - __main__ -   MSE:0.49736x10^(-5),	SQNR:52.86060dB 

02/28/2024 01:49:47 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:49:53 - INFO - __main__ -   MSE:0.28493x10^(-5),	SQNR:55.29133dB 

02/28/2024 01:49:53 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:49:58 - INFO - __main__ -   MSE:0.00070x10^(-5),	SQNR:81.35337dB 

02/28/2024 01:49:58 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:50:06 - INFO - __main__ -   MSE:0.00100x10^(-5),	SQNR:79.84731dB 

02/28/2024 01:50:06 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:50:12 - INFO - __main__ -   MSE:0.00770x10^(-5),	SQNR:70.98126dB 

02/28/2024 01:50:12 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:50:17 - INFO - __main__ -   MSE:0.00632x10^(-5),	SQNR:71.87021dB 

02/28/2024 01:50:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:50:24 - INFO - __main__ -   MSE:3.09621x10^(-5),	SQNR:44.92553dB 

02/28/2024 01:50:24 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:50:30 - INFO - __main__ -   MSE:1.80117x10^(-5),	SQNR:47.27629dB 

02/28/2024 01:50:30 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:50:35 - INFO - __main__ -   MSE:0.10676x10^(-5),	SQNR:59.59797dB 

02/28/2024 01:50:35 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:50:41 - INFO - __main__ -   MSE:0.10186x10^(-5),	SQNR:59.89708dB 

02/28/2024 01:50:41 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:50:47 - INFO - __main__ -   MSE:0.42334x10^(-5),	SQNR:53.57012dB 

02/28/2024 01:50:47 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:50:52 - INFO - __main__ -   MSE:0.23639x10^(-5),	SQNR:56.08470dB 

02/28/2024 01:50:52 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:50:59 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.11584dB 

02/28/2024 01:50:59 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:51:05 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.10892dB 

02/28/2024 01:51:05 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:51:10 - INFO - __main__ -   MSE:0.00693x10^(-5),	SQNR:71.43198dB 

02/28/2024 01:51:10 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:51:16 - INFO - __main__ -   MSE:0.00643x10^(-5),	SQNR:71.84267dB 

02/28/2024 01:51:16 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:51:23 - INFO - __main__ -   MSE:2.97389x10^(-5),	SQNR:45.10263dB 

02/28/2024 01:51:23 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:51:30 - INFO - __main__ -   MSE:1.61238x10^(-5),	SQNR:47.73978dB 

02/28/2024 01:51:30 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:51:35 - INFO - __main__ -   MSE:0.10029x10^(-5),	SQNR:59.82618dB 

02/28/2024 01:51:35 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:51:42 - INFO - __main__ -   MSE:0.10538x10^(-5),	SQNR:59.58978dB 

02/28/2024 01:51:42 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:51:49 - INFO - __main__ -   MSE:0.34790x10^(-5),	SQNR:54.40641dB 

02/28/2024 01:51:50 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:51:54 - INFO - __main__ -   MSE:0.22503x10^(-5),	SQNR:56.29299dB 

02/28/2024 01:51:54 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:52:01 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.10005dB 

02/28/2024 01:52:01 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:52:08 - INFO - __main__ -   MSE:0.00132x10^(-5),	SQNR:78.61218dB 

02/28/2024 01:52:08 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:52:13 - INFO - __main__ -   MSE:0.00350x10^(-5),	SQNR:74.38046dB 

02/28/2024 01:52:13 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:52:18 - INFO - __main__ -   MSE:0.00308x10^(-5),	SQNR:74.95358dB 

02/28/2024 01:52:18 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:52:25 - INFO - __main__ -   MSE:3.06378x10^(-5),	SQNR:44.95568dB 

02/28/2024 01:52:25 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:52:31 - INFO - __main__ -   MSE:1.64107x10^(-5),	SQNR:47.68200dB 

02/28/2024 01:52:31 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:52:38 - INFO - __main__ -   MSE:0.03438x10^(-5),	SQNR:64.48826dB 

02/28/2024 01:52:38 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:52:45 - INFO - __main__ -   MSE:0.03654x10^(-5),	SQNR:64.36045dB 

02/28/2024 01:52:45 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:52:51 - INFO - __main__ -   MSE:0.18361x10^(-5),	SQNR:57.19611dB 

02/28/2024 01:52:51 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:52:57 - INFO - __main__ -   MSE:0.09921x10^(-5),	SQNR:59.86822dB 

02/28/2024 01:52:57 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:53:04 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.22792dB 

02/28/2024 01:53:04 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:53:09 - INFO - __main__ -   MSE:0.00074x10^(-5),	SQNR:81.11687dB 

02/28/2024 01:53:09 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:53:17 - INFO - __main__ -   MSE:0.00206x10^(-5),	SQNR:76.68655dB 

02/28/2024 01:53:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:53:22 - INFO - __main__ -   MSE:0.00229x10^(-5),	SQNR:76.24223dB 

02/28/2024 01:53:22 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:53:29 - INFO - __main__ -   MSE:2.76266x10^(-5),	SQNR:45.40917dB 

02/28/2024 01:53:29 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:53:35 - INFO - __main__ -   MSE:1.73573x10^(-5),	SQNR:47.43121dB 

02/28/2024 01:53:35 - INFO - __main__ -   model.up_blocks.0.attentions.2.proj_out: weight_quant=True, act_quant=False
02/28/2024 01:53:43 - INFO - __main__ -   MSE:6.31661x10^(-5),	SQNR:41.81273dB 

02/28/2024 01:53:43 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 01:53:50 - INFO - __main__ -   MSE:38.19573x10^(-5),	SQNR:34.01624dB 

02/28/2024 01:53:50 - INFO - __main__ -   model.up_blocks.0.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 01:53:57 - INFO - __main__ -   MSE:0.82246x10^(-5),	SQNR:50.69229dB 

02/28/2024 01:53:57 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 01:54:03 - INFO - __main__ -   MSE:40.69154x10^(-5),	SQNR:33.73761dB 

02/28/2024 01:54:03 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 01:54:09 - INFO - __main__ -   MSE:20.10946x10^(-5),	SQNR:36.78539dB 

02/28/2024 01:54:09 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 01:54:15 - INFO - __main__ -   MSE:37.15423x10^(-5),	SQNR:34.44391dB 

02/28/2024 01:54:15 - INFO - __main__ -   model.up_blocks.0.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 01:54:22 - INFO - __main__ -   MSE:3.17711x10^(-5),	SQNR:45.08867dB 

02/28/2024 01:54:22 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 01:54:29 - INFO - __main__ -   MSE:16.17205x10^(-5),	SQNR:37.72612dB 

02/28/2024 01:54:29 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 01:54:35 - INFO - __main__ -   MSE:21.58270x10^(-5),	SQNR:36.49125dB 

02/28/2024 01:54:35 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 01:54:42 - INFO - __main__ -   MSE:10.15466x10^(-5),	SQNR:39.75339dB 

02/28/2024 01:54:42 - INFO - __main__ -   model.up_blocks.0.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 01:54:48 - INFO - __main__ -   MSE:2.33204x10^(-5),	SQNR:46.16021dB 

02/28/2024 01:54:48 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 01:54:54 - INFO - __main__ -   MSE:7.42401x10^(-5),	SQNR:41.12609dB 

02/28/2024 01:54:54 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 01:55:02 - INFO - __main__ -   MSE:24.60079x10^(-5),	SQNR:35.90146dB 

02/28/2024 01:55:02 - INFO - __main__ -   model.up_blocks.0.upsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 01:55:10 - INFO - __main__ -   MSE:39.67216x10^(-5),	SQNR:33.82721dB 

02/28/2024 01:55:10 - INFO - __main__ -   model.up_blocks.1.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 01:55:16 - INFO - __main__ -   MSE:12.66279x10^(-5),	SQNR:38.78106dB 

02/28/2024 01:55:16 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:55:24 - INFO - __main__ -   MSE:1.43594x10^(-5),	SQNR:48.23606dB 

02/28/2024 01:55:24 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:55:30 - INFO - __main__ -   MSE:1.27557x10^(-5),	SQNR:48.75682dB 

02/28/2024 01:55:30 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:55:36 - INFO - __main__ -   MSE:6.49331x10^(-5),	SQNR:41.68240dB 

02/28/2024 01:55:36 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:55:45 - INFO - __main__ -   MSE:7.61635x10^(-5),	SQNR:40.99277dB 

02/28/2024 01:55:45 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:55:52 - INFO - __main__ -   MSE:0.02343x10^(-5),	SQNR:66.19417dB 

02/28/2024 01:55:52 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:55:57 - INFO - __main__ -   MSE:0.04891x10^(-5),	SQNR:62.98920dB 

02/28/2024 01:55:57 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:56:07 - INFO - __main__ -   MSE:0.03575x10^(-5),	SQNR:64.28735dB 

02/28/2024 01:56:07 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:56:11 - INFO - __main__ -   MSE:0.04324x10^(-5),	SQNR:63.49266dB 

02/28/2024 01:56:12 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:56:18 - INFO - __main__ -   MSE:6.76312x10^(-5),	SQNR:41.52115dB 

02/28/2024 01:56:18 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:56:27 - INFO - __main__ -   MSE:6.07404x10^(-5),	SQNR:41.99323dB 

02/28/2024 01:56:27 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:56:33 - INFO - __main__ -   MSE:1.22954x10^(-5),	SQNR:48.93408dB 

02/28/2024 01:56:33 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:56:38 - INFO - __main__ -   MSE:1.22979x10^(-5),	SQNR:48.91415dB 

02/28/2024 01:56:38 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:56:46 - INFO - __main__ -   MSE:5.70418x10^(-5),	SQNR:42.25003dB 

02/28/2024 01:56:46 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:56:51 - INFO - __main__ -   MSE:4.60678x10^(-5),	SQNR:43.17181dB 

02/28/2024 01:56:51 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:56:57 - INFO - __main__ -   MSE:0.02421x10^(-5),	SQNR:65.98082dB 

02/28/2024 01:56:57 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:57:03 - INFO - __main__ -   MSE:0.03659x10^(-5),	SQNR:64.17514dB 

02/28/2024 01:57:03 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:57:09 - INFO - __main__ -   MSE:0.04233x10^(-5),	SQNR:63.57804dB 

02/28/2024 01:57:09 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:57:15 - INFO - __main__ -   MSE:0.03823x10^(-5),	SQNR:64.00021dB 

02/28/2024 01:57:15 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:57:22 - INFO - __main__ -   MSE:6.30892x10^(-5),	SQNR:41.81100dB 

02/28/2024 01:57:22 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:57:29 - INFO - __main__ -   MSE:2.65965x10^(-5),	SQNR:45.57104dB 

02/28/2024 01:57:29 - INFO - __main__ -   model.up_blocks.1.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 01:57:35 - INFO - __main__ -   MSE:2.85171x10^(-5),	SQNR:45.26681dB 

02/28/2024 01:57:35 - INFO - __main__ -   model.up_blocks.1.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 01:57:43 - INFO - __main__ -   MSE:7.45949x10^(-5),	SQNR:41.08350dB 

02/28/2024 01:57:43 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:57:51 - INFO - __main__ -   MSE:0.42381x10^(-5),	SQNR:53.55519dB 

02/28/2024 01:57:51 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:57:56 - INFO - __main__ -   MSE:0.35114x10^(-5),	SQNR:54.37366dB 

02/28/2024 01:57:56 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:58:03 - INFO - __main__ -   MSE:3.17718x10^(-5),	SQNR:44.78745dB 

02/28/2024 01:58:03 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:58:09 - INFO - __main__ -   MSE:2.77832x10^(-5),	SQNR:45.37433dB 

02/28/2024 01:58:09 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:58:15 - INFO - __main__ -   MSE:0.13156x10^(-5),	SQNR:58.80966dB 

02/28/2024 01:58:15 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:58:21 - INFO - __main__ -   MSE:0.05887x10^(-5),	SQNR:62.10829dB 

02/28/2024 01:58:21 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:58:30 - INFO - __main__ -   MSE:0.01976x10^(-5),	SQNR:66.86218dB 

02/28/2024 01:58:30 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:58:36 - INFO - __main__ -   MSE:0.08158x10^(-5),	SQNR:60.84342dB 

02/28/2024 01:58:36 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:58:41 - INFO - __main__ -   MSE:4.16810x10^(-5),	SQNR:43.61105dB 

02/28/2024 01:58:41 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:58:50 - INFO - __main__ -   MSE:3.15196x10^(-5),	SQNR:44.83970dB 

02/28/2024 01:58:50 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 01:58:56 - INFO - __main__ -   MSE:0.28683x10^(-5),	SQNR:55.25613dB 

02/28/2024 01:58:56 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 01:59:02 - INFO - __main__ -   MSE:0.30030x10^(-5),	SQNR:55.07066dB 

02/28/2024 01:59:02 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 01:59:11 - INFO - __main__ -   MSE:2.03881x10^(-5),	SQNR:46.71840dB 

02/28/2024 01:59:11 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:59:16 - INFO - __main__ -   MSE:1.60799x10^(-5),	SQNR:47.74446dB 

02/28/2024 01:59:16 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 01:59:23 - INFO - __main__ -   MSE:0.04664x10^(-5),	SQNR:63.12601dB 

02/28/2024 01:59:23 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 01:59:30 - INFO - __main__ -   MSE:0.11870x10^(-5),	SQNR:59.06968dB 

02/28/2024 01:59:30 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 01:59:36 - INFO - __main__ -   MSE:0.04635x10^(-5),	SQNR:63.23252dB 

02/28/2024 01:59:36 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 01:59:41 - INFO - __main__ -   MSE:0.03078x10^(-5),	SQNR:64.95384dB 

02/28/2024 01:59:41 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 01:59:48 - INFO - __main__ -   MSE:4.17975x10^(-5),	SQNR:43.60053dB 

02/28/2024 01:59:48 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 01:59:54 - INFO - __main__ -   MSE:1.46419x10^(-5),	SQNR:48.17085dB 

02/28/2024 01:59:54 - INFO - __main__ -   model.up_blocks.1.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 02:00:01 - INFO - __main__ -   MSE:2.90369x10^(-5),	SQNR:45.18051dB 

02/28/2024 02:00:01 - INFO - __main__ -   model.up_blocks.1.attentions.2.proj_in: weight_quant=True, act_quant=False
02/28/2024 02:00:08 - INFO - __main__ -   MSE:8.06347x10^(-5),	SQNR:40.74668dB 

02/28/2024 02:00:08 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:00:16 - INFO - __main__ -   MSE:0.08406x10^(-5),	SQNR:60.60432dB 

02/28/2024 02:00:16 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:00:21 - INFO - __main__ -   MSE:0.05107x10^(-5),	SQNR:62.74837dB 

02/28/2024 02:00:21 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:00:28 - INFO - __main__ -   MSE:2.84331x10^(-5),	SQNR:45.27014dB 

02/28/2024 02:00:28 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:00:33 - INFO - __main__ -   MSE:1.40078x10^(-5),	SQNR:48.37649dB 

02/28/2024 02:00:33 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:00:39 - INFO - __main__ -   MSE:0.01693x10^(-5),	SQNR:67.55365dB 

02/28/2024 02:00:39 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:00:45 - INFO - __main__ -   MSE:0.09605x10^(-5),	SQNR:59.98117dB 

02/28/2024 02:00:45 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:00:51 - INFO - __main__ -   MSE:0.01993x10^(-5),	SQNR:66.84354dB 

02/28/2024 02:00:51 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:00:56 - INFO - __main__ -   MSE:0.03195x10^(-5),	SQNR:64.79675dB 

02/28/2024 02:00:56 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:01:03 - INFO - __main__ -   MSE:3.75388x10^(-5),	SQNR:44.06434dB 

02/28/2024 02:01:03 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:01:10 - INFO - __main__ -   MSE:1.78032x10^(-5),	SQNR:47.30465dB 

02/28/2024 02:01:10 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:01:17 - INFO - __main__ -   MSE:0.06494x10^(-5),	SQNR:61.68953dB 

02/28/2024 02:01:17 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:01:22 - INFO - __main__ -   MSE:0.05173x10^(-5),	SQNR:62.68631dB 

02/28/2024 02:01:22 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:01:29 - INFO - __main__ -   MSE:1.13074x10^(-5),	SQNR:49.28233dB 

02/28/2024 02:01:29 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:01:34 - INFO - __main__ -   MSE:0.54055x10^(-5),	SQNR:52.48095dB 

02/28/2024 02:01:34 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:01:41 - INFO - __main__ -   MSE:0.01725x10^(-5),	SQNR:67.57407dB 

02/28/2024 02:01:41 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:01:48 - INFO - __main__ -   MSE:0.07516x10^(-5),	SQNR:61.15856dB 

02/28/2024 02:01:48 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:01:55 - INFO - __main__ -   MSE:0.03545x10^(-5),	SQNR:64.37940dB 

02/28/2024 02:01:55 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:02:00 - INFO - __main__ -   MSE:0.02109x10^(-5),	SQNR:66.63998dB 

02/28/2024 02:02:00 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:02:07 - INFO - __main__ -   MSE:2.05359x10^(-5),	SQNR:46.68537dB 

02/28/2024 02:02:07 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:02:13 - INFO - __main__ -   MSE:1.11281x10^(-5),	SQNR:49.35410dB 

02/28/2024 02:02:13 - INFO - __main__ -   model.up_blocks.1.attentions.2.proj_out: weight_quant=True, act_quant=False
02/28/2024 02:02:19 - INFO - __main__ -   MSE:4.20312x10^(-5),	SQNR:43.56917dB 

02/28/2024 02:02:19 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 02:02:25 - INFO - __main__ -   MSE:18.88827x10^(-5),	SQNR:37.05990dB 

02/28/2024 02:02:25 - INFO - __main__ -   model.up_blocks.1.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:02:32 - INFO - __main__ -   MSE:0.52858x10^(-5),	SQNR:52.59284dB 

02/28/2024 02:02:32 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 02:02:37 - INFO - __main__ -   MSE:13.29322x10^(-5),	SQNR:38.58055dB 

02/28/2024 02:02:37 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 02:02:43 - INFO - __main__ -   MSE:17.03159x10^(-5),	SQNR:37.50788dB 

02/28/2024 02:02:43 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 02:02:52 - INFO - __main__ -   MSE:10.12136x10^(-5),	SQNR:39.76399dB 

02/28/2024 02:02:52 - INFO - __main__ -   model.up_blocks.1.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:02:59 - INFO - __main__ -   MSE:0.77737x10^(-5),	SQNR:50.91187dB 

02/28/2024 02:02:59 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 02:03:07 - INFO - __main__ -   MSE:5.83927x10^(-5),	SQNR:42.15204dB 

02/28/2024 02:03:07 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 02:03:13 - INFO - __main__ -   MSE:11.77397x10^(-5),	SQNR:39.09892dB 

02/28/2024 02:03:13 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 02:03:21 - INFO - __main__ -   MSE:19.33303x10^(-5),	SQNR:36.95467dB 

02/28/2024 02:03:21 - INFO - __main__ -   model.up_blocks.1.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:03:27 - INFO - __main__ -   MSE:1.91844x10^(-5),	SQNR:46.99883dB 

02/28/2024 02:03:28 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 02:03:34 - INFO - __main__ -   MSE:5.05094x10^(-5),	SQNR:42.77691dB 

02/28/2024 02:03:34 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 02:03:40 - INFO - __main__ -   MSE:10.90217x10^(-5),	SQNR:39.43271dB 

02/28/2024 02:03:40 - INFO - __main__ -   model.up_blocks.1.upsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 02:03:46 - INFO - __main__ -   MSE:37.43220x10^(-5),	SQNR:34.07416dB 

02/28/2024 02:03:46 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 02:03:53 - INFO - __main__ -   MSE:28.96393x10^(-5),	SQNR:35.18881dB 

02/28/2024 02:03:53 - INFO - __main__ -   model.up_blocks.2.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:03:59 - INFO - __main__ -   MSE:0.42355x10^(-5),	SQNR:53.53835dB 

02/28/2024 02:03:59 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 02:04:07 - INFO - __main__ -   MSE:12.86613x10^(-5),	SQNR:38.70928dB 

02/28/2024 02:04:07 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 02:04:13 - INFO - __main__ -   MSE:19.00145x10^(-5),	SQNR:37.01755dB 

02/28/2024 02:04:13 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 02:04:18 - INFO - __main__ -   MSE:34.82494x10^(-5),	SQNR:34.38747dB 

02/28/2024 02:04:18 - INFO - __main__ -   model.up_blocks.2.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:04:24 - INFO - __main__ -   MSE:0.85601x10^(-5),	SQNR:50.47867dB 

02/28/2024 02:04:24 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 02:04:31 - INFO - __main__ -   MSE:157.52695x10^(-5),	SQNR:27.82859dB 

02/28/2024 02:04:31 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 02:04:37 - INFO - __main__ -   MSE:40.58839x10^(-5),	SQNR:33.71845dB 

02/28/2024 02:04:37 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 02:04:44 - INFO - __main__ -   MSE:108.61837x10^(-5),	SQNR:29.44469dB 

02/28/2024 02:04:44 - INFO - __main__ -   model.up_blocks.2.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:04:51 - INFO - __main__ -   MSE:5.47890x10^(-5),	SQNR:42.41692dB 

02/28/2024 02:04:51 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 02:04:58 - INFO - __main__ -   MSE:15988.10840x10^(-5),	SQNR:7.76410dB 

02/28/2024 02:04:58 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 02:05:03 - INFO - __main__ -   MSE:76.35260x10^(-5),	SQNR:30.97400dB 

02/28/2024 02:05:03 - INFO - __main__ -   model.mid_block.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 02:05:11 - INFO - __main__ -   MSE:42.69245x10^(-5),	SQNR:33.59827dB 

02/28/2024 02:05:11 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:05:18 - INFO - __main__ -   MSE:2.44607x10^(-5),	SQNR:46.12585dB 

02/28/2024 02:05:18 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:05:23 - INFO - __main__ -   MSE:1.91230x10^(-5),	SQNR:47.15855dB 

02/28/2024 02:05:23 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:05:30 - INFO - __main__ -   MSE:7.39462x10^(-5),	SQNR:41.18439dB 

02/28/2024 02:05:31 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:05:36 - INFO - __main__ -   MSE:12.77978x10^(-5),	SQNR:38.80682dB 

02/28/2024 02:05:36 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:05:41 - INFO - __main__ -   MSE:0.02863x10^(-5),	SQNR:65.35299dB 

02/28/2024 02:05:41 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:05:49 - INFO - __main__ -   MSE:0.17207x10^(-5),	SQNR:58.47142dB 

02/28/2024 02:05:49 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:05:56 - INFO - __main__ -   MSE:0.49886x10^(-5),	SQNR:53.53653dB 

02/28/2024 02:05:56 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:06:01 - INFO - __main__ -   MSE:0.35112x10^(-5),	SQNR:54.63860dB 

02/28/2024 02:06:01 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:06:06 - INFO - __main__ -   MSE:12.08901x10^(-5),	SQNR:39.33810dB 

02/28/2024 02:06:06 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:06:13 - INFO - __main__ -   MSE:10.53683x10^(-5),	SQNR:39.69539dB 

02/28/2024 02:06:13 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:06:19 - INFO - __main__ -   MSE:3.26178x10^(-5),	SQNR:44.67087dB 

02/28/2024 02:06:19 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:06:26 - INFO - __main__ -   MSE:2.78757x10^(-5),	SQNR:45.68435dB 

02/28/2024 02:06:26 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:06:33 - INFO - __main__ -   MSE:8.42090x10^(-5),	SQNR:40.68296dB 

02/28/2024 02:06:33 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:06:38 - INFO - __main__ -   MSE:9.98104x10^(-5),	SQNR:39.95235dB 

02/28/2024 02:06:38 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:06:45 - INFO - __main__ -   MSE:0.06508x10^(-5),	SQNR:61.79725dB 

02/28/2024 02:06:45 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:06:51 - INFO - __main__ -   MSE:0.32234x10^(-5),	SQNR:54.82144dB 

02/28/2024 02:06:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:06:57 - INFO - __main__ -   MSE:1.05521x10^(-5),	SQNR:49.90769dB 

02/28/2024 02:06:57 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:07:02 - INFO - __main__ -   MSE:0.87830x10^(-5),	SQNR:50.59771dB 

02/28/2024 02:07:02 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:07:09 - INFO - __main__ -   MSE:8.29129x10^(-5),	SQNR:40.81491dB 

02/28/2024 02:07:09 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:07:15 - INFO - __main__ -   MSE:8.49608x10^(-5),	SQNR:40.56797dB 

02/28/2024 02:07:15 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:07:22 - INFO - __main__ -   MSE:1.97108x10^(-5),	SQNR:47.16559dB 

02/28/2024 02:07:22 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:07:28 - INFO - __main__ -   MSE:2.12662x10^(-5),	SQNR:46.59082dB 

02/28/2024 02:07:28 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:07:34 - INFO - __main__ -   MSE:8.06366x10^(-5),	SQNR:41.10205dB 

02/28/2024 02:07:34 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:07:40 - INFO - __main__ -   MSE:6.56881x10^(-5),	SQNR:41.70145dB 

02/28/2024 02:07:40 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:07:46 - INFO - __main__ -   MSE:0.01544x10^(-5),	SQNR:68.20329dB 

02/28/2024 02:07:46 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:07:54 - INFO - __main__ -   MSE:0.09197x10^(-5),	SQNR:60.85144dB 

02/28/2024 02:07:54 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:08:00 - INFO - __main__ -   MSE:0.51964x10^(-5),	SQNR:53.36462dB 

02/28/2024 02:08:00 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:08:06 - INFO - __main__ -   MSE:0.48765x10^(-5),	SQNR:54.12727dB 

02/28/2024 02:08:06 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:08:13 - INFO - __main__ -   MSE:8.59426x10^(-5),	SQNR:40.61166dB 

02/28/2024 02:08:13 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:08:18 - INFO - __main__ -   MSE:7.82650x10^(-5),	SQNR:41.04654dB 

02/28/2024 02:08:18 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:08:26 - INFO - __main__ -   MSE:1.97231x10^(-5),	SQNR:46.93095dB 

02/28/2024 02:08:26 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:08:32 - INFO - __main__ -   MSE:1.69270x10^(-5),	SQNR:47.52250dB 

02/28/2024 02:08:32 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:08:38 - INFO - __main__ -   MSE:9.19107x10^(-5),	SQNR:40.34665dB 

02/28/2024 02:08:38 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:08:44 - INFO - __main__ -   MSE:6.85235x10^(-5),	SQNR:41.48302dB 

02/28/2024 02:08:44 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:08:50 - INFO - __main__ -   MSE:0.00733x10^(-5),	SQNR:72.42561dB 

02/28/2024 02:08:50 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:08:57 - INFO - __main__ -   MSE:0.00748x10^(-5),	SQNR:71.50833dB 

02/28/2024 02:08:57 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:09:02 - INFO - __main__ -   MSE:0.13812x10^(-5),	SQNR:58.44976dB 

02/28/2024 02:09:02 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:09:10 - INFO - __main__ -   MSE:0.08565x10^(-5),	SQNR:60.60718dB 

02/28/2024 02:09:10 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:09:17 - INFO - __main__ -   MSE:9.82108x10^(-5),	SQNR:40.05782dB 

02/28/2024 02:09:17 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:09:23 - INFO - __main__ -   MSE:7.31566x10^(-5),	SQNR:41.21975dB 

02/28/2024 02:09:23 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:09:30 - INFO - __main__ -   MSE:2.52173x10^(-5),	SQNR:45.80961dB 

02/28/2024 02:09:30 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:09:36 - INFO - __main__ -   MSE:2.04945x10^(-5),	SQNR:46.74404dB 

02/28/2024 02:09:36 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:09:42 - INFO - __main__ -   MSE:5.04955x10^(-5),	SQNR:42.81934dB 

02/28/2024 02:09:42 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:09:47 - INFO - __main__ -   MSE:6.84205x10^(-5),	SQNR:41.63467dB 

02/28/2024 02:09:47 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:09:55 - INFO - __main__ -   MSE:0.00159x10^(-5),	SQNR:77.82452dB 

02/28/2024 02:09:55 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:10:00 - INFO - __main__ -   MSE:0.00416x10^(-5),	SQNR:73.71040dB 

02/28/2024 02:10:00 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:10:08 - INFO - __main__ -   MSE:0.04205x10^(-5),	SQNR:63.80968dB 

02/28/2024 02:10:08 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:10:15 - INFO - __main__ -   MSE:0.05048x10^(-5),	SQNR:63.43937dB 

02/28/2024 02:10:15 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:10:21 - INFO - __main__ -   MSE:8.60455x10^(-5),	SQNR:40.67593dB 

02/28/2024 02:10:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:10:28 - INFO - __main__ -   MSE:6.29575x10^(-5),	SQNR:41.85207dB 

02/28/2024 02:10:28 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:10:35 - INFO - __main__ -   MSE:2.27704x10^(-5),	SQNR:46.38667dB 

02/28/2024 02:10:35 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:10:40 - INFO - __main__ -   MSE:1.74711x10^(-5),	SQNR:47.49289dB 

02/28/2024 02:10:40 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:10:48 - INFO - __main__ -   MSE:4.90653x10^(-5),	SQNR:43.11179dB 

02/28/2024 02:10:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:10:53 - INFO - __main__ -   MSE:3.80804x10^(-5),	SQNR:44.22224dB 

02/28/2024 02:10:53 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:11:00 - INFO - __main__ -   MSE:0.00167x10^(-5),	SQNR:77.60824dB 

02/28/2024 02:11:00 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:11:06 - INFO - __main__ -   MSE:0.00373x10^(-5),	SQNR:74.84866dB 

02/28/2024 02:11:06 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:11:12 - INFO - __main__ -   MSE:0.04327x10^(-5),	SQNR:63.49556dB 

02/28/2024 02:11:12 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:11:18 - INFO - __main__ -   MSE:0.03638x10^(-5),	SQNR:64.25976dB 

02/28/2024 02:11:18 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:11:23 - INFO - __main__ -   MSE:7.61377x10^(-5),	SQNR:41.02843dB 

02/28/2024 02:11:23 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:11:32 - INFO - __main__ -   MSE:4.80298x10^(-5),	SQNR:43.09136dB 

02/28/2024 02:11:32 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:11:37 - INFO - __main__ -   MSE:0.86379x10^(-5),	SQNR:50.64685dB 

02/28/2024 02:11:37 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:11:43 - INFO - __main__ -   MSE:0.77512x10^(-5),	SQNR:51.17221dB 

02/28/2024 02:11:43 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:11:50 - INFO - __main__ -   MSE:2.62321x10^(-5),	SQNR:45.71236dB 

02/28/2024 02:11:50 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:11:56 - INFO - __main__ -   MSE:2.04319x10^(-5),	SQNR:46.84302dB 

02/28/2024 02:11:56 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:12:01 - INFO - __main__ -   MSE:0.00147x10^(-5),	SQNR:78.18307dB 

02/28/2024 02:12:01 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:12:07 - INFO - __main__ -   MSE:0.00151x10^(-5),	SQNR:78.21687dB 

02/28/2024 02:12:07 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:12:13 - INFO - __main__ -   MSE:0.01319x10^(-5),	SQNR:68.60339dB 

02/28/2024 02:12:13 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:12:18 - INFO - __main__ -   MSE:0.01145x10^(-5),	SQNR:69.41505dB 

02/28/2024 02:12:18 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:12:25 - INFO - __main__ -   MSE:8.69023x10^(-5),	SQNR:40.53871dB 

02/28/2024 02:12:25 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:12:31 - INFO - __main__ -   MSE:4.30209x10^(-5),	SQNR:43.64074dB 

02/28/2024 02:12:31 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:12:37 - INFO - __main__ -   MSE:1.19589x10^(-5),	SQNR:49.11242dB 

02/28/2024 02:12:37 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:12:45 - INFO - __main__ -   MSE:0.82909x10^(-5),	SQNR:50.73304dB 

02/28/2024 02:12:45 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:12:51 - INFO - __main__ -   MSE:2.39315x10^(-5),	SQNR:46.20939dB 

02/28/2024 02:12:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:12:57 - INFO - __main__ -   MSE:1.67878x10^(-5),	SQNR:47.58898dB 

02/28/2024 02:12:57 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:13:02 - INFO - __main__ -   MSE:0.00215x10^(-5),	SQNR:78.05080dB 

02/28/2024 02:13:02 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:13:10 - INFO - __main__ -   MSE:0.00083x10^(-5),	SQNR:80.64769dB 

02/28/2024 02:13:10 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:13:16 - INFO - __main__ -   MSE:0.00913x10^(-5),	SQNR:70.24005dB 

02/28/2024 02:13:16 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:13:21 - INFO - __main__ -   MSE:0.00834x10^(-5),	SQNR:70.98941dB 

02/28/2024 02:13:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:13:30 - INFO - __main__ -   MSE:8.29220x10^(-5),	SQNR:40.77601dB 

02/28/2024 02:13:30 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:13:37 - INFO - __main__ -   MSE:3.73516x10^(-5),	SQNR:44.23065dB 

02/28/2024 02:13:37 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:13:42 - INFO - __main__ -   MSE:1.54470x10^(-5),	SQNR:47.99309dB 

02/28/2024 02:13:42 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:13:51 - INFO - __main__ -   MSE:1.28278x10^(-5),	SQNR:49.07514dB 

02/28/2024 02:13:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:13:56 - INFO - __main__ -   MSE:2.50307x10^(-5),	SQNR:45.87860dB 

02/28/2024 02:13:56 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:14:01 - INFO - __main__ -   MSE:1.38410x10^(-5),	SQNR:48.52739dB 

02/28/2024 02:14:01 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:14:08 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.72256dB 

02/28/2024 02:14:08 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:14:14 - INFO - __main__ -   MSE:0.00099x10^(-5),	SQNR:79.94585dB 

02/28/2024 02:14:14 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:14:20 - INFO - __main__ -   MSE:0.01018x10^(-5),	SQNR:69.98543dB 

02/28/2024 02:14:20 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:14:25 - INFO - __main__ -   MSE:0.00918x10^(-5),	SQNR:70.54295dB 

02/28/2024 02:14:25 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:14:32 - INFO - __main__ -   MSE:7.10528x10^(-5),	SQNR:41.33936dB 

02/28/2024 02:14:32 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:14:39 - INFO - __main__ -   MSE:3.56527x10^(-5),	SQNR:44.44552dB 

02/28/2024 02:14:39 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:14:44 - INFO - __main__ -   MSE:1.30098x10^(-5),	SQNR:48.97465dB 

02/28/2024 02:14:44 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:14:51 - INFO - __main__ -   MSE:1.33979x10^(-5),	SQNR:48.77216dB 

02/28/2024 02:14:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:14:58 - INFO - __main__ -   MSE:2.25588x10^(-5),	SQNR:46.38609dB 

02/28/2024 02:14:58 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:15:02 - INFO - __main__ -   MSE:1.03155x10^(-5),	SQNR:49.82312dB 

02/28/2024 02:15:02 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:15:10 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.59709dB 

02/28/2024 02:15:10 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:15:16 - INFO - __main__ -   MSE:0.00063x10^(-5),	SQNR:81.80421dB 

02/28/2024 02:15:16 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:15:21 - INFO - __main__ -   MSE:0.00337x10^(-5),	SQNR:74.62275dB 

02/28/2024 02:15:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:15:26 - INFO - __main__ -   MSE:0.00545x10^(-5),	SQNR:72.54900dB 

02/28/2024 02:15:26 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:15:33 - INFO - __main__ -   MSE:6.35350x10^(-5),	SQNR:41.89405dB 

02/28/2024 02:15:34 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:15:38 - INFO - __main__ -   MSE:2.21510x10^(-5),	SQNR:46.41771dB 

02/28/2024 02:15:38 - INFO - __main__ -   model.mid_block.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 02:15:44 - INFO - __main__ -   MSE:14.29775x10^(-5),	SQNR:38.35085dB 

02/28/2024 02:15:44 - INFO - __main__ -   model.mid_block.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 02:15:50 - INFO - __main__ -   MSE:40.01156x10^(-5),	SQNR:33.79737dB 

02/28/2024 02:15:50 - INFO - __main__ -   model.mid_block.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:15:56 - INFO - __main__ -   MSE:3.79232x10^(-5),	SQNR:44.34993dB 

02/28/2024 02:15:56 - INFO - __main__ -   model.mid_block.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 02:16:01 - INFO - __main__ -   MSE:37.43805x10^(-5),	SQNR:34.18278dB 

02/28/2024 02:16:01 - INFO - __main__ -   model.mid_block.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 02:16:10 - INFO - __main__ -   MSE:15.22156x10^(-5),	SQNR:38.03860dB 

02/28/2024 02:16:10 - INFO - __main__ -   model.mid_block.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:16:17 - INFO - __main__ -   MSE:1.30259x10^(-5),	SQNR:48.68965dB 

02/28/2024 02:16:17 - INFO - __main__ -   model.mid_block.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 02:16:22 - INFO - __main__ -   MSE:19.78630x10^(-5),	SQNR:36.88178dB 

02/28/2024 02:16:22 - INFO - __main__ -   model.conv_out: weight_quant=True, act_quant=False
02/28/2024 02:16:28 - INFO - __main__ -   MSE:16206.57129x10^(-5),	SQNR:7.70516dB 

02/28/2024 02:16:28 - INFO - __main__ -   
the bit width is 4!

02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.conv_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.time_embedding.linear_1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.time_embedding.linear_2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.add_embedding.linear_1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.add_embedding.linear_2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.0.downsamplers.0.conv.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.1.downsamplers.0.conv.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.0.upsamplers.0.conv.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.1.upsamplers.0.conv.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv_shortcut.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.proj_in.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.proj_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.conv1.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.time_emb_proj.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.conv2.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - qdiff.models.quant_model -   model.conv_out.weight_quantizer: weight_quant=4
02/28/2024 02:16:28 - INFO - __main__ -   ################# Start to quantize the layers one by one #################
02/28/2024 02:16:28 - INFO - __main__ -   model.conv_in: weight_quant=True, act_quant=False
02/28/2024 02:16:35 - INFO - __main__ -   MSE:30.01046x10^(-5),	SQNR:35.05618dB 

02/28/2024 02:16:35 - INFO - __main__ -   model.time_embedding.linear_1: weight_quant=True, act_quant=False
02/28/2024 02:16:40 - INFO - __main__ -   MSE:0.06613x10^(-5),	SQNR:62.13661dB 

02/28/2024 02:16:40 - INFO - __main__ -   model.time_embedding.linear_2: weight_quant=True, act_quant=False
02/28/2024 02:16:48 - INFO - __main__ -   MSE:0.42711x10^(-5),	SQNR:53.56496dB 

02/28/2024 02:16:48 - INFO - __main__ -   model.add_embedding.linear_1: weight_quant=True, act_quant=False
02/28/2024 02:16:55 - INFO - __main__ -   MSE:13.52276x10^(-5),	SQNR:38.59379dB 

02/28/2024 02:16:55 - INFO - __main__ -   model.add_embedding.linear_2: weight_quant=True, act_quant=False
02/28/2024 02:17:02 - INFO - __main__ -   MSE:1.57303x10^(-5),	SQNR:48.12559dB 

02/28/2024 02:17:02 - INFO - __main__ -   model.down_blocks.0.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 02:17:09 - INFO - __main__ -   MSE:0.64091x10^(-5),	SQNR:52.15459dB 

02/28/2024 02:17:09 - INFO - __main__ -   model.down_blocks.0.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:17:15 - INFO - __main__ -   MSE:2.68815x10^(-5),	SQNR:45.79455dB 

02/28/2024 02:17:15 - INFO - __main__ -   model.down_blocks.0.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 02:17:21 - INFO - __main__ -   MSE:7.65756x10^(-5),	SQNR:41.03705dB 

02/28/2024 02:17:21 - INFO - __main__ -   model.down_blocks.0.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 02:17:27 - INFO - __main__ -   MSE:2.22937x10^(-5),	SQNR:46.92274dB 

02/28/2024 02:17:27 - INFO - __main__ -   model.down_blocks.0.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:17:34 - INFO - __main__ -   MSE:0.41361x10^(-5),	SQNR:53.77515dB 

02/28/2024 02:17:34 - INFO - __main__ -   model.down_blocks.0.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 02:17:39 - INFO - __main__ -   MSE:2.55517x10^(-5),	SQNR:45.74012dB 

02/28/2024 02:17:39 - INFO - __main__ -   model.down_blocks.0.downsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 02:17:46 - INFO - __main__ -   MSE:8.68684x10^(-5),	SQNR:40.54213dB 

02/28/2024 02:17:46 - INFO - __main__ -   model.down_blocks.1.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 02:17:53 - INFO - __main__ -   MSE:1.73253x10^(-5),	SQNR:47.46212dB 

02/28/2024 02:17:53 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:17:59 - INFO - __main__ -   MSE:0.02359x10^(-5),	SQNR:66.32386dB 

02/28/2024 02:17:59 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:18:04 - INFO - __main__ -   MSE:0.03548x10^(-5),	SQNR:64.55627dB 

02/28/2024 02:18:04 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:18:11 - INFO - __main__ -   MSE:0.34969x10^(-5),	SQNR:54.55838dB 

02/28/2024 02:18:11 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:18:15 - INFO - __main__ -   MSE:0.32479x10^(-5),	SQNR:55.18384dB 

02/28/2024 02:18:15 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:18:22 - INFO - __main__ -   MSE:0.00529x10^(-5),	SQNR:73.24258dB 

02/28/2024 02:18:22 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:18:28 - INFO - __main__ -   MSE:0.01571x10^(-5),	SQNR:68.11652dB 

02/28/2024 02:18:28 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:18:35 - INFO - __main__ -   MSE:0.04258x10^(-5),	SQNR:63.98095dB 

02/28/2024 02:18:35 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:18:39 - INFO - __main__ -   MSE:0.02579x10^(-5),	SQNR:65.79822dB 

02/28/2024 02:18:39 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:18:45 - INFO - __main__ -   MSE:0.59983x10^(-5),	SQNR:52.11299dB 

02/28/2024 02:18:45 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:18:52 - INFO - __main__ -   MSE:0.46824x10^(-5),	SQNR:53.55849dB 

02/28/2024 02:18:52 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:18:58 - INFO - __main__ -   MSE:0.02656x10^(-5),	SQNR:66.24265dB 

02/28/2024 02:18:58 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:19:04 - INFO - __main__ -   MSE:0.03637x10^(-5),	SQNR:64.58138dB 

02/28/2024 02:19:04 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:19:10 - INFO - __main__ -   MSE:0.71641x10^(-5),	SQNR:51.45441dB 

02/28/2024 02:19:10 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:19:16 - INFO - __main__ -   MSE:0.18932x10^(-5),	SQNR:57.07989dB 

02/28/2024 02:19:16 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:19:21 - INFO - __main__ -   MSE:0.00182x10^(-5),	SQNR:77.33766dB 

02/28/2024 02:19:21 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:19:27 - INFO - __main__ -   MSE:0.00196x10^(-5),	SQNR:77.03906dB 

02/28/2024 02:19:27 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:19:34 - INFO - __main__ -   MSE:0.01032x10^(-5),	SQNR:70.23447dB 

02/28/2024 02:19:34 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:19:39 - INFO - __main__ -   MSE:0.00535x10^(-5),	SQNR:72.68240dB 

02/28/2024 02:19:39 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:19:45 - INFO - __main__ -   MSE:0.80074x10^(-5),	SQNR:51.08833dB 

02/28/2024 02:19:45 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:19:53 - INFO - __main__ -   MSE:0.38364x10^(-5),	SQNR:54.23341dB 

02/28/2024 02:19:53 - INFO - __main__ -   model.down_blocks.1.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 02:19:59 - INFO - __main__ -   MSE:1.05592x10^(-5),	SQNR:49.86107dB 

02/28/2024 02:19:59 - INFO - __main__ -   model.down_blocks.1.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 02:20:04 - INFO - __main__ -   MSE:1.17312x10^(-5),	SQNR:49.51981dB 

02/28/2024 02:20:05 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:20:11 - INFO - __main__ -   MSE:0.00764x10^(-5),	SQNR:71.07396dB 

02/28/2024 02:20:11 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:20:16 - INFO - __main__ -   MSE:0.01742x10^(-5),	SQNR:67.62134dB 

02/28/2024 02:20:16 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:20:22 - INFO - __main__ -   MSE:0.44496x10^(-5),	SQNR:53.55753dB 

02/28/2024 02:20:22 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:20:28 - INFO - __main__ -   MSE:0.13085x10^(-5),	SQNR:58.96095dB 

02/28/2024 02:20:28 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:20:34 - INFO - __main__ -   MSE:0.00073x10^(-5),	SQNR:81.20244dB 

02/28/2024 02:20:34 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:20:38 - INFO - __main__ -   MSE:0.00087x10^(-5),	SQNR:80.66257dB 

02/28/2024 02:20:38 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:20:44 - INFO - __main__ -   MSE:0.00421x10^(-5),	SQNR:73.63781dB 

02/28/2024 02:20:44 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:20:51 - INFO - __main__ -   MSE:0.00267x10^(-5),	SQNR:75.59837dB 

02/28/2024 02:20:51 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:20:57 - INFO - __main__ -   MSE:0.26239x10^(-5),	SQNR:56.23791dB 

02/28/2024 02:20:57 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:21:02 - INFO - __main__ -   MSE:0.09541x10^(-5),	SQNR:60.31812dB 

02/28/2024 02:21:02 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:21:10 - INFO - __main__ -   MSE:0.01053x10^(-5),	SQNR:69.76562dB 

02/28/2024 02:21:10 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:21:17 - INFO - __main__ -   MSE:0.00404x10^(-5),	SQNR:73.82612dB 

02/28/2024 02:21:17 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:21:22 - INFO - __main__ -   MSE:0.61902x10^(-5),	SQNR:52.08269dB 

02/28/2024 02:21:22 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:21:27 - INFO - __main__ -   MSE:0.09943x10^(-5),	SQNR:59.95305dB 

02/28/2024 02:21:27 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:21:33 - INFO - __main__ -   MSE:0.00086x10^(-5),	SQNR:80.48848dB 

02/28/2024 02:21:33 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:21:38 - INFO - __main__ -   MSE:0.00119x10^(-5),	SQNR:79.18298dB 

02/28/2024 02:21:38 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:21:43 - INFO - __main__ -   MSE:0.00566x10^(-5),	SQNR:72.36816dB 

02/28/2024 02:21:43 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:21:48 - INFO - __main__ -   MSE:0.00267x10^(-5),	SQNR:75.63152dB 

02/28/2024 02:21:48 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:21:54 - INFO - __main__ -   MSE:0.25507x10^(-5),	SQNR:55.76026dB 

02/28/2024 02:21:54 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:21:59 - INFO - __main__ -   MSE:0.14480x10^(-5),	SQNR:58.52604dB 

02/28/2024 02:21:59 - INFO - __main__ -   model.down_blocks.1.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 02:22:07 - INFO - __main__ -   MSE:3.83200x10^(-5),	SQNR:44.10619dB 

02/28/2024 02:22:07 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 02:22:13 - INFO - __main__ -   MSE:1.65330x10^(-5),	SQNR:47.91474dB 

02/28/2024 02:22:13 - INFO - __main__ -   model.down_blocks.1.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:22:19 - INFO - __main__ -   MSE:0.90235x10^(-5),	SQNR:50.47144dB 

02/28/2024 02:22:19 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 02:22:25 - INFO - __main__ -   MSE:1.56240x10^(-5),	SQNR:48.08104dB 

02/28/2024 02:22:25 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 02:22:32 - INFO - __main__ -   MSE:3.06419x10^(-5),	SQNR:45.01779dB 

02/28/2024 02:22:32 - INFO - __main__ -   model.down_blocks.1.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 02:22:38 - INFO - __main__ -   MSE:1.44717x10^(-5),	SQNR:48.52747dB 

02/28/2024 02:22:38 - INFO - __main__ -   model.down_blocks.1.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:22:43 - INFO - __main__ -   MSE:0.31050x10^(-5),	SQNR:55.12262dB 

02/28/2024 02:22:43 - INFO - __main__ -   model.down_blocks.1.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 02:22:52 - INFO - __main__ -   MSE:2.40701x10^(-5),	SQNR:46.21233dB 

02/28/2024 02:22:52 - INFO - __main__ -   model.down_blocks.1.downsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 02:22:57 - INFO - __main__ -   MSE:4.32460x10^(-5),	SQNR:43.57536dB 

02/28/2024 02:22:57 - INFO - __main__ -   model.down_blocks.2.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 02:23:02 - INFO - __main__ -   MSE:1.38934x10^(-5),	SQNR:48.62529dB 

02/28/2024 02:23:02 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:23:09 - INFO - __main__ -   MSE:0.04980x10^(-5),	SQNR:64.00455dB 

02/28/2024 02:23:09 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:23:14 - INFO - __main__ -   MSE:0.03477x10^(-5),	SQNR:65.04300dB 

02/28/2024 02:23:14 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:23:19 - INFO - __main__ -   MSE:0.12867x10^(-5),	SQNR:59.07574dB 

02/28/2024 02:23:19 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:23:25 - INFO - __main__ -   MSE:0.25645x10^(-5),	SQNR:55.84677dB 

02/28/2024 02:23:25 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:23:32 - INFO - __main__ -   MSE:0.00579x10^(-5),	SQNR:72.69070dB 

02/28/2024 02:23:32 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:23:38 - INFO - __main__ -   MSE:0.03118x10^(-5),	SQNR:65.53089dB 

02/28/2024 02:23:38 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:23:44 - INFO - __main__ -   MSE:0.05683x10^(-5),	SQNR:62.75948dB 

02/28/2024 02:23:44 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:23:51 - INFO - __main__ -   MSE:0.05995x10^(-5),	SQNR:62.99057dB 

02/28/2024 02:23:52 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:23:58 - INFO - __main__ -   MSE:0.14736x10^(-5),	SQNR:58.44747dB 

02/28/2024 02:23:58 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:24:04 - INFO - __main__ -   MSE:0.14696x10^(-5),	SQNR:58.33410dB 

02/28/2024 02:24:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:24:11 - INFO - __main__ -   MSE:0.00299x10^(-5),	SQNR:75.07491dB 

02/28/2024 02:24:11 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:24:16 - INFO - __main__ -   MSE:0.00575x10^(-5),	SQNR:73.00371dB 

02/28/2024 02:24:17 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:24:22 - INFO - __main__ -   MSE:0.05320x10^(-5),	SQNR:63.16377dB 

02/28/2024 02:24:22 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:24:28 - INFO - __main__ -   MSE:0.03544x10^(-5),	SQNR:64.72006dB 

02/28/2024 02:24:28 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:24:35 - INFO - __main__ -   MSE:0.00515x10^(-5),	SQNR:73.16094dB 

02/28/2024 02:24:35 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:24:40 - INFO - __main__ -   MSE:0.03464x10^(-5),	SQNR:65.22299dB 

02/28/2024 02:24:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:24:46 - INFO - __main__ -   MSE:0.12389x10^(-5),	SQNR:60.42503dB 

02/28/2024 02:24:46 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:24:53 - INFO - __main__ -   MSE:0.07548x10^(-5),	SQNR:61.34245dB 

02/28/2024 02:24:53 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:24:58 - INFO - __main__ -   MSE:0.13151x10^(-5),	SQNR:59.07631dB 

02/28/2024 02:24:58 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:25:04 - INFO - __main__ -   MSE:0.19138x10^(-5),	SQNR:57.39871dB 

02/28/2024 02:25:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:25:11 - INFO - __main__ -   MSE:0.01587x10^(-5),	SQNR:68.62844dB 

02/28/2024 02:25:11 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:25:16 - INFO - __main__ -   MSE:0.00604x10^(-5),	SQNR:72.64093dB 

02/28/2024 02:25:16 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:25:21 - INFO - __main__ -   MSE:0.07739x10^(-5),	SQNR:61.08899dB 

02/28/2024 02:25:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:25:28 - INFO - __main__ -   MSE:0.05648x10^(-5),	SQNR:62.53074dB 

02/28/2024 02:25:28 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:25:33 - INFO - __main__ -   MSE:0.00364x10^(-5),	SQNR:75.97814dB 

02/28/2024 02:25:33 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:25:39 - INFO - __main__ -   MSE:0.00554x10^(-5),	SQNR:73.65788dB 

02/28/2024 02:25:39 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:25:44 - INFO - __main__ -   MSE:0.22372x10^(-5),	SQNR:57.82919dB 

02/28/2024 02:25:44 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:25:50 - INFO - __main__ -   MSE:0.05166x10^(-5),	SQNR:62.86040dB 

02/28/2024 02:25:50 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:25:56 - INFO - __main__ -   MSE:0.14380x10^(-5),	SQNR:58.50124dB 

02/28/2024 02:25:56 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:26:01 - INFO - __main__ -   MSE:0.10658x10^(-5),	SQNR:59.93938dB 

02/28/2024 02:26:01 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:26:05 - INFO - __main__ -   MSE:0.01077x10^(-5),	SQNR:69.84100dB 

02/28/2024 02:26:05 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:26:12 - INFO - __main__ -   MSE:0.01061x10^(-5),	SQNR:69.82314dB 

02/28/2024 02:26:12 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:26:17 - INFO - __main__ -   MSE:0.15506x10^(-5),	SQNR:58.63975dB 

02/28/2024 02:26:17 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:26:21 - INFO - __main__ -   MSE:0.06773x10^(-5),	SQNR:61.53316dB 

02/28/2024 02:26:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:26:29 - INFO - __main__ -   MSE:0.00118x10^(-5),	SQNR:79.19334dB 

02/28/2024 02:26:29 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:26:34 - INFO - __main__ -   MSE:0.00250x10^(-5),	SQNR:76.22119dB 

02/28/2024 02:26:34 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:26:40 - INFO - __main__ -   MSE:0.03092x10^(-5),	SQNR:65.13133dB 

02/28/2024 02:26:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:26:45 - INFO - __main__ -   MSE:0.02745x10^(-5),	SQNR:65.73260dB 

02/28/2024 02:26:45 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:26:52 - INFO - __main__ -   MSE:0.16310x10^(-5),	SQNR:57.70186dB 

02/28/2024 02:26:52 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:26:59 - INFO - __main__ -   MSE:0.14375x10^(-5),	SQNR:59.03587dB 

02/28/2024 02:26:59 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:27:04 - INFO - __main__ -   MSE:0.00336x10^(-5),	SQNR:74.63225dB 

02/28/2024 02:27:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:27:12 - INFO - __main__ -   MSE:0.00411x10^(-5),	SQNR:73.85896dB 

02/28/2024 02:27:12 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:27:19 - INFO - __main__ -   MSE:0.09109x10^(-5),	SQNR:60.59089dB 

02/28/2024 02:27:19 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:27:23 - INFO - __main__ -   MSE:0.03843x10^(-5),	SQNR:64.46527dB 

02/28/2024 02:27:23 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:27:30 - INFO - __main__ -   MSE:0.00083x10^(-5),	SQNR:80.77780dB 

02/28/2024 02:27:30 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:27:36 - INFO - __main__ -   MSE:0.00324x10^(-5),	SQNR:75.25505dB 

02/28/2024 02:27:36 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:27:40 - INFO - __main__ -   MSE:0.01677x10^(-5),	SQNR:67.75822dB 

02/28/2024 02:27:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:27:45 - INFO - __main__ -   MSE:0.01203x10^(-5),	SQNR:69.75089dB 

02/28/2024 02:27:45 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:27:52 - INFO - __main__ -   MSE:0.12161x10^(-5),	SQNR:59.58495dB 

02/28/2024 02:27:52 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:27:56 - INFO - __main__ -   MSE:0.22684x10^(-5),	SQNR:56.96584dB 

02/28/2024 02:27:56 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:28:02 - INFO - __main__ -   MSE:0.00449x10^(-5),	SQNR:73.56334dB 

02/28/2024 02:28:02 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:28:09 - INFO - __main__ -   MSE:0.00776x10^(-5),	SQNR:71.91337dB 

02/28/2024 02:28:09 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:28:14 - INFO - __main__ -   MSE:0.06237x10^(-5),	SQNR:62.43347dB 

02/28/2024 02:28:14 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:28:19 - INFO - __main__ -   MSE:0.03172x10^(-5),	SQNR:65.04585dB 

02/28/2024 02:28:19 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:28:27 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.51073dB 

02/28/2024 02:28:27 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:28:32 - INFO - __main__ -   MSE:0.00064x10^(-5),	SQNR:81.73225dB 

02/28/2024 02:28:33 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:28:39 - INFO - __main__ -   MSE:0.00400x10^(-5),	SQNR:74.13867dB 

02/28/2024 02:28:39 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:28:43 - INFO - __main__ -   MSE:0.00214x10^(-5),	SQNR:76.97397dB 

02/28/2024 02:28:43 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:28:52 - INFO - __main__ -   MSE:0.25747x10^(-5),	SQNR:57.11978dB 

02/28/2024 02:28:52 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:28:59 - INFO - __main__ -   MSE:0.11688x10^(-5),	SQNR:59.53460dB 

02/28/2024 02:28:59 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:29:04 - INFO - __main__ -   MSE:0.00257x10^(-5),	SQNR:75.81201dB 

02/28/2024 02:29:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:29:11 - INFO - __main__ -   MSE:0.00408x10^(-5),	SQNR:74.36362dB 

02/28/2024 02:29:11 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:29:18 - INFO - __main__ -   MSE:0.04238x10^(-5),	SQNR:63.92143dB 

02/28/2024 02:29:18 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:29:22 - INFO - __main__ -   MSE:0.02360x10^(-5),	SQNR:66.11416dB 

02/28/2024 02:29:22 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:29:30 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.90107dB 

02/28/2024 02:29:30 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:29:35 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.42123dB 

02/28/2024 02:29:35 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:29:40 - INFO - __main__ -   MSE:0.00099x10^(-5),	SQNR:80.03740dB 

02/28/2024 02:29:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:29:45 - INFO - __main__ -   MSE:0.00132x10^(-5),	SQNR:78.69485dB 

02/28/2024 02:29:45 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:29:52 - INFO - __main__ -   MSE:0.16877x10^(-5),	SQNR:57.96045dB 

02/28/2024 02:29:52 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:29:57 - INFO - __main__ -   MSE:0.10620x10^(-5),	SQNR:59.72010dB 

02/28/2024 02:29:57 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:30:04 - INFO - __main__ -   MSE:0.00391x10^(-5),	SQNR:73.99973dB 

02/28/2024 02:30:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:30:10 - INFO - __main__ -   MSE:0.00540x10^(-5),	SQNR:72.83260dB 

02/28/2024 02:30:10 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:30:16 - INFO - __main__ -   MSE:0.03992x10^(-5),	SQNR:63.89260dB 

02/28/2024 02:30:16 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:30:20 - INFO - __main__ -   MSE:0.01729x10^(-5),	SQNR:68.01324dB 

02/28/2024 02:30:20 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:30:26 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.82402dB 

02/28/2024 02:30:26 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:30:33 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.86803dB 

02/28/2024 02:30:33 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:30:40 - INFO - __main__ -   MSE:0.00171x10^(-5),	SQNR:77.65608dB 

02/28/2024 02:30:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:30:45 - INFO - __main__ -   MSE:0.00131x10^(-5),	SQNR:78.89742dB 

02/28/2024 02:30:45 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:30:54 - INFO - __main__ -   MSE:0.13805x10^(-5),	SQNR:58.80708dB 

02/28/2024 02:30:54 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:30:59 - INFO - __main__ -   MSE:0.06631x10^(-5),	SQNR:61.60234dB 

02/28/2024 02:30:59 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:31:04 - INFO - __main__ -   MSE:0.00258x10^(-5),	SQNR:76.44358dB 

02/28/2024 02:31:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:31:09 - INFO - __main__ -   MSE:0.00175x10^(-5),	SQNR:77.80353dB 

02/28/2024 02:31:10 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:31:16 - INFO - __main__ -   MSE:0.04641x10^(-5),	SQNR:63.41420dB 

02/28/2024 02:31:16 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:31:20 - INFO - __main__ -   MSE:0.01254x10^(-5),	SQNR:68.98270dB 

02/28/2024 02:31:20 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:31:25 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.74004dB 

02/28/2024 02:31:25 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:31:31 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.80859dB 

02/28/2024 02:31:31 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:31:37 - INFO - __main__ -   MSE:0.00233x10^(-5),	SQNR:76.73530dB 

02/28/2024 02:31:37 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:31:41 - INFO - __main__ -   MSE:0.00170x10^(-5),	SQNR:77.97121dB 

02/28/2024 02:31:41 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:31:48 - INFO - __main__ -   MSE:0.20366x10^(-5),	SQNR:56.80460dB 

02/28/2024 02:31:48 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:31:54 - INFO - __main__ -   MSE:0.09459x10^(-5),	SQNR:60.13496dB 

02/28/2024 02:31:54 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:32:00 - INFO - __main__ -   MSE:0.00642x10^(-5),	SQNR:72.09448dB 

02/28/2024 02:32:00 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:32:06 - INFO - __main__ -   MSE:0.00485x10^(-5),	SQNR:73.23590dB 

02/28/2024 02:32:06 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:32:11 - INFO - __main__ -   MSE:0.07122x10^(-5),	SQNR:61.42129dB 

02/28/2024 02:32:11 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:32:17 - INFO - __main__ -   MSE:0.01559x10^(-5),	SQNR:67.99026dB 

02/28/2024 02:32:17 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:32:22 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.66198dB 

02/28/2024 02:32:22 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:32:27 - INFO - __main__ -   MSE:0.00067x10^(-5),	SQNR:81.62526dB 

02/28/2024 02:32:27 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:32:35 - INFO - __main__ -   MSE:0.00478x10^(-5),	SQNR:73.31105dB 

02/28/2024 02:32:35 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:32:40 - INFO - __main__ -   MSE:0.00227x10^(-5),	SQNR:76.51868dB 

02/28/2024 02:32:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:32:45 - INFO - __main__ -   MSE:0.27016x10^(-5),	SQNR:55.88324dB 

02/28/2024 02:32:45 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:32:52 - INFO - __main__ -   MSE:0.10797x10^(-5),	SQNR:59.59211dB 

02/28/2024 02:32:52 - INFO - __main__ -   model.down_blocks.2.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 02:32:58 - INFO - __main__ -   MSE:1.86206x10^(-5),	SQNR:47.39181dB 

02/28/2024 02:32:58 - INFO - __main__ -   model.down_blocks.2.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 02:33:03 - INFO - __main__ -   MSE:4.15339x10^(-5),	SQNR:43.90233dB 

02/28/2024 02:33:03 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:33:09 - INFO - __main__ -   MSE:0.01472x10^(-5),	SQNR:68.47660dB 

02/28/2024 02:33:09 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:33:15 - INFO - __main__ -   MSE:0.02999x10^(-5),	SQNR:66.10663dB 

02/28/2024 02:33:15 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:33:19 - INFO - __main__ -   MSE:0.46260x10^(-5),	SQNR:53.40504dB 

02/28/2024 02:33:19 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:33:24 - INFO - __main__ -   MSE:0.70482x10^(-5),	SQNR:52.26103dB 

02/28/2024 02:33:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:33:31 - INFO - __main__ -   MSE:0.04774x10^(-5),	SQNR:63.75545dB 

02/28/2024 02:33:31 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:33:37 - INFO - __main__ -   MSE:0.18898x10^(-5),	SQNR:57.07660dB 

02/28/2024 02:33:37 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:33:43 - INFO - __main__ -   MSE:1.52182x10^(-5),	SQNR:48.01168dB 

02/28/2024 02:33:43 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:33:49 - INFO - __main__ -   MSE:1.18283x10^(-5),	SQNR:49.43296dB 

02/28/2024 02:33:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:33:56 - INFO - __main__ -   MSE:0.87050x10^(-5),	SQNR:50.64469dB 

02/28/2024 02:33:56 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:34:02 - INFO - __main__ -   MSE:0.51711x10^(-5),	SQNR:52.99557dB 

02/28/2024 02:34:02 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:34:08 - INFO - __main__ -   MSE:0.03533x10^(-5),	SQNR:65.27299dB 

02/28/2024 02:34:08 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:34:15 - INFO - __main__ -   MSE:0.03850x10^(-5),	SQNR:64.48128dB 

02/28/2024 02:34:15 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:34:20 - INFO - __main__ -   MSE:0.67207x10^(-5),	SQNR:51.95955dB 

02/28/2024 02:34:20 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:34:25 - INFO - __main__ -   MSE:0.99229x10^(-5),	SQNR:50.15291dB 

02/28/2024 02:34:26 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:34:32 - INFO - __main__ -   MSE:0.21635x10^(-5),	SQNR:56.72891dB 

02/28/2024 02:34:33 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:34:39 - INFO - __main__ -   MSE:0.58422x10^(-5),	SQNR:52.62022dB 

02/28/2024 02:34:39 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:34:44 - INFO - __main__ -   MSE:3.09310x10^(-5),	SQNR:45.36066dB 

02/28/2024 02:34:44 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:34:51 - INFO - __main__ -   MSE:1.80545x10^(-5),	SQNR:47.38760dB 

02/28/2024 02:34:51 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:34:57 - INFO - __main__ -   MSE:1.55886x10^(-5),	SQNR:48.36163dB 

02/28/2024 02:34:57 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:35:03 - INFO - __main__ -   MSE:1.17479x10^(-5),	SQNR:49.29760dB 

02/28/2024 02:35:03 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:35:09 - INFO - __main__ -   MSE:0.05063x10^(-5),	SQNR:63.08420dB 

02/28/2024 02:35:09 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:35:16 - INFO - __main__ -   MSE:0.11104x10^(-5),	SQNR:62.06352dB 

02/28/2024 02:35:16 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:35:20 - INFO - __main__ -   MSE:1.40642x10^(-5),	SQNR:48.52283dB 

02/28/2024 02:35:20 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:35:27 - INFO - __main__ -   MSE:0.68037x10^(-5),	SQNR:51.81830dB 

02/28/2024 02:35:27 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:35:34 - INFO - __main__ -   MSE:0.45859x10^(-5),	SQNR:54.50304dB 

02/28/2024 02:35:34 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:35:38 - INFO - __main__ -   MSE:0.96987x10^(-5),	SQNR:51.93604dB 

02/28/2024 02:35:38 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:35:43 - INFO - __main__ -   MSE:1.61017x10^(-5),	SQNR:48.22153dB 

02/28/2024 02:35:43 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:35:48 - INFO - __main__ -   MSE:1.39818x10^(-5),	SQNR:48.56664dB 

02/28/2024 02:35:48 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:35:54 - INFO - __main__ -   MSE:2.07359x10^(-5),	SQNR:47.02777dB 

02/28/2024 02:35:54 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:35:59 - INFO - __main__ -   MSE:1.76905x10^(-5),	SQNR:47.75488dB 

02/28/2024 02:35:59 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:36:05 - INFO - __main__ -   MSE:0.06771x10^(-5),	SQNR:62.31656dB 

02/28/2024 02:36:05 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:36:12 - INFO - __main__ -   MSE:0.05812x10^(-5),	SQNR:62.46391dB 

02/28/2024 02:36:12 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:36:16 - INFO - __main__ -   MSE:1.09971x10^(-5),	SQNR:50.23307dB 

02/28/2024 02:36:16 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:36:22 - INFO - __main__ -   MSE:0.42470x10^(-5),	SQNR:53.58711dB 

02/28/2024 02:36:22 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:36:28 - INFO - __main__ -   MSE:0.17183x10^(-5),	SQNR:58.14356dB 

02/28/2024 02:36:28 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:36:33 - INFO - __main__ -   MSE:0.16903x10^(-5),	SQNR:57.81158dB 

02/28/2024 02:36:33 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:36:39 - INFO - __main__ -   MSE:1.09469x10^(-5),	SQNR:50.03708dB 

02/28/2024 02:36:39 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:36:43 - INFO - __main__ -   MSE:0.84177x10^(-5),	SQNR:51.70052dB 

02/28/2024 02:36:43 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:36:50 - INFO - __main__ -   MSE:2.83652x10^(-5),	SQNR:45.38677dB 

02/28/2024 02:36:50 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:36:57 - INFO - __main__ -   MSE:2.18530x10^(-5),	SQNR:46.66418dB 

02/28/2024 02:36:57 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:37:02 - INFO - __main__ -   MSE:0.04157x10^(-5),	SQNR:63.81063dB 

02/28/2024 02:37:02 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:37:11 - INFO - __main__ -   MSE:0.05742x10^(-5),	SQNR:63.41358dB 

02/28/2024 02:37:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:37:17 - INFO - __main__ -   MSE:0.88322x10^(-5),	SQNR:51.24081dB 

02/28/2024 02:37:17 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:37:21 - INFO - __main__ -   MSE:0.36083x10^(-5),	SQNR:54.55394dB 

02/28/2024 02:37:21 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:37:26 - INFO - __main__ -   MSE:0.08345x10^(-5),	SQNR:61.74183dB 

02/28/2024 02:37:26 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:37:34 - INFO - __main__ -   MSE:0.11817x10^(-5),	SQNR:59.96951dB 

02/28/2024 02:37:34 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:37:38 - INFO - __main__ -   MSE:0.78786x10^(-5),	SQNR:51.10541dB 

02/28/2024 02:37:38 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:37:43 - INFO - __main__ -   MSE:0.64890x10^(-5),	SQNR:52.48054dB 

02/28/2024 02:37:43 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:37:49 - INFO - __main__ -   MSE:5.16039x10^(-5),	SQNR:42.75726dB 

02/28/2024 02:37:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:37:55 - INFO - __main__ -   MSE:2.86569x10^(-5),	SQNR:45.51228dB 

02/28/2024 02:37:55 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:38:00 - INFO - __main__ -   MSE:0.07611x10^(-5),	SQNR:61.95068dB 

02/28/2024 02:38:00 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:38:05 - INFO - __main__ -   MSE:0.07734x10^(-5),	SQNR:61.31095dB 

02/28/2024 02:38:06 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:38:12 - INFO - __main__ -   MSE:0.90688x10^(-5),	SQNR:50.58086dB 

02/28/2024 02:38:12 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:38:16 - INFO - __main__ -   MSE:0.33958x10^(-5),	SQNR:54.91613dB 

02/28/2024 02:38:16 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:38:24 - INFO - __main__ -   MSE:0.06180x10^(-5),	SQNR:62.65005dB 

02/28/2024 02:38:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:38:30 - INFO - __main__ -   MSE:0.26194x10^(-5),	SQNR:59.63116dB 

02/28/2024 02:38:30 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:38:38 - INFO - __main__ -   MSE:0.68533x10^(-5),	SQNR:52.01693dB 

02/28/2024 02:38:38 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:38:42 - INFO - __main__ -   MSE:0.60642x10^(-5),	SQNR:52.26125dB 

02/28/2024 02:38:43 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:38:49 - INFO - __main__ -   MSE:3.70903x10^(-5),	SQNR:44.15885dB 

02/28/2024 02:38:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:38:55 - INFO - __main__ -   MSE:3.13351x10^(-5),	SQNR:45.03687dB 

02/28/2024 02:38:55 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:39:00 - INFO - __main__ -   MSE:0.03571x10^(-5),	SQNR:64.48949dB 

02/28/2024 02:39:00 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:39:05 - INFO - __main__ -   MSE:0.09532x10^(-5),	SQNR:61.03421dB 

02/28/2024 02:39:05 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:39:13 - INFO - __main__ -   MSE:0.74721x10^(-5),	SQNR:51.54499dB 

02/28/2024 02:39:13 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:39:18 - INFO - __main__ -   MSE:0.37404x10^(-5),	SQNR:54.29561dB 

02/28/2024 02:39:18 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:39:22 - INFO - __main__ -   MSE:0.00617x10^(-5),	SQNR:72.32526dB 

02/28/2024 02:39:22 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:39:29 - INFO - __main__ -   MSE:0.01398x10^(-5),	SQNR:68.85264dB 

02/28/2024 02:39:29 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:39:34 - INFO - __main__ -   MSE:0.14383x10^(-5),	SQNR:58.51049dB 

02/28/2024 02:39:34 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:39:39 - INFO - __main__ -   MSE:0.14959x10^(-5),	SQNR:59.66968dB 

02/28/2024 02:39:39 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:39:44 - INFO - __main__ -   MSE:4.04419x10^(-5),	SQNR:44.58622dB 

02/28/2024 02:39:44 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:39:52 - INFO - __main__ -   MSE:3.72298x10^(-5),	SQNR:44.40568dB 

02/28/2024 02:39:52 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:39:57 - INFO - __main__ -   MSE:0.11801x10^(-5),	SQNR:59.89478dB 

02/28/2024 02:39:57 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:40:04 - INFO - __main__ -   MSE:0.05715x10^(-5),	SQNR:63.27283dB 

02/28/2024 02:40:04 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:40:11 - INFO - __main__ -   MSE:0.44813x10^(-5),	SQNR:53.45981dB 

02/28/2024 02:40:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:40:17 - INFO - __main__ -   MSE:0.31517x10^(-5),	SQNR:55.24164dB 

02/28/2024 02:40:17 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:40:22 - INFO - __main__ -   MSE:0.00964x10^(-5),	SQNR:71.93224dB 

02/28/2024 02:40:22 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:40:27 - INFO - __main__ -   MSE:0.01393x10^(-5),	SQNR:69.32729dB 

02/28/2024 02:40:27 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:40:34 - INFO - __main__ -   MSE:0.17701x10^(-5),	SQNR:57.98373dB 

02/28/2024 02:40:34 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:40:40 - INFO - __main__ -   MSE:0.11230x10^(-5),	SQNR:59.63128dB 

02/28/2024 02:40:40 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:40:45 - INFO - __main__ -   MSE:4.13697x10^(-5),	SQNR:43.65353dB 

02/28/2024 02:40:45 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:40:53 - INFO - __main__ -   MSE:2.94138x10^(-5),	SQNR:45.46429dB 

02/28/2024 02:40:53 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:40:58 - INFO - __main__ -   MSE:0.09869x10^(-5),	SQNR:60.76896dB 

02/28/2024 02:40:58 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:41:03 - INFO - __main__ -   MSE:0.07974x10^(-5),	SQNR:61.18627dB 

02/28/2024 02:41:03 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:41:09 - INFO - __main__ -   MSE:0.42164x10^(-5),	SQNR:53.75039dB 

02/28/2024 02:41:09 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:41:14 - INFO - __main__ -   MSE:0.30671x10^(-5),	SQNR:55.17781dB 

02/28/2024 02:41:14 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:41:19 - INFO - __main__ -   MSE:0.00480x10^(-5),	SQNR:74.13992dB 

02/28/2024 02:41:19 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:41:25 - INFO - __main__ -   MSE:0.01229x10^(-5),	SQNR:70.04834dB 

02/28/2024 02:41:25 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:41:30 - INFO - __main__ -   MSE:0.08718x10^(-5),	SQNR:60.65033dB 

02/28/2024 02:41:30 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:41:35 - INFO - __main__ -   MSE:0.05351x10^(-5),	SQNR:62.55867dB 

02/28/2024 02:41:35 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:41:40 - INFO - __main__ -   MSE:3.86973x10^(-5),	SQNR:44.00218dB 

02/28/2024 02:41:40 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:41:48 - INFO - __main__ -   MSE:1.56640x10^(-5),	SQNR:47.93223dB 

02/28/2024 02:41:48 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:41:54 - INFO - __main__ -   MSE:0.13280x10^(-5),	SQNR:58.84620dB 

02/28/2024 02:41:54 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:42:00 - INFO - __main__ -   MSE:0.11033x10^(-5),	SQNR:59.81948dB 

02/28/2024 02:42:00 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:42:06 - INFO - __main__ -   MSE:0.33942x10^(-5),	SQNR:54.91528dB 

02/28/2024 02:42:06 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:42:12 - INFO - __main__ -   MSE:0.23778x10^(-5),	SQNR:56.39020dB 

02/28/2024 02:42:12 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:42:19 - INFO - __main__ -   MSE:0.00090x10^(-5),	SQNR:80.42200dB 

02/28/2024 02:42:19 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:42:24 - INFO - __main__ -   MSE:0.00179x10^(-5),	SQNR:77.58806dB 

02/28/2024 02:42:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:42:30 - INFO - __main__ -   MSE:0.01124x10^(-5),	SQNR:69.88095dB 

02/28/2024 02:42:30 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:42:35 - INFO - __main__ -   MSE:0.01174x10^(-5),	SQNR:69.66195dB 

02/28/2024 02:42:35 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:42:40 - INFO - __main__ -   MSE:3.95629x10^(-5),	SQNR:43.94957dB 

02/28/2024 02:42:40 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:42:45 - INFO - __main__ -   MSE:0.60804x10^(-5),	SQNR:52.09125dB 

02/28/2024 02:42:45 - INFO - __main__ -   model.down_blocks.2.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 02:42:53 - INFO - __main__ -   MSE:2.64879x10^(-5),	SQNR:45.74936dB 

02/28/2024 02:42:53 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 02:42:58 - INFO - __main__ -   MSE:0.98035x10^(-5),	SQNR:50.19004dB 

02/28/2024 02:42:58 - INFO - __main__ -   model.down_blocks.2.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:43:03 - INFO - __main__ -   MSE:1.76060x10^(-5),	SQNR:47.63787dB 

02/28/2024 02:43:03 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 02:43:11 - INFO - __main__ -   MSE:1.00802x10^(-5),	SQNR:50.30256dB 

02/28/2024 02:43:11 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 02:43:16 - INFO - __main__ -   MSE:2.12015x10^(-5),	SQNR:46.61089dB 

02/28/2024 02:43:16 - INFO - __main__ -   model.down_blocks.2.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 02:43:21 - INFO - __main__ -   MSE:2.10515x10^(-5),	SQNR:46.72211dB 

02/28/2024 02:43:21 - INFO - __main__ -   model.down_blocks.2.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 02:43:28 - INFO - __main__ -   MSE:3.82260x10^(-5),	SQNR:44.39095dB 

02/28/2024 02:43:28 - INFO - __main__ -   model.down_blocks.2.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 02:43:34 - INFO - __main__ -   MSE:1.97132x10^(-5),	SQNR:47.07989dB 

02/28/2024 02:43:34 - INFO - __main__ -   model.up_blocks.0.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 02:43:39 - INFO - __main__ -   MSE:1.93457x10^(-5),	SQNR:47.18145dB 

02/28/2024 02:43:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:43:45 - INFO - __main__ -   MSE:0.08949x10^(-5),	SQNR:60.39010dB 

02/28/2024 02:43:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:43:52 - INFO - __main__ -   MSE:0.07589x10^(-5),	SQNR:61.39154dB 

02/28/2024 02:43:52 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:43:57 - INFO - __main__ -   MSE:0.47877x10^(-5),	SQNR:53.21076dB 

02/28/2024 02:43:57 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:44:02 - INFO - __main__ -   MSE:1.09069x10^(-5),	SQNR:49.56781dB 

02/28/2024 02:44:02 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:44:09 - INFO - __main__ -   MSE:0.00305x10^(-5),	SQNR:74.99667dB 

02/28/2024 02:44:09 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:44:14 - INFO - __main__ -   MSE:0.01105x10^(-5),	SQNR:69.89179dB 

02/28/2024 02:44:14 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:44:21 - INFO - __main__ -   MSE:0.09063x10^(-5),	SQNR:60.53012dB 

02/28/2024 02:44:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:44:26 - INFO - __main__ -   MSE:0.06758x10^(-5),	SQNR:61.71025dB 

02/28/2024 02:44:26 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:44:33 - INFO - __main__ -   MSE:0.52267x10^(-5),	SQNR:52.72108dB 

02/28/2024 02:44:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:44:39 - INFO - __main__ -   MSE:0.62564x10^(-5),	SQNR:51.86293dB 

02/28/2024 02:44:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:44:44 - INFO - __main__ -   MSE:0.06974x10^(-5),	SQNR:61.48576dB 

02/28/2024 02:44:44 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:44:50 - INFO - __main__ -   MSE:0.06455x10^(-5),	SQNR:62.03506dB 

02/28/2024 02:44:50 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:44:57 - INFO - __main__ -   MSE:0.58582x10^(-5),	SQNR:52.31229dB 

02/28/2024 02:44:57 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:45:01 - INFO - __main__ -   MSE:0.69872x10^(-5),	SQNR:51.44696dB 

02/28/2024 02:45:01 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:45:10 - INFO - __main__ -   MSE:0.00845x10^(-5),	SQNR:71.06070dB 

02/28/2024 02:45:10 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:45:15 - INFO - __main__ -   MSE:0.02047x10^(-5),	SQNR:67.21044dB 

02/28/2024 02:45:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:45:21 - INFO - __main__ -   MSE:0.16898x10^(-5),	SQNR:57.71996dB 

02/28/2024 02:45:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:45:26 - INFO - __main__ -   MSE:0.18249x10^(-5),	SQNR:57.24231dB 

02/28/2024 02:45:26 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:45:33 - INFO - __main__ -   MSE:0.85354x10^(-5),	SQNR:50.56558dB 

02/28/2024 02:45:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:45:39 - INFO - __main__ -   MSE:0.97698x10^(-5),	SQNR:50.08051dB 

02/28/2024 02:45:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:45:44 - INFO - __main__ -   MSE:0.08319x10^(-5),	SQNR:61.00795dB 

02/28/2024 02:45:44 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:45:52 - INFO - __main__ -   MSE:0.07313x10^(-5),	SQNR:61.37657dB 

02/28/2024 02:45:53 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:45:59 - INFO - __main__ -   MSE:0.42358x10^(-5),	SQNR:53.58652dB 

02/28/2024 02:45:59 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:46:04 - INFO - __main__ -   MSE:0.38718x10^(-5),	SQNR:54.07066dB 

02/28/2024 02:46:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:46:10 - INFO - __main__ -   MSE:0.01822x10^(-5),	SQNR:67.25918dB 

02/28/2024 02:46:10 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:46:16 - INFO - __main__ -   MSE:0.03303x10^(-5),	SQNR:64.87989dB 

02/28/2024 02:46:16 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:46:21 - INFO - __main__ -   MSE:0.15416x10^(-5),	SQNR:58.13568dB 

02/28/2024 02:46:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:46:25 - INFO - __main__ -   MSE:0.12571x10^(-5),	SQNR:58.90601dB 

02/28/2024 02:46:25 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:46:32 - INFO - __main__ -   MSE:1.08293x10^(-5),	SQNR:49.56682dB 

02/28/2024 02:46:32 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:46:37 - INFO - __main__ -   MSE:0.82543x10^(-5),	SQNR:50.70058dB 

02/28/2024 02:46:37 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:46:42 - INFO - __main__ -   MSE:0.07955x10^(-5),	SQNR:61.06177dB 

02/28/2024 02:46:42 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:46:49 - INFO - __main__ -   MSE:0.07361x10^(-5),	SQNR:61.24025dB 

02/28/2024 02:46:49 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:46:55 - INFO - __main__ -   MSE:0.44213x10^(-5),	SQNR:53.41594dB 

02/28/2024 02:46:55 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:46:59 - INFO - __main__ -   MSE:0.31623x10^(-5),	SQNR:54.86641dB 

02/28/2024 02:46:59 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:47:04 - INFO - __main__ -   MSE:0.01091x10^(-5),	SQNR:69.55524dB 

02/28/2024 02:47:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:47:12 - INFO - __main__ -   MSE:0.01114x10^(-5),	SQNR:69.41950dB 

02/28/2024 02:47:12 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:47:17 - INFO - __main__ -   MSE:0.08096x10^(-5),	SQNR:60.81079dB 

02/28/2024 02:47:17 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:47:21 - INFO - __main__ -   MSE:0.05211x10^(-5),	SQNR:62.77459dB 

02/28/2024 02:47:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:47:28 - INFO - __main__ -   MSE:1.02952x10^(-5),	SQNR:49.76977dB 

02/28/2024 02:47:28 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:47:33 - INFO - __main__ -   MSE:0.83105x10^(-5),	SQNR:50.65709dB 

02/28/2024 02:47:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:47:38 - INFO - __main__ -   MSE:0.05755x10^(-5),	SQNR:62.32569dB 

02/28/2024 02:47:38 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:47:45 - INFO - __main__ -   MSE:0.07609x10^(-5),	SQNR:61.49673dB 

02/28/2024 02:47:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:47:52 - INFO - __main__ -   MSE:0.31696x10^(-5),	SQNR:54.85950dB 

02/28/2024 02:47:52 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:47:58 - INFO - __main__ -   MSE:0.24654x10^(-5),	SQNR:55.95452dB 

02/28/2024 02:47:58 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:48:04 - INFO - __main__ -   MSE:0.00296x10^(-5),	SQNR:75.26399dB 

02/28/2024 02:48:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:48:10 - INFO - __main__ -   MSE:0.00372x10^(-5),	SQNR:74.31653dB 

02/28/2024 02:48:10 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:48:16 - INFO - __main__ -   MSE:0.03898x10^(-5),	SQNR:64.03299dB 

02/28/2024 02:48:16 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:48:21 - INFO - __main__ -   MSE:0.02144x10^(-5),	SQNR:66.54082dB 

02/28/2024 02:48:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:48:26 - INFO - __main__ -   MSE:1.03916x10^(-5),	SQNR:49.71811dB 

02/28/2024 02:48:26 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:48:33 - INFO - __main__ -   MSE:0.82427x10^(-5),	SQNR:50.65408dB 

02/28/2024 02:48:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:48:38 - INFO - __main__ -   MSE:0.06001x10^(-5),	SQNR:62.16206dB 

02/28/2024 02:48:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:48:43 - INFO - __main__ -   MSE:0.05803x10^(-5),	SQNR:62.41854dB 

02/28/2024 02:48:43 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:48:50 - INFO - __main__ -   MSE:0.27087x10^(-5),	SQNR:55.56696dB 

02/28/2024 02:48:50 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:48:55 - INFO - __main__ -   MSE:0.17009x10^(-5),	SQNR:57.53195dB 

02/28/2024 02:48:55 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:49:00 - INFO - __main__ -   MSE:0.00171x10^(-5),	SQNR:77.48988dB 

02/28/2024 02:49:00 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:49:04 - INFO - __main__ -   MSE:0.00216x10^(-5),	SQNR:76.55186dB 

02/28/2024 02:49:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:49:11 - INFO - __main__ -   MSE:0.02196x10^(-5),	SQNR:66.54045dB 

02/28/2024 02:49:11 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:49:15 - INFO - __main__ -   MSE:0.01405x10^(-5),	SQNR:68.47327dB 

02/28/2024 02:49:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:49:20 - INFO - __main__ -   MSE:1.14626x10^(-5),	SQNR:49.24566dB 

02/28/2024 02:49:20 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:49:27 - INFO - __main__ -   MSE:0.73042x10^(-5),	SQNR:51.22517dB 

02/28/2024 02:49:27 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:49:33 - INFO - __main__ -   MSE:0.04595x10^(-5),	SQNR:63.29333dB 

02/28/2024 02:49:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:49:37 - INFO - __main__ -   MSE:0.03885x10^(-5),	SQNR:63.94110dB 

02/28/2024 02:49:37 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:49:44 - INFO - __main__ -   MSE:0.17245x10^(-5),	SQNR:57.48925dB 

02/28/2024 02:49:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:49:50 - INFO - __main__ -   MSE:0.11886x10^(-5),	SQNR:59.06678dB 

02/28/2024 02:49:50 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:49:57 - INFO - __main__ -   MSE:0.00090x10^(-5),	SQNR:80.36327dB 

02/28/2024 02:49:57 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:50:02 - INFO - __main__ -   MSE:0.00107x10^(-5),	SQNR:79.50751dB 

02/28/2024 02:50:02 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:50:07 - INFO - __main__ -   MSE:0.01113x10^(-5),	SQNR:69.46246dB 

02/28/2024 02:50:07 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:50:14 - INFO - __main__ -   MSE:0.00617x10^(-5),	SQNR:71.98789dB 

02/28/2024 02:50:14 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:50:20 - INFO - __main__ -   MSE:1.14039x10^(-5),	SQNR:49.34364dB 

02/28/2024 02:50:20 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:50:26 - INFO - __main__ -   MSE:0.75484x10^(-5),	SQNR:51.05575dB 

02/28/2024 02:50:26 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:50:34 - INFO - __main__ -   MSE:0.04919x10^(-5),	SQNR:62.91896dB 

02/28/2024 02:50:34 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:50:39 - INFO - __main__ -   MSE:0.05095x10^(-5),	SQNR:63.01062dB 

02/28/2024 02:50:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:50:45 - INFO - __main__ -   MSE:0.11946x10^(-5),	SQNR:59.08312dB 

02/28/2024 02:50:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:50:51 - INFO - __main__ -   MSE:0.08353x10^(-5),	SQNR:60.65289dB 

02/28/2024 02:50:51 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:50:56 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.64453dB 

02/28/2024 02:50:56 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:51:00 - INFO - __main__ -   MSE:0.00080x10^(-5),	SQNR:80.82051dB 

02/28/2024 02:51:00 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:51:07 - INFO - __main__ -   MSE:0.00582x10^(-5),	SQNR:72.16177dB 

02/28/2024 02:51:07 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:51:12 - INFO - __main__ -   MSE:0.00400x10^(-5),	SQNR:73.88486dB 

02/28/2024 02:51:12 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:51:17 - INFO - __main__ -   MSE:1.10546x10^(-5),	SQNR:49.38343dB 

02/28/2024 02:51:17 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:51:22 - INFO - __main__ -   MSE:0.43694x10^(-5),	SQNR:53.45988dB 

02/28/2024 02:51:22 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:51:29 - INFO - __main__ -   MSE:0.05534x10^(-5),	SQNR:62.60764dB 

02/28/2024 02:51:29 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:51:34 - INFO - __main__ -   MSE:0.05295x10^(-5),	SQNR:62.62009dB 

02/28/2024 02:51:34 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:51:38 - INFO - __main__ -   MSE:0.12096x10^(-5),	SQNR:59.00141dB 

02/28/2024 02:51:38 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:51:45 - INFO - __main__ -   MSE:0.06243x10^(-5),	SQNR:61.91618dB 

02/28/2024 02:51:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:51:51 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.94008dB 

02/28/2024 02:51:51 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:51:57 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.12375dB 

02/28/2024 02:51:57 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:52:05 - INFO - __main__ -   MSE:0.00355x10^(-5),	SQNR:74.31570dB 

02/28/2024 02:52:05 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:52:09 - INFO - __main__ -   MSE:0.00223x10^(-5),	SQNR:76.35592dB 

02/28/2024 02:52:09 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:52:15 - INFO - __main__ -   MSE:0.95045x10^(-5),	SQNR:50.05123dB 

02/28/2024 02:52:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:52:20 - INFO - __main__ -   MSE:0.28938x10^(-5),	SQNR:55.23366dB 

02/28/2024 02:52:20 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:52:25 - INFO - __main__ -   MSE:0.04247x10^(-5),	SQNR:63.56694dB 

02/28/2024 02:52:25 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:52:32 - INFO - __main__ -   MSE:0.04296x10^(-5),	SQNR:63.58065dB 

02/28/2024 02:52:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:52:37 - INFO - __main__ -   MSE:0.08198x10^(-5),	SQNR:60.70201dB 

02/28/2024 02:52:37 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:52:43 - INFO - __main__ -   MSE:0.04077x10^(-5),	SQNR:63.92899dB 

02/28/2024 02:52:43 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:52:51 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.49458dB 

02/28/2024 02:52:51 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:52:55 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.03382dB 

02/28/2024 02:52:56 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:53:00 - INFO - __main__ -   MSE:0.00233x10^(-5),	SQNR:76.83986dB 

02/28/2024 02:53:00 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:53:07 - INFO - __main__ -   MSE:0.00110x10^(-5),	SQNR:79.40997dB 

02/28/2024 02:53:07 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:53:12 - INFO - __main__ -   MSE:0.67851x10^(-5),	SQNR:51.56715dB 

02/28/2024 02:53:12 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:53:17 - INFO - __main__ -   MSE:0.14060x10^(-5),	SQNR:58.40416dB 

02/28/2024 02:53:17 - INFO - __main__ -   model.up_blocks.0.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 02:53:23 - INFO - __main__ -   MSE:0.58332x10^(-5),	SQNR:52.19511dB 

02/28/2024 02:53:23 - INFO - __main__ -   model.up_blocks.0.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 02:53:30 - INFO - __main__ -   MSE:1.06250x10^(-5),	SQNR:49.67225dB 

02/28/2024 02:53:30 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:53:35 - INFO - __main__ -   MSE:0.02352x10^(-5),	SQNR:66.18839dB 

02/28/2024 02:53:35 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:53:40 - INFO - __main__ -   MSE:0.02492x10^(-5),	SQNR:65.86456dB 

02/28/2024 02:53:40 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:53:48 - INFO - __main__ -   MSE:0.18507x10^(-5),	SQNR:57.18840dB 

02/28/2024 02:53:48 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:53:52 - INFO - __main__ -   MSE:0.33461x10^(-5),	SQNR:54.59819dB 

02/28/2024 02:53:52 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:53:58 - INFO - __main__ -   MSE:0.00204x10^(-5),	SQNR:77.18492dB 

02/28/2024 02:53:58 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:54:04 - INFO - __main__ -   MSE:0.00524x10^(-5),	SQNR:72.93330dB 

02/28/2024 02:54:04 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:54:10 - INFO - __main__ -   MSE:0.03101x10^(-5),	SQNR:64.99397dB 

02/28/2024 02:54:11 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:54:15 - INFO - __main__ -   MSE:0.02044x10^(-5),	SQNR:66.87410dB 

02/28/2024 02:54:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:54:20 - INFO - __main__ -   MSE:0.25633x10^(-5),	SQNR:55.79165dB 

02/28/2024 02:54:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:54:27 - INFO - __main__ -   MSE:0.39024x10^(-5),	SQNR:53.97868dB 

02/28/2024 02:54:27 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:54:32 - INFO - __main__ -   MSE:0.02154x10^(-5),	SQNR:66.64597dB 

02/28/2024 02:54:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:54:38 - INFO - __main__ -   MSE:0.01589x10^(-5),	SQNR:67.83238dB 

02/28/2024 02:54:38 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:54:45 - INFO - __main__ -   MSE:0.21879x10^(-5),	SQNR:56.44143dB 

02/28/2024 02:54:45 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:54:51 - INFO - __main__ -   MSE:0.23866x10^(-5),	SQNR:56.06300dB 

02/28/2024 02:54:51 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:54:57 - INFO - __main__ -   MSE:0.01295x10^(-5),	SQNR:68.81361dB 

02/28/2024 02:54:57 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:55:02 - INFO - __main__ -   MSE:0.03219x10^(-5),	SQNR:65.08496dB 

02/28/2024 02:55:02 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:55:10 - INFO - __main__ -   MSE:0.13416x10^(-5),	SQNR:58.54374dB 

02/28/2024 02:55:10 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:55:14 - INFO - __main__ -   MSE:0.08038x10^(-5),	SQNR:60.82143dB 

02/28/2024 02:55:14 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:55:19 - INFO - __main__ -   MSE:0.34296x10^(-5),	SQNR:54.52928dB 

02/28/2024 02:55:19 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:55:28 - INFO - __main__ -   MSE:0.32819x10^(-5),	SQNR:54.67513dB 

02/28/2024 02:55:28 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:55:33 - INFO - __main__ -   MSE:0.01817x10^(-5),	SQNR:67.26382dB 

02/28/2024 02:55:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:55:39 - INFO - __main__ -   MSE:0.01457x10^(-5),	SQNR:68.23277dB 

02/28/2024 02:55:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:55:45 - INFO - __main__ -   MSE:0.21446x10^(-5),	SQNR:56.56905dB 

02/28/2024 02:55:45 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:55:52 - INFO - __main__ -   MSE:0.13907x10^(-5),	SQNR:58.42988dB 

02/28/2024 02:55:52 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:55:58 - INFO - __main__ -   MSE:0.00862x10^(-5),	SQNR:70.62499dB 

02/28/2024 02:55:58 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:56:04 - INFO - __main__ -   MSE:0.02092x10^(-5),	SQNR:66.79308dB 

02/28/2024 02:56:04 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:56:10 - INFO - __main__ -   MSE:0.12661x10^(-5),	SQNR:58.86754dB 

02/28/2024 02:56:10 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:56:16 - INFO - __main__ -   MSE:0.09294x10^(-5),	SQNR:60.14252dB 

02/28/2024 02:56:16 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:56:21 - INFO - __main__ -   MSE:0.45447x10^(-5),	SQNR:53.26528dB 

02/28/2024 02:56:21 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:56:28 - INFO - __main__ -   MSE:0.35152x10^(-5),	SQNR:54.40340dB 

02/28/2024 02:56:28 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:56:34 - INFO - __main__ -   MSE:0.02553x10^(-5),	SQNR:65.78722dB 

02/28/2024 02:56:34 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:56:39 - INFO - __main__ -   MSE:0.02141x10^(-5),	SQNR:66.51800dB 

02/28/2024 02:56:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:56:45 - INFO - __main__ -   MSE:0.20321x10^(-5),	SQNR:56.75029dB 

02/28/2024 02:56:45 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:56:51 - INFO - __main__ -   MSE:0.13172x10^(-5),	SQNR:58.61116dB 

02/28/2024 02:56:51 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:56:56 - INFO - __main__ -   MSE:0.03546x10^(-5),	SQNR:66.45036dB 

02/28/2024 02:56:56 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:57:01 - INFO - __main__ -   MSE:0.05075x10^(-5),	SQNR:64.87142dB 

02/28/2024 02:57:01 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:57:07 - INFO - __main__ -   MSE:0.07548x10^(-5),	SQNR:61.11144dB 

02/28/2024 02:57:07 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:57:12 - INFO - __main__ -   MSE:0.05766x10^(-5),	SQNR:62.33546dB 

02/28/2024 02:57:12 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:57:17 - INFO - __main__ -   MSE:0.59604x10^(-5),	SQNR:52.05817dB 

02/28/2024 02:57:17 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:57:23 - INFO - __main__ -   MSE:0.33315x10^(-5),	SQNR:54.62057dB 

02/28/2024 02:57:23 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:57:29 - INFO - __main__ -   MSE:0.02145x10^(-5),	SQNR:66.62978dB 

02/28/2024 02:57:29 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:57:34 - INFO - __main__ -   MSE:0.01863x10^(-5),	SQNR:67.23465dB 

02/28/2024 02:57:34 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:57:39 - INFO - __main__ -   MSE:0.19148x10^(-5),	SQNR:56.99702dB 

02/28/2024 02:57:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:57:45 - INFO - __main__ -   MSE:0.08725x10^(-5),	SQNR:60.40401dB 

02/28/2024 02:57:45 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:57:50 - INFO - __main__ -   MSE:0.00761x10^(-5),	SQNR:71.41975dB 

02/28/2024 02:57:50 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:57:56 - INFO - __main__ -   MSE:0.00914x10^(-5),	SQNR:70.60411dB 

02/28/2024 02:57:56 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:58:03 - INFO - __main__ -   MSE:0.04563x10^(-5),	SQNR:63.37527dB 

02/28/2024 02:58:03 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:58:08 - INFO - __main__ -   MSE:0.03184x10^(-5),	SQNR:65.09732dB 

02/28/2024 02:58:08 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:58:15 - INFO - __main__ -   MSE:0.53445x10^(-5),	SQNR:52.57541dB 

02/28/2024 02:58:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:58:21 - INFO - __main__ -   MSE:0.32366x10^(-5),	SQNR:54.75715dB 

02/28/2024 02:58:22 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:58:28 - INFO - __main__ -   MSE:0.02325x10^(-5),	SQNR:66.21273dB 

02/28/2024 02:58:28 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:58:34 - INFO - __main__ -   MSE:0.01808x10^(-5),	SQNR:67.27558dB 

02/28/2024 02:58:34 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:58:39 - INFO - __main__ -   MSE:0.12673x10^(-5),	SQNR:58.84674dB 

02/28/2024 02:58:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:58:44 - INFO - __main__ -   MSE:0.08804x10^(-5),	SQNR:60.44677dB 

02/28/2024 02:58:44 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:58:51 - INFO - __main__ -   MSE:0.00529x10^(-5),	SQNR:73.89317dB 

02/28/2024 02:58:51 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:58:55 - INFO - __main__ -   MSE:0.00329x10^(-5),	SQNR:74.66772dB 

02/28/2024 02:58:55 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:59:00 - INFO - __main__ -   MSE:0.03104x10^(-5),	SQNR:64.93629dB 

02/28/2024 02:59:00 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:59:07 - INFO - __main__ -   MSE:0.01508x10^(-5),	SQNR:68.29141dB 

02/28/2024 02:59:07 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 02:59:11 - INFO - __main__ -   MSE:0.55581x10^(-5),	SQNR:52.37021dB 

02/28/2024 02:59:11 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 02:59:16 - INFO - __main__ -   MSE:0.30987x10^(-5),	SQNR:54.90556dB 

02/28/2024 02:59:16 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 02:59:23 - INFO - __main__ -   MSE:0.02644x10^(-5),	SQNR:65.61446dB 

02/28/2024 02:59:23 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 02:59:28 - INFO - __main__ -   MSE:0.02050x10^(-5),	SQNR:66.82678dB 

02/28/2024 02:59:28 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 02:59:33 - INFO - __main__ -   MSE:0.12795x10^(-5),	SQNR:58.79581dB 

02/28/2024 02:59:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 02:59:38 - INFO - __main__ -   MSE:0.06372x10^(-5),	SQNR:61.77321dB 

02/28/2024 02:59:38 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 02:59:44 - INFO - __main__ -   MSE:0.00166x10^(-5),	SQNR:77.93723dB 

02/28/2024 02:59:44 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 02:59:50 - INFO - __main__ -   MSE:0.00294x10^(-5),	SQNR:75.39394dB 

02/28/2024 02:59:50 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 02:59:56 - INFO - __main__ -   MSE:0.01352x10^(-5),	SQNR:68.56685dB 

02/28/2024 02:59:56 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:00:02 - INFO - __main__ -   MSE:0.00732x10^(-5),	SQNR:71.20274dB 

02/28/2024 03:00:02 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:00:08 - INFO - __main__ -   MSE:0.51895x10^(-5),	SQNR:52.66689dB 

02/28/2024 03:00:08 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:00:15 - INFO - __main__ -   MSE:0.28322x10^(-5),	SQNR:55.32610dB 

02/28/2024 03:00:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:00:22 - INFO - __main__ -   MSE:0.02193x10^(-5),	SQNR:66.64106dB 

02/28/2024 03:00:22 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:00:29 - INFO - __main__ -   MSE:0.01348x10^(-5),	SQNR:68.52856dB 

02/28/2024 03:00:29 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:00:34 - INFO - __main__ -   MSE:0.05498x10^(-5),	SQNR:62.42626dB 

02/28/2024 03:00:34 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:00:38 - INFO - __main__ -   MSE:0.04896x10^(-5),	SQNR:62.92542dB 

02/28/2024 03:00:38 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:00:45 - INFO - __main__ -   MSE:0.00065x10^(-5),	SQNR:81.67888dB 

02/28/2024 03:00:45 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:00:50 - INFO - __main__ -   MSE:0.00077x10^(-5),	SQNR:80.96329dB 

02/28/2024 03:00:50 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:00:55 - INFO - __main__ -   MSE:0.00609x10^(-5),	SQNR:71.99032dB 

02/28/2024 03:00:55 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:01:01 - INFO - __main__ -   MSE:0.00394x10^(-5),	SQNR:73.87000dB 

02/28/2024 03:01:01 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:01:07 - INFO - __main__ -   MSE:0.45792x10^(-5),	SQNR:53.25214dB 

02/28/2024 03:01:07 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:01:12 - INFO - __main__ -   MSE:0.24860x10^(-5),	SQNR:55.86334dB 

02/28/2024 03:01:12 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:01:18 - INFO - __main__ -   MSE:0.04398x10^(-5),	SQNR:63.38377dB 

02/28/2024 03:01:18 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:01:24 - INFO - __main__ -   MSE:0.03318x10^(-5),	SQNR:64.75342dB 

02/28/2024 03:01:24 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:01:29 - INFO - __main__ -   MSE:0.05842x10^(-5),	SQNR:62.14188dB 

02/28/2024 03:01:29 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:01:33 - INFO - __main__ -   MSE:0.05481x10^(-5),	SQNR:62.47762dB 

02/28/2024 03:01:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:01:41 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.86246dB 

02/28/2024 03:01:41 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:01:47 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.42400dB 

02/28/2024 03:01:47 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:01:53 - INFO - __main__ -   MSE:0.00226x10^(-5),	SQNR:76.27509dB 

02/28/2024 03:01:53 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:01:57 - INFO - __main__ -   MSE:0.00184x10^(-5),	SQNR:77.20840dB 

02/28/2024 03:01:57 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:02:04 - INFO - __main__ -   MSE:0.39380x10^(-5),	SQNR:53.86127dB 

02/28/2024 03:02:04 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:02:09 - INFO - __main__ -   MSE:0.14940x10^(-5),	SQNR:58.11191dB 

02/28/2024 03:02:09 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:02:15 - INFO - __main__ -   MSE:0.03112x10^(-5),	SQNR:64.88063dB 

02/28/2024 03:02:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:02:20 - INFO - __main__ -   MSE:0.02045x10^(-5),	SQNR:66.74644dB 

02/28/2024 03:02:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:02:27 - INFO - __main__ -   MSE:0.04575x10^(-5),	SQNR:63.24129dB 

02/28/2024 03:02:27 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:02:33 - INFO - __main__ -   MSE:0.02339x10^(-5),	SQNR:66.14136dB 

02/28/2024 03:02:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:02:39 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.86928dB 

02/28/2024 03:02:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:02:46 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.43262dB 

02/28/2024 03:02:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:02:51 - INFO - __main__ -   MSE:0.00102x10^(-5),	SQNR:79.72708dB 

02/28/2024 03:02:51 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:02:55 - INFO - __main__ -   MSE:0.00096x10^(-5),	SQNR:80.01315dB 

02/28/2024 03:02:55 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:03:02 - INFO - __main__ -   MSE:0.25720x10^(-5),	SQNR:55.72272dB 

02/28/2024 03:03:02 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:03:08 - INFO - __main__ -   MSE:0.07227x10^(-5),	SQNR:61.25125dB 

02/28/2024 03:03:08 - INFO - __main__ -   model.up_blocks.0.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:03:12 - INFO - __main__ -   MSE:0.40465x10^(-5),	SQNR:53.77485dB 

02/28/2024 03:03:13 - INFO - __main__ -   model.up_blocks.0.attentions.2.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:03:19 - INFO - __main__ -   MSE:0.68004x10^(-5),	SQNR:51.53536dB 

02/28/2024 03:03:19 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:03:25 - INFO - __main__ -   MSE:0.03175x10^(-5),	SQNR:64.90592dB 

02/28/2024 03:03:25 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:03:30 - INFO - __main__ -   MSE:0.02170x10^(-5),	SQNR:66.47975dB 

02/28/2024 03:03:30 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:03:34 - INFO - __main__ -   MSE:0.08418x10^(-5),	SQNR:60.55727dB 

02/28/2024 03:03:34 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:03:40 - INFO - __main__ -   MSE:0.19004x10^(-5),	SQNR:57.06810dB 

02/28/2024 03:03:40 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:03:46 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.14922dB 

02/28/2024 03:03:46 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:03:52 - INFO - __main__ -   MSE:0.00063x10^(-5),	SQNR:81.81860dB 

02/28/2024 03:03:52 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:03:57 - INFO - __main__ -   MSE:0.00357x10^(-5),	SQNR:74.37249dB 

02/28/2024 03:03:57 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:04:04 - INFO - __main__ -   MSE:0.00164x10^(-5),	SQNR:77.69705dB 

02/28/2024 03:04:04 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:04:10 - INFO - __main__ -   MSE:0.21098x10^(-5),	SQNR:56.62968dB 

02/28/2024 03:04:10 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:04:15 - INFO - __main__ -   MSE:0.17412x10^(-5),	SQNR:57.39783dB 

02/28/2024 03:04:15 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:04:21 - INFO - __main__ -   MSE:0.00879x10^(-5),	SQNR:70.39333dB 

02/28/2024 03:04:21 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:04:27 - INFO - __main__ -   MSE:0.00955x10^(-5),	SQNR:70.02785dB 

02/28/2024 03:04:27 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:04:32 - INFO - __main__ -   MSE:0.08569x10^(-5),	SQNR:60.52434dB 

02/28/2024 03:04:32 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:04:36 - INFO - __main__ -   MSE:0.06332x10^(-5),	SQNR:61.82473dB 

02/28/2024 03:04:36 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:04:44 - INFO - __main__ -   MSE:0.00061x10^(-5),	SQNR:81.98470dB 

02/28/2024 03:04:44 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:04:49 - INFO - __main__ -   MSE:0.00125x10^(-5),	SQNR:78.97508dB 

02/28/2024 03:04:49 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:04:53 - INFO - __main__ -   MSE:0.01768x10^(-5),	SQNR:67.37244dB 

02/28/2024 03:04:53 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:04:58 - INFO - __main__ -   MSE:0.00415x10^(-5),	SQNR:73.65332dB 

02/28/2024 03:04:58 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:05:05 - INFO - __main__ -   MSE:0.18390x10^(-5),	SQNR:57.23397dB 

02/28/2024 03:05:05 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:05:11 - INFO - __main__ -   MSE:0.14547x10^(-5),	SQNR:58.23167dB 

02/28/2024 03:05:11 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:05:17 - INFO - __main__ -   MSE:0.00953x10^(-5),	SQNR:70.06050dB 

02/28/2024 03:05:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:05:23 - INFO - __main__ -   MSE:0.00968x10^(-5),	SQNR:70.03548dB 

02/28/2024 03:05:23 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:05:29 - INFO - __main__ -   MSE:0.05613x10^(-5),	SQNR:62.34061dB 

02/28/2024 03:05:29 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:05:34 - INFO - __main__ -   MSE:0.04470x10^(-5),	SQNR:63.34130dB 

02/28/2024 03:05:34 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:05:40 - INFO - __main__ -   MSE:0.00060x10^(-5),	SQNR:82.01405dB 

02/28/2024 03:05:40 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:05:46 - INFO - __main__ -   MSE:0.00123x10^(-5),	SQNR:79.05715dB 

02/28/2024 03:05:46 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:05:51 - INFO - __main__ -   MSE:0.01109x10^(-5),	SQNR:69.38506dB 

02/28/2024 03:05:52 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:05:57 - INFO - __main__ -   MSE:0.00342x10^(-5),	SQNR:74.54673dB 

02/28/2024 03:05:57 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:06:04 - INFO - __main__ -   MSE:0.15369x10^(-5),	SQNR:58.01868dB 

02/28/2024 03:06:04 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:06:09 - INFO - __main__ -   MSE:0.11377x10^(-5),	SQNR:59.28816dB 

02/28/2024 03:06:09 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:06:14 - INFO - __main__ -   MSE:0.01192x10^(-5),	SQNR:69.11277dB 

02/28/2024 03:06:14 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:06:21 - INFO - __main__ -   MSE:0.00986x10^(-5),	SQNR:69.97668dB 

02/28/2024 03:06:21 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:06:26 - INFO - __main__ -   MSE:0.04470x10^(-5),	SQNR:63.35999dB 

02/28/2024 03:06:26 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:06:32 - INFO - __main__ -   MSE:0.03413x10^(-5),	SQNR:64.53612dB 

02/28/2024 03:06:32 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:06:39 - INFO - __main__ -   MSE:0.00054x10^(-5),	SQNR:82.50298dB 

02/28/2024 03:06:39 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:06:45 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.59146dB 

02/28/2024 03:06:45 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:06:50 - INFO - __main__ -   MSE:0.00564x10^(-5),	SQNR:72.35246dB 

02/28/2024 03:06:50 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:06:55 - INFO - __main__ -   MSE:0.00217x10^(-5),	SQNR:76.64365dB 

02/28/2024 03:06:55 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:07:03 - INFO - __main__ -   MSE:0.13859x10^(-5),	SQNR:58.41449dB 

02/28/2024 03:07:03 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:07:09 - INFO - __main__ -   MSE:0.11663x10^(-5),	SQNR:59.16304dB 

02/28/2024 03:07:09 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:07:13 - INFO - __main__ -   MSE:0.00569x10^(-5),	SQNR:72.29969dB 

02/28/2024 03:07:13 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:07:21 - INFO - __main__ -   MSE:0.00542x10^(-5),	SQNR:72.51389dB 

02/28/2024 03:07:21 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:07:26 - INFO - __main__ -   MSE:0.03185x10^(-5),	SQNR:64.79790dB 

02/28/2024 03:07:26 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:07:31 - INFO - __main__ -   MSE:0.02149x10^(-5),	SQNR:66.51074dB 

02/28/2024 03:07:31 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:07:37 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.22400dB 

02/28/2024 03:07:37 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:07:43 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:82.98193dB 

02/28/2024 03:07:43 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:07:48 - INFO - __main__ -   MSE:0.00199x10^(-5),	SQNR:76.84930dB 

02/28/2024 03:07:48 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:07:53 - INFO - __main__ -   MSE:0.00109x10^(-5),	SQNR:79.46927dB 

02/28/2024 03:07:53 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:08:00 - INFO - __main__ -   MSE:0.14999x10^(-5),	SQNR:58.11332dB 

02/28/2024 03:08:00 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:08:05 - INFO - __main__ -   MSE:0.10089x10^(-5),	SQNR:59.77515dB 

02/28/2024 03:08:05 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:08:11 - INFO - __main__ -   MSE:0.00405x10^(-5),	SQNR:73.77294dB 

02/28/2024 03:08:11 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:08:17 - INFO - __main__ -   MSE:0.00388x10^(-5),	SQNR:74.01178dB 

02/28/2024 03:08:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:08:23 - INFO - __main__ -   MSE:0.02065x10^(-5),	SQNR:66.70302dB 

02/28/2024 03:08:23 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:08:28 - INFO - __main__ -   MSE:0.01628x10^(-5),	SQNR:67.70901dB 

02/28/2024 03:08:28 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:08:33 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.52213dB 

02/28/2024 03:08:33 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:08:39 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.32182dB 

02/28/2024 03:08:39 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:08:46 - INFO - __main__ -   MSE:0.00137x10^(-5),	SQNR:78.49043dB 

02/28/2024 03:08:46 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:08:50 - INFO - __main__ -   MSE:0.00093x10^(-5),	SQNR:80.12512dB 

02/28/2024 03:08:50 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:08:55 - INFO - __main__ -   MSE:0.13845x10^(-5),	SQNR:58.44733dB 

02/28/2024 03:08:55 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:09:04 - INFO - __main__ -   MSE:0.09221x10^(-5),	SQNR:60.19669dB 

02/28/2024 03:09:04 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:09:09 - INFO - __main__ -   MSE:0.00487x10^(-5),	SQNR:73.07523dB 

02/28/2024 03:09:09 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:09:13 - INFO - __main__ -   MSE:0.00504x10^(-5),	SQNR:72.84167dB 

02/28/2024 03:09:13 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:09:21 - INFO - __main__ -   MSE:0.02472x10^(-5),	SQNR:65.98943dB 

02/28/2024 03:09:21 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:09:26 - INFO - __main__ -   MSE:0.01225x10^(-5),	SQNR:68.95387dB 

02/28/2024 03:09:26 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:09:31 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.66695dB 

02/28/2024 03:09:31 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:09:35 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.54939dB 

02/28/2024 03:09:36 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:09:42 - INFO - __main__ -   MSE:0.00087x10^(-5),	SQNR:80.43011dB 

02/28/2024 03:09:42 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:09:46 - INFO - __main__ -   MSE:0.00074x10^(-5),	SQNR:81.14405dB 

02/28/2024 03:09:46 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:09:51 - INFO - __main__ -   MSE:0.12814x10^(-5),	SQNR:58.74780dB 

02/28/2024 03:09:51 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:09:58 - INFO - __main__ -   MSE:0.07994x10^(-5),	SQNR:60.78535dB 

02/28/2024 03:09:58 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:10:04 - INFO - __main__ -   MSE:0.00455x10^(-5),	SQNR:73.26849dB 

02/28/2024 03:10:04 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:10:11 - INFO - __main__ -   MSE:0.00496x10^(-5),	SQNR:72.95508dB 

02/28/2024 03:10:11 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:10:17 - INFO - __main__ -   MSE:0.01603x10^(-5),	SQNR:67.79166dB 

02/28/2024 03:10:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:10:23 - INFO - __main__ -   MSE:0.00990x10^(-5),	SQNR:69.88575dB 

02/28/2024 03:10:23 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:10:29 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.70408dB 

02/28/2024 03:10:29 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:10:34 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.56966dB 

02/28/2024 03:10:34 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:10:42 - INFO - __main__ -   MSE:0.00080x10^(-5),	SQNR:80.79975dB 

02/28/2024 03:10:42 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:10:47 - INFO - __main__ -   MSE:0.00068x10^(-5),	SQNR:81.47910dB 

02/28/2024 03:10:47 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:10:52 - INFO - __main__ -   MSE:0.13100x10^(-5),	SQNR:58.66101dB 

02/28/2024 03:10:52 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:10:57 - INFO - __main__ -   MSE:0.07942x10^(-5),	SQNR:60.85387dB 

02/28/2024 03:10:58 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:11:05 - INFO - __main__ -   MSE:0.00436x10^(-5),	SQNR:73.43247dB 

02/28/2024 03:11:05 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:11:10 - INFO - __main__ -   MSE:0.00425x10^(-5),	SQNR:73.58382dB 

02/28/2024 03:11:10 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:11:14 - INFO - __main__ -   MSE:0.01333x10^(-5),	SQNR:68.56856dB 

02/28/2024 03:11:15 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:11:21 - INFO - __main__ -   MSE:0.01020x10^(-5),	SQNR:69.73528dB 

02/28/2024 03:11:21 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:11:26 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.68497dB 

02/28/2024 03:11:26 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:11:31 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.64353dB 

02/28/2024 03:11:31 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:11:39 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.12692dB 

02/28/2024 03:11:39 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:11:44 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.37684dB 

02/28/2024 03:11:44 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:11:49 - INFO - __main__ -   MSE:0.12512x10^(-5),	SQNR:58.85042dB 

02/28/2024 03:11:49 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:11:56 - INFO - __main__ -   MSE:0.06662x10^(-5),	SQNR:61.60744dB 

02/28/2024 03:11:56 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:12:03 - INFO - __main__ -   MSE:0.00191x10^(-5),	SQNR:77.04905dB 

02/28/2024 03:12:03 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:12:08 - INFO - __main__ -   MSE:0.00165x10^(-5),	SQNR:77.62935dB 

02/28/2024 03:12:08 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:12:14 - INFO - __main__ -   MSE:0.00816x10^(-5),	SQNR:70.69443dB 

02/28/2024 03:12:14 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:12:20 - INFO - __main__ -   MSE:0.00430x10^(-5),	SQNR:73.47730dB 

02/28/2024 03:12:20 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:12:28 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77193dB 

02/28/2024 03:12:28 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:12:33 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.68669dB 

02/28/2024 03:12:33 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:12:39 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.77747dB 

02/28/2024 03:12:39 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:12:44 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.73137dB 

02/28/2024 03:12:44 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:12:50 - INFO - __main__ -   MSE:0.10827x10^(-5),	SQNR:59.47332dB 

02/28/2024 03:12:50 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:12:55 - INFO - __main__ -   MSE:0.07249x10^(-5),	SQNR:61.23711dB 

02/28/2024 03:12:55 - INFO - __main__ -   model.up_blocks.0.attentions.2.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:13:01 - INFO - __main__ -   MSE:0.32336x10^(-5),	SQNR:54.73143dB 

02/28/2024 03:13:01 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 03:13:07 - INFO - __main__ -   MSE:1.17174x10^(-5),	SQNR:49.31746dB 

02/28/2024 03:13:07 - INFO - __main__ -   model.up_blocks.0.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:13:12 - INFO - __main__ -   MSE:0.04333x10^(-5),	SQNR:63.60343dB 

02/28/2024 03:13:12 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 03:13:19 - INFO - __main__ -   MSE:0.76935x10^(-5),	SQNR:51.07955dB 

02/28/2024 03:13:19 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:13:25 - INFO - __main__ -   MSE:1.47080x10^(-5),	SQNR:48.18590dB 

02/28/2024 03:13:25 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 03:13:30 - INFO - __main__ -   MSE:0.83441x10^(-5),	SQNR:50.71520dB 

02/28/2024 03:13:30 - INFO - __main__ -   model.up_blocks.0.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:13:36 - INFO - __main__ -   MSE:0.05198x10^(-5),	SQNR:62.97251dB 

02/28/2024 03:13:36 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 03:13:44 - INFO - __main__ -   MSE:0.51766x10^(-5),	SQNR:52.74105dB 

02/28/2024 03:13:44 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:13:51 - INFO - __main__ -   MSE:1.19056x10^(-5),	SQNR:49.08110dB 

02/28/2024 03:13:51 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 03:13:58 - INFO - __main__ -   MSE:0.39996x10^(-5),	SQNR:53.83885dB 

02/28/2024 03:13:58 - INFO - __main__ -   model.up_blocks.0.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:14:04 - INFO - __main__ -   MSE:0.06998x10^(-5),	SQNR:61.46449dB 

02/28/2024 03:14:04 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 03:14:10 - INFO - __main__ -   MSE:0.21028x10^(-5),	SQNR:56.60714dB 

02/28/2024 03:14:10 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:14:15 - INFO - __main__ -   MSE:1.19731x10^(-5),	SQNR:49.03066dB 

02/28/2024 03:14:15 - INFO - __main__ -   model.up_blocks.0.upsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 03:14:22 - INFO - __main__ -   MSE:1.84919x10^(-5),	SQNR:47.13502dB 

02/28/2024 03:14:22 - INFO - __main__ -   model.up_blocks.1.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:14:28 - INFO - __main__ -   MSE:0.65734x10^(-5),	SQNR:51.62877dB 

02/28/2024 03:14:28 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:14:33 - INFO - __main__ -   MSE:0.05700x10^(-5),	SQNR:62.25577dB 

02/28/2024 03:14:33 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:14:38 - INFO - __main__ -   MSE:0.05289x10^(-5),	SQNR:62.59763dB 

02/28/2024 03:14:38 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:14:45 - INFO - __main__ -   MSE:0.30134x10^(-5),	SQNR:55.01421dB 

02/28/2024 03:14:45 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:14:50 - INFO - __main__ -   MSE:0.34443x10^(-5),	SQNR:54.44561dB 

02/28/2024 03:14:50 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:14:54 - INFO - __main__ -   MSE:0.00301x10^(-5),	SQNR:75.16350dB 

02/28/2024 03:14:54 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:15:02 - INFO - __main__ -   MSE:0.00096x10^(-5),	SQNR:80.01824dB 

02/28/2024 03:15:02 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:15:07 - INFO - __main__ -   MSE:0.00162x10^(-5),	SQNR:77.76990dB 

02/28/2024 03:15:07 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:15:11 - INFO - __main__ -   MSE:0.00234x10^(-5),	SQNR:76.13670dB 

02/28/2024 03:15:11 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:15:16 - INFO - __main__ -   MSE:0.29271x10^(-5),	SQNR:55.16616dB 

02/28/2024 03:15:16 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:15:22 - INFO - __main__ -   MSE:0.29507x10^(-5),	SQNR:55.12838dB 

02/28/2024 03:15:22 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:15:27 - INFO - __main__ -   MSE:0.04504x10^(-5),	SQNR:63.29226dB 

02/28/2024 03:15:27 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:15:33 - INFO - __main__ -   MSE:0.05683x10^(-5),	SQNR:62.31110dB 

02/28/2024 03:15:33 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:15:38 - INFO - __main__ -   MSE:0.29828x10^(-5),	SQNR:55.06668dB 

02/28/2024 03:15:38 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:15:44 - INFO - __main__ -   MSE:0.21580x10^(-5),	SQNR:56.48364dB 

02/28/2024 03:15:44 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:15:49 - INFO - __main__ -   MSE:0.00154x10^(-5),	SQNR:77.93422dB 

02/28/2024 03:15:49 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:15:57 - INFO - __main__ -   MSE:0.00080x10^(-5),	SQNR:80.79834dB 

02/28/2024 03:15:57 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:16:04 - INFO - __main__ -   MSE:0.00128x10^(-5),	SQNR:78.75274dB 

02/28/2024 03:16:04 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:16:10 - INFO - __main__ -   MSE:0.00192x10^(-5),	SQNR:76.98593dB 

02/28/2024 03:16:10 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:16:18 - INFO - __main__ -   MSE:0.26229x10^(-5),	SQNR:55.63350dB 

02/28/2024 03:16:18 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:16:24 - INFO - __main__ -   MSE:0.11778x10^(-5),	SQNR:59.11247dB 

02/28/2024 03:16:24 - INFO - __main__ -   model.up_blocks.1.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:16:30 - INFO - __main__ -   MSE:0.13379x10^(-5),	SQNR:58.56336dB 

02/28/2024 03:16:30 - INFO - __main__ -   model.up_blocks.1.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:16:35 - INFO - __main__ -   MSE:0.36703x10^(-5),	SQNR:54.18232dB 

02/28/2024 03:16:35 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:16:42 - INFO - __main__ -   MSE:0.01716x10^(-5),	SQNR:67.48636dB 

02/28/2024 03:16:42 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:16:48 - INFO - __main__ -   MSE:0.01561x10^(-5),	SQNR:67.92306dB 

02/28/2024 03:16:48 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:16:52 - INFO - __main__ -   MSE:0.11319x10^(-5),	SQNR:59.26741dB 

02/28/2024 03:16:52 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:16:59 - INFO - __main__ -   MSE:0.13360x10^(-5),	SQNR:58.55201dB 

02/28/2024 03:16:59 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:17:05 - INFO - __main__ -   MSE:0.01041x10^(-5),	SQNR:69.84974dB 

02/28/2024 03:17:05 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:17:11 - INFO - __main__ -   MSE:0.00061x10^(-5),	SQNR:81.96763dB 

02/28/2024 03:17:11 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:17:17 - INFO - __main__ -   MSE:0.00082x10^(-5),	SQNR:80.67291dB 

02/28/2024 03:17:17 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:17:23 - INFO - __main__ -   MSE:0.00183x10^(-5),	SQNR:77.21062dB 

02/28/2024 03:17:23 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:17:29 - INFO - __main__ -   MSE:0.18645x10^(-5),	SQNR:57.11583dB 

02/28/2024 03:17:29 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:17:35 - INFO - __main__ -   MSE:0.13976x10^(-5),	SQNR:58.36819dB 

02/28/2024 03:17:35 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:17:42 - INFO - __main__ -   MSE:0.01168x10^(-5),	SQNR:69.15514dB 

02/28/2024 03:17:42 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:17:46 - INFO - __main__ -   MSE:0.01084x10^(-5),	SQNR:69.47872dB 

02/28/2024 03:17:47 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:17:52 - INFO - __main__ -   MSE:0.10886x10^(-5),	SQNR:59.43410dB 

02/28/2024 03:17:52 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:17:58 - INFO - __main__ -   MSE:0.07180x10^(-5),	SQNR:61.25144dB 

02/28/2024 03:17:58 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:18:03 - INFO - __main__ -   MSE:0.00184x10^(-5),	SQNR:77.14629dB 

02/28/2024 03:18:03 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:18:09 - INFO - __main__ -   MSE:0.00083x10^(-5),	SQNR:80.60468dB 

02/28/2024 03:18:09 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:18:13 - INFO - __main__ -   MSE:0.00099x10^(-5),	SQNR:79.83235dB 

02/28/2024 03:18:13 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:18:18 - INFO - __main__ -   MSE:0.00152x10^(-5),	SQNR:77.99117dB 

02/28/2024 03:18:18 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:18:24 - INFO - __main__ -   MSE:0.18400x10^(-5),	SQNR:57.16541dB 

02/28/2024 03:18:24 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:18:30 - INFO - __main__ -   MSE:0.05773x10^(-5),	SQNR:62.21009dB 

02/28/2024 03:18:30 - INFO - __main__ -   model.up_blocks.1.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:18:36 - INFO - __main__ -   MSE:0.11439x10^(-5),	SQNR:59.23078dB 

02/28/2024 03:18:36 - INFO - __main__ -   model.up_blocks.1.attentions.2.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:18:44 - INFO - __main__ -   MSE:0.25931x10^(-5),	SQNR:55.67420dB 

02/28/2024 03:18:44 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:18:49 - INFO - __main__ -   MSE:0.00320x10^(-5),	SQNR:74.77132dB 

02/28/2024 03:18:49 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:18:53 - INFO - __main__ -   MSE:0.00289x10^(-5),	SQNR:75.21028dB 

02/28/2024 03:18:54 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:19:01 - INFO - __main__ -   MSE:0.06473x10^(-5),	SQNR:61.69875dB 

02/28/2024 03:19:01 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:19:05 - INFO - __main__ -   MSE:0.05987x10^(-5),	SQNR:62.03614dB 

02/28/2024 03:19:06 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:19:10 - INFO - __main__ -   MSE:0.00134x10^(-5),	SQNR:78.56084dB 

02/28/2024 03:19:10 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:19:18 - INFO - __main__ -   MSE:0.00079x10^(-5),	SQNR:80.85969dB 

02/28/2024 03:19:18 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:19:24 - INFO - __main__ -   MSE:0.00101x10^(-5),	SQNR:79.80718dB 

02/28/2024 03:19:24 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:19:28 - INFO - __main__ -   MSE:0.00180x10^(-5),	SQNR:77.32011dB 

02/28/2024 03:19:28 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:19:34 - INFO - __main__ -   MSE:0.12644x10^(-5),	SQNR:58.78563dB 

02/28/2024 03:19:34 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:19:41 - INFO - __main__ -   MSE:0.07143x10^(-5),	SQNR:61.27628dB 

02/28/2024 03:19:41 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:19:46 - INFO - __main__ -   MSE:0.00248x10^(-5),	SQNR:75.86423dB 

02/28/2024 03:19:46 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:19:51 - INFO - __main__ -   MSE:0.00211x10^(-5),	SQNR:76.57253dB 

02/28/2024 03:19:51 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:19:57 - INFO - __main__ -   MSE:0.05663x10^(-5),	SQNR:62.27569dB 

02/28/2024 03:19:57 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:20:03 - INFO - __main__ -   MSE:0.02497x10^(-5),	SQNR:65.84707dB 

02/28/2024 03:20:03 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:20:10 - INFO - __main__ -   MSE:0.00098x10^(-5),	SQNR:79.92390dB 

02/28/2024 03:20:10 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:20:17 - INFO - __main__ -   MSE:0.00071x10^(-5),	SQNR:81.27269dB 

02/28/2024 03:20:17 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:20:24 - INFO - __main__ -   MSE:0.00166x10^(-5),	SQNR:77.66441dB 

02/28/2024 03:20:24 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:20:29 - INFO - __main__ -   MSE:0.00147x10^(-5),	SQNR:78.16543dB 

02/28/2024 03:20:29 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:20:34 - INFO - __main__ -   MSE:0.07663x10^(-5),	SQNR:60.97503dB 

02/28/2024 03:20:34 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:20:43 - INFO - __main__ -   MSE:0.04194x10^(-5),	SQNR:63.59229dB 

02/28/2024 03:20:43 - INFO - __main__ -   model.up_blocks.1.attentions.2.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:20:49 - INFO - __main__ -   MSE:0.18081x10^(-5),	SQNR:57.23816dB 

02/28/2024 03:20:49 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 03:20:54 - INFO - __main__ -   MSE:1.90900x10^(-5),	SQNR:47.02943dB 

02/28/2024 03:20:54 - INFO - __main__ -   model.up_blocks.1.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:21:01 - INFO - __main__ -   MSE:0.01479x10^(-5),	SQNR:68.12717dB 

02/28/2024 03:21:01 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 03:21:07 - INFO - __main__ -   MSE:0.80417x10^(-5),	SQNR:50.75706dB 

02/28/2024 03:21:07 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:21:12 - INFO - __main__ -   MSE:1.05175x10^(-5),	SQNR:49.59549dB 

02/28/2024 03:21:12 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 03:21:17 - INFO - __main__ -   MSE:0.67353x10^(-5),	SQNR:51.53972dB 

02/28/2024 03:21:17 - INFO - __main__ -   model.up_blocks.1.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:21:24 - INFO - __main__ -   MSE:0.02214x10^(-5),	SQNR:66.36700dB 

02/28/2024 03:21:24 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 03:21:29 - INFO - __main__ -   MSE:0.50056x10^(-5),	SQNR:52.81454dB 

02/28/2024 03:21:29 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:21:34 - INFO - __main__ -   MSE:0.57187x10^(-5),	SQNR:52.24215dB 

02/28/2024 03:21:34 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 03:21:41 - INFO - __main__ -   MSE:0.29310x10^(-5),	SQNR:55.14273dB 

02/28/2024 03:21:41 - INFO - __main__ -   model.up_blocks.1.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:21:47 - INFO - __main__ -   MSE:0.01528x10^(-5),	SQNR:67.96774dB 

02/28/2024 03:21:47 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 03:21:54 - INFO - __main__ -   MSE:0.29135x10^(-5),	SQNR:55.17554dB 

02/28/2024 03:21:54 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:22:02 - INFO - __main__ -   MSE:0.47312x10^(-5),	SQNR:53.05740dB 

02/28/2024 03:22:02 - INFO - __main__ -   model.up_blocks.1.upsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 03:22:09 - INFO - __main__ -   MSE:0.81009x10^(-5),	SQNR:50.71796dB 

02/28/2024 03:22:09 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 03:22:15 - INFO - __main__ -   MSE:2.95695x10^(-5),	SQNR:45.10064dB 

02/28/2024 03:22:15 - INFO - __main__ -   model.up_blocks.2.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:22:22 - INFO - __main__ -   MSE:0.00788x10^(-5),	SQNR:70.84413dB 

02/28/2024 03:22:22 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 03:22:29 - INFO - __main__ -   MSE:1.96532x10^(-5),	SQNR:46.87019dB 

02/28/2024 03:22:29 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:22:34 - INFO - __main__ -   MSE:1.39982x10^(-5),	SQNR:48.34389dB 

02/28/2024 03:22:34 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 03:22:41 - INFO - __main__ -   MSE:4.56891x10^(-5),	SQNR:43.20549dB 

02/28/2024 03:22:41 - INFO - __main__ -   model.up_blocks.2.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:22:47 - INFO - __main__ -   MSE:0.04079x10^(-5),	SQNR:63.69764dB 

02/28/2024 03:22:47 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 03:22:52 - INFO - __main__ -   MSE:3.09135x10^(-5),	SQNR:44.90131dB 

02/28/2024 03:22:52 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:22:58 - INFO - __main__ -   MSE:2.26317x10^(-5),	SQNR:46.25530dB 

02/28/2024 03:22:58 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 03:23:04 - INFO - __main__ -   MSE:9.50536x10^(-5),	SQNR:40.02404dB 

02/28/2024 03:23:04 - INFO - __main__ -   model.up_blocks.2.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:23:09 - INFO - __main__ -   MSE:0.08844x10^(-5),	SQNR:60.33632dB 

02/28/2024 03:23:09 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 03:23:15 - INFO - __main__ -   MSE:31.63336x10^(-5),	SQNR:34.80143dB 

02/28/2024 03:23:15 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:23:22 - INFO - __main__ -   MSE:2.99964x10^(-5),	SQNR:45.03162dB 

02/28/2024 03:23:22 - INFO - __main__ -   model.mid_block.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:23:27 - INFO - __main__ -   MSE:3.44754x10^(-5),	SQNR:44.61130dB 

02/28/2024 03:23:27 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:23:34 - INFO - __main__ -   MSE:0.08707x10^(-5),	SQNR:60.78703dB 

02/28/2024 03:23:34 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:23:41 - INFO - __main__ -   MSE:0.10525x10^(-5),	SQNR:59.64466dB 

02/28/2024 03:23:41 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:23:45 - INFO - __main__ -   MSE:0.54506x10^(-5),	SQNR:52.90918dB 

02/28/2024 03:23:45 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:23:51 - INFO - __main__ -   MSE:1.01017x10^(-5),	SQNR:49.92035dB 

02/28/2024 03:23:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:23:58 - INFO - __main__ -   MSE:0.00158x10^(-5),	SQNR:78.11649dB 

02/28/2024 03:23:58 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:24:04 - INFO - __main__ -   MSE:0.00381x10^(-5),	SQNR:74.58762dB 

02/28/2024 03:24:04 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:24:10 - INFO - __main__ -   MSE:0.03826x10^(-5),	SQNR:64.87242dB 

02/28/2024 03:24:10 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:24:15 - INFO - __main__ -   MSE:0.02318x10^(-5),	SQNR:66.27107dB 

02/28/2024 03:24:15 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:24:23 - INFO - __main__ -   MSE:0.52012x10^(-5),	SQNR:52.82734dB 

02/28/2024 03:24:23 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:24:28 - INFO - __main__ -   MSE:1.08675x10^(-5),	SQNR:49.86882dB 

02/28/2024 03:24:28 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:24:33 - INFO - __main__ -   MSE:0.14728x10^(-5),	SQNR:58.15457dB 

02/28/2024 03:24:33 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:24:38 - INFO - __main__ -   MSE:0.27132x10^(-5),	SQNR:55.98158dB 

02/28/2024 03:24:38 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:24:44 - INFO - __main__ -   MSE:0.61808x10^(-5),	SQNR:52.34771dB 

02/28/2024 03:24:44 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:24:48 - INFO - __main__ -   MSE:0.67351x10^(-5),	SQNR:51.93651dB 

02/28/2024 03:24:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:24:53 - INFO - __main__ -   MSE:0.00622x10^(-5),	SQNR:73.41307dB 

02/28/2024 03:24:53 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:25:00 - INFO - __main__ -   MSE:0.00411x10^(-5),	SQNR:73.88467dB 

02/28/2024 03:25:00 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:25:05 - INFO - __main__ -   MSE:0.03864x10^(-5),	SQNR:64.27463dB 

02/28/2024 03:25:05 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:25:09 - INFO - __main__ -   MSE:0.04394x10^(-5),	SQNR:63.89034dB 

02/28/2024 03:25:09 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:25:15 - INFO - __main__ -   MSE:0.54880x10^(-5),	SQNR:52.49032dB 

02/28/2024 03:25:15 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:25:22 - INFO - __main__ -   MSE:0.58802x10^(-5),	SQNR:52.64248dB 

02/28/2024 03:25:22 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:25:27 - INFO - __main__ -   MSE:0.09347x10^(-5),	SQNR:60.13158dB 

02/28/2024 03:25:27 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:25:32 - INFO - __main__ -   MSE:0.12255x10^(-5),	SQNR:59.02544dB 

02/28/2024 03:25:32 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:25:40 - INFO - __main__ -   MSE:0.38286x10^(-5),	SQNR:54.25139dB 

02/28/2024 03:25:40 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:25:44 - INFO - __main__ -   MSE:0.38638x10^(-5),	SQNR:53.99930dB 

02/28/2024 03:25:44 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:25:51 - INFO - __main__ -   MSE:0.00102x10^(-5),	SQNR:79.74562dB 

02/28/2024 03:25:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:25:56 - INFO - __main__ -   MSE:0.00115x10^(-5),	SQNR:79.24446dB 

02/28/2024 03:25:56 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:26:03 - INFO - __main__ -   MSE:0.01604x10^(-5),	SQNR:68.01715dB 

02/28/2024 03:26:03 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:26:08 - INFO - __main__ -   MSE:0.01764x10^(-5),	SQNR:67.71967dB 

02/28/2024 03:26:08 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:26:13 - INFO - __main__ -   MSE:0.60367x10^(-5),	SQNR:52.14677dB 

02/28/2024 03:26:13 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:26:21 - INFO - __main__ -   MSE:0.45835x10^(-5),	SQNR:53.56533dB 

02/28/2024 03:26:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:26:28 - INFO - __main__ -   MSE:0.11813x10^(-5),	SQNR:59.27140dB 

02/28/2024 03:26:28 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:26:33 - INFO - __main__ -   MSE:0.07857x10^(-5),	SQNR:61.07592dB 

02/28/2024 03:26:33 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:26:40 - INFO - __main__ -   MSE:0.43538x10^(-5),	SQNR:53.49120dB 

02/28/2024 03:26:40 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:26:45 - INFO - __main__ -   MSE:0.38098x10^(-5),	SQNR:54.23508dB 

02/28/2024 03:26:45 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:26:50 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.28273dB 

02/28/2024 03:26:50 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:26:57 - INFO - __main__ -   MSE:0.00073x10^(-5),	SQNR:81.27659dB 

02/28/2024 03:26:57 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:27:04 - INFO - __main__ -   MSE:0.00687x10^(-5),	SQNR:71.63686dB 

02/28/2024 03:27:04 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:27:08 - INFO - __main__ -   MSE:0.00569x10^(-5),	SQNR:72.58199dB 

02/28/2024 03:27:08 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:27:14 - INFO - __main__ -   MSE:0.58162x10^(-5),	SQNR:52.42510dB 

02/28/2024 03:27:14 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:27:21 - INFO - __main__ -   MSE:0.48853x10^(-5),	SQNR:53.07420dB 

02/28/2024 03:27:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:27:26 - INFO - __main__ -   MSE:0.15226x10^(-5),	SQNR:58.09441dB 

02/28/2024 03:27:26 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:27:32 - INFO - __main__ -   MSE:0.09541x10^(-5),	SQNR:60.18066dB 

02/28/2024 03:27:32 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:27:38 - INFO - __main__ -   MSE:0.39001x10^(-5),	SQNR:54.34439dB 

02/28/2024 03:27:38 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:27:44 - INFO - __main__ -   MSE:0.33664x10^(-5),	SQNR:54.55517dB 

02/28/2024 03:27:44 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:27:51 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.52657dB 

02/28/2024 03:27:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:27:57 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.73764dB 

02/28/2024 03:27:57 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:28:04 - INFO - __main__ -   MSE:0.00225x10^(-5),	SQNR:76.36008dB 

02/28/2024 03:28:04 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:28:09 - INFO - __main__ -   MSE:0.00157x10^(-5),	SQNR:77.90350dB 

02/28/2024 03:28:09 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:28:14 - INFO - __main__ -   MSE:0.58189x10^(-5),	SQNR:52.24857dB 

02/28/2024 03:28:14 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:28:20 - INFO - __main__ -   MSE:0.36658x10^(-5),	SQNR:54.46096dB 

02/28/2024 03:28:20 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:28:25 - INFO - __main__ -   MSE:0.07656x10^(-5),	SQNR:61.10328dB 

02/28/2024 03:28:25 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:28:31 - INFO - __main__ -   MSE:0.10239x10^(-5),	SQNR:59.93535dB 

02/28/2024 03:28:31 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:28:37 - INFO - __main__ -   MSE:0.25880x10^(-5),	SQNR:56.06542dB 

02/28/2024 03:28:37 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:28:43 - INFO - __main__ -   MSE:0.20005x10^(-5),	SQNR:56.94651dB 

02/28/2024 03:28:43 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:28:48 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.41286dB 

02/28/2024 03:28:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:28:52 - INFO - __main__ -   MSE:0.00047x10^(-5),	SQNR:83.08820dB 

02/28/2024 03:28:52 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:28:58 - INFO - __main__ -   MSE:0.00215x10^(-5),	SQNR:76.48894dB 

02/28/2024 03:28:58 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:29:04 - INFO - __main__ -   MSE:0.00229x10^(-5),	SQNR:76.28167dB 

02/28/2024 03:29:04 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:29:09 - INFO - __main__ -   MSE:0.51983x10^(-5),	SQNR:52.76218dB 

02/28/2024 03:29:09 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:29:14 - INFO - __main__ -   MSE:0.26708x10^(-5),	SQNR:55.55480dB 

02/28/2024 03:29:14 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:29:21 - INFO - __main__ -   MSE:0.04281x10^(-5),	SQNR:63.92945dB 

02/28/2024 03:29:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:29:26 - INFO - __main__ -   MSE:0.03506x10^(-5),	SQNR:64.66889dB 

02/28/2024 03:29:26 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:29:31 - INFO - __main__ -   MSE:0.11942x10^(-5),	SQNR:59.13710dB 

02/28/2024 03:29:31 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:29:38 - INFO - __main__ -   MSE:0.12895x10^(-5),	SQNR:58.72282dB 

02/28/2024 03:29:38 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:29:44 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.62470dB 

02/28/2024 03:29:44 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:29:50 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.39298dB 

02/28/2024 03:29:50 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:29:56 - INFO - __main__ -   MSE:0.00091x10^(-5),	SQNR:80.28269dB 

02/28/2024 03:29:56 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:30:01 - INFO - __main__ -   MSE:0.00093x10^(-5),	SQNR:80.20621dB 

02/28/2024 03:30:01 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:30:08 - INFO - __main__ -   MSE:0.44992x10^(-5),	SQNR:53.40966dB 

02/28/2024 03:30:08 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:30:13 - INFO - __main__ -   MSE:0.24049x10^(-5),	SQNR:56.09399dB 

02/28/2024 03:30:13 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:30:21 - INFO - __main__ -   MSE:0.05942x10^(-5),	SQNR:62.26369dB 

02/28/2024 03:30:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:30:27 - INFO - __main__ -   MSE:0.05720x10^(-5),	SQNR:62.48552dB 

02/28/2024 03:30:27 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:30:31 - INFO - __main__ -   MSE:0.11280x10^(-5),	SQNR:59.36992dB 

02/28/2024 03:30:31 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:30:36 - INFO - __main__ -   MSE:0.10237x10^(-5),	SQNR:59.93508dB 

02/28/2024 03:30:36 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:30:43 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.57175dB 

02/28/2024 03:30:43 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:30:48 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.42209dB 

02/28/2024 03:30:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:30:52 - INFO - __main__ -   MSE:0.00077x10^(-5),	SQNR:80.98370dB 

02/28/2024 03:30:52 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:30:58 - INFO - __main__ -   MSE:0.00075x10^(-5),	SQNR:81.06738dB 

02/28/2024 03:30:58 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:31:04 - INFO - __main__ -   MSE:0.43218x10^(-5),	SQNR:53.49508dB 

02/28/2024 03:31:04 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:31:09 - INFO - __main__ -   MSE:0.19989x10^(-5),	SQNR:56.79758dB 

02/28/2024 03:31:09 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:31:16 - INFO - __main__ -   MSE:0.06447x10^(-5),	SQNR:61.90273dB 

02/28/2024 03:31:16 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:31:21 - INFO - __main__ -   MSE:0.07886x10^(-5),	SQNR:60.90527dB 

02/28/2024 03:31:22 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:31:26 - INFO - __main__ -   MSE:0.13495x10^(-5),	SQNR:58.62513dB 

02/28/2024 03:31:26 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:31:31 - INFO - __main__ -   MSE:0.08318x10^(-5),	SQNR:60.75442dB 

02/28/2024 03:31:31 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:31:37 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.74831dB 

02/28/2024 03:31:37 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:31:43 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.56559dB 

02/28/2024 03:31:43 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:31:48 - INFO - __main__ -   MSE:0.00082x10^(-5),	SQNR:80.82714dB 

02/28/2024 03:31:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:31:53 - INFO - __main__ -   MSE:0.00081x10^(-5),	SQNR:80.84024dB 

02/28/2024 03:31:53 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:32:00 - INFO - __main__ -   MSE:0.41474x10^(-5),	SQNR:53.70374dB 

02/28/2024 03:32:00 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:32:06 - INFO - __main__ -   MSE:0.16075x10^(-5),	SQNR:57.81246dB 

02/28/2024 03:32:06 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:32:12 - INFO - __main__ -   MSE:0.08005x10^(-5),	SQNR:61.01809dB 

02/28/2024 03:32:12 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:32:21 - INFO - __main__ -   MSE:0.05788x10^(-5),	SQNR:62.34610dB 

02/28/2024 03:32:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:32:26 - INFO - __main__ -   MSE:0.08830x10^(-5),	SQNR:60.41711dB 

02/28/2024 03:32:26 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:32:30 - INFO - __main__ -   MSE:0.04774x10^(-5),	SQNR:63.09653dB 

02/28/2024 03:32:30 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:32:36 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.72705dB 

02/28/2024 03:32:36 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:32:42 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.62212dB 

02/28/2024 03:32:42 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:32:47 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.44212dB 

02/28/2024 03:32:47 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:32:51 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.42905dB 

02/28/2024 03:32:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:32:59 - INFO - __main__ -   MSE:0.40385x10^(-5),	SQNR:53.74899dB 

02/28/2024 03:32:59 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:33:04 - INFO - __main__ -   MSE:0.10117x10^(-5),	SQNR:59.75552dB 

02/28/2024 03:33:04 - INFO - __main__ -   model.mid_block.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:33:09 - INFO - __main__ -   MSE:0.95931x10^(-5),	SQNR:50.08386dB 

02/28/2024 03:33:09 - INFO - __main__ -   model.mid_block.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 03:33:17 - INFO - __main__ -   MSE:2.09648x10^(-5),	SQNR:46.90412dB 

02/28/2024 03:33:17 - INFO - __main__ -   model.mid_block.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:33:23 - INFO - __main__ -   MSE:0.35149x10^(-5),	SQNR:57.32008dB 

02/28/2024 03:33:23 - INFO - __main__ -   model.mid_block.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 03:33:29 - INFO - __main__ -   MSE:1.33723x10^(-5),	SQNR:48.84075dB 

02/28/2024 03:33:29 - INFO - __main__ -   model.mid_block.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 03:33:37 - INFO - __main__ -   MSE:0.76487x10^(-5),	SQNR:51.03783dB 

02/28/2024 03:33:37 - INFO - __main__ -   model.mid_block.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:33:43 - INFO - __main__ -   MSE:0.07104x10^(-5),	SQNR:61.33469dB 

02/28/2024 03:33:43 - INFO - __main__ -   model.mid_block.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 03:33:50 - INFO - __main__ -   MSE:0.48636x10^(-5),	SQNR:53.05015dB 

02/28/2024 03:33:50 - INFO - __main__ -   model.conv_out: weight_quant=True, act_quant=False
02/28/2024 03:33:55 - INFO - __main__ -   MSE:453.67685x10^(-5),	SQNR:23.23464dB 

02/28/2024 03:33:55 - INFO - __main__ -   
the bit width is 8!

02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.conv_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.time_embedding.linear_1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.time_embedding.linear_2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.add_embedding.linear_1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.add_embedding.linear_2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.0.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.0.resnets.1.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.0.downsamplers.0.conv.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.0.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.attentions.1.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.0.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.resnets.1.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.1.downsamplers.0.conv.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.0.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.attentions.1.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.0.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.down_blocks.2.resnets.1.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.0.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.1.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.attentions.2.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.0.upsamplers.0.conv.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.0.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.1.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.attentions.2.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.1.upsamplers.0.conv.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.0.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.1.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv_shortcut.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.up_blocks.2.resnets.2.conv_shortcut.weight_quantizer_0: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.proj_in.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_q.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_k.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_v.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.attentions.0.proj_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.0.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.conv1.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.time_emb_proj.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.mid_block.resnets.1.conv2.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - qdiff.models.quant_model -   model.conv_out.weight_quantizer: weight_quant=8
02/28/2024 03:33:55 - INFO - __main__ -   ################# Start to quantize the layers one by one #################
02/28/2024 03:33:55 - INFO - __main__ -   model.conv_in: weight_quant=True, act_quant=False
02/28/2024 03:34:01 - INFO - __main__ -   MSE:0.11487x10^(-5),	SQNR:59.25853dB 

02/28/2024 03:34:01 - INFO - __main__ -   model.time_embedding.linear_1: weight_quant=True, act_quant=False
02/28/2024 03:34:07 - INFO - __main__ -   MSE:0.00121x10^(-5),	SQNR:79.11298dB 

02/28/2024 03:34:07 - INFO - __main__ -   model.time_embedding.linear_2: weight_quant=True, act_quant=False
02/28/2024 03:34:12 - INFO - __main__ -   MSE:0.00470x10^(-5),	SQNR:73.23423dB 

02/28/2024 03:34:12 - INFO - __main__ -   model.add_embedding.linear_1: weight_quant=True, act_quant=False
02/28/2024 03:34:21 - INFO - __main__ -   MSE:0.02942x10^(-5),	SQNR:65.36525dB 

02/28/2024 03:34:21 - INFO - __main__ -   model.add_embedding.linear_2: weight_quant=True, act_quant=False
02/28/2024 03:34:26 - INFO - __main__ -   MSE:0.00703x10^(-5),	SQNR:71.66156dB 

02/28/2024 03:34:26 - INFO - __main__ -   model.down_blocks.0.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 03:34:31 - INFO - __main__ -   MSE:0.00673x10^(-5),	SQNR:71.94646dB 

02/28/2024 03:34:31 - INFO - __main__ -   model.down_blocks.0.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:34:38 - INFO - __main__ -   MSE:0.01314x10^(-5),	SQNR:68.89232dB 

02/28/2024 03:34:38 - INFO - __main__ -   model.down_blocks.0.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 03:34:44 - INFO - __main__ -   MSE:0.07277x10^(-5),	SQNR:61.38833dB 

02/28/2024 03:34:44 - INFO - __main__ -   model.down_blocks.0.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 03:34:49 - INFO - __main__ -   MSE:0.01174x10^(-5),	SQNR:69.38309dB 

02/28/2024 03:34:49 - INFO - __main__ -   model.down_blocks.0.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:34:56 - INFO - __main__ -   MSE:0.00230x10^(-5),	SQNR:76.27295dB 

02/28/2024 03:34:56 - INFO - __main__ -   model.down_blocks.0.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 03:35:02 - INFO - __main__ -   MSE:0.05039x10^(-5),	SQNR:63.25792dB 

02/28/2024 03:35:02 - INFO - __main__ -   model.down_blocks.0.downsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 03:35:07 - INFO - __main__ -   MSE:0.03772x10^(-5),	SQNR:64.44308dB 

02/28/2024 03:35:07 - INFO - __main__ -   model.down_blocks.1.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:35:13 - INFO - __main__ -   MSE:0.00716x10^(-5),	SQNR:71.35257dB 

02/28/2024 03:35:13 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:35:19 - INFO - __main__ -   MSE:0.00062x10^(-5),	SQNR:81.91676dB 

02/28/2024 03:35:19 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:35:25 - INFO - __main__ -   MSE:0.00057x10^(-5),	SQNR:82.33929dB 

02/28/2024 03:35:25 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:35:31 - INFO - __main__ -   MSE:0.00124x10^(-5),	SQNR:78.91065dB 

02/28/2024 03:35:31 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:35:36 - INFO - __main__ -   MSE:0.00195x10^(-5),	SQNR:77.11020dB 

02/28/2024 03:35:36 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:35:43 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.60017dB 

02/28/2024 03:35:43 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:35:47 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.56267dB 

02/28/2024 03:35:48 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:35:52 - INFO - __main__ -   MSE:0.00070x10^(-5),	SQNR:81.39606dB 

02/28/2024 03:35:52 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:35:59 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.59591dB 

02/28/2024 03:35:59 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:36:05 - INFO - __main__ -   MSE:0.00220x10^(-5),	SQNR:76.41739dB 

02/28/2024 03:36:05 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:36:09 - INFO - __main__ -   MSE:0.00168x10^(-5),	SQNR:77.72917dB 

02/28/2024 03:36:09 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:36:16 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.41685dB 

02/28/2024 03:36:16 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:36:22 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.43869dB 

02/28/2024 03:36:22 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:36:27 - INFO - __main__ -   MSE:0.00366x10^(-5),	SQNR:74.34045dB 

02/28/2024 03:36:27 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:36:31 - INFO - __main__ -   MSE:0.00153x10^(-5),	SQNR:78.20642dB 

02/28/2024 03:36:31 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:36:38 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.32691dB 

02/28/2024 03:36:38 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:36:45 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:83.00208dB 

02/28/2024 03:36:45 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:36:51 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.71960dB 

02/28/2024 03:36:51 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:36:58 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.25479dB 

02/28/2024 03:36:58 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:37:03 - INFO - __main__ -   MSE:0.00369x10^(-5),	SQNR:74.29103dB 

02/28/2024 03:37:04 - INFO - __main__ -   model.down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:37:10 - INFO - __main__ -   MSE:0.00276x10^(-5),	SQNR:75.66138dB 

02/28/2024 03:37:10 - INFO - __main__ -   model.down_blocks.1.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:37:15 - INFO - __main__ -   MSE:0.00364x10^(-5),	SQNR:74.45243dB 

02/28/2024 03:37:15 - INFO - __main__ -   model.down_blocks.1.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:37:22 - INFO - __main__ -   MSE:0.00700x10^(-5),	SQNR:71.55226dB 

02/28/2024 03:37:22 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:37:27 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.77103dB 

02/28/2024 03:37:27 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:37:33 - INFO - __main__ -   MSE:0.00047x10^(-5),	SQNR:83.09695dB 

02/28/2024 03:37:33 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:37:42 - INFO - __main__ -   MSE:0.00264x10^(-5),	SQNR:75.88134dB 

02/28/2024 03:37:42 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:37:46 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.10478dB 

02/28/2024 03:37:46 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:37:52 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.72343dB 

02/28/2024 03:37:52 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:37:58 - INFO - __main__ -   MSE:0.00047x10^(-5),	SQNR:83.21925dB 

02/28/2024 03:37:58 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:38:04 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.33098dB 

02/28/2024 03:38:04 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:38:09 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.55771dB 

02/28/2024 03:38:09 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:38:15 - INFO - __main__ -   MSE:0.00131x10^(-5),	SQNR:78.77126dB 

02/28/2024 03:38:15 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:38:21 - INFO - __main__ -   MSE:0.00081x10^(-5),	SQNR:80.83170dB 

02/28/2024 03:38:21 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:38:28 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.84917dB 

02/28/2024 03:38:28 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:38:33 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.95813dB 

02/28/2024 03:38:33 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:38:41 - INFO - __main__ -   MSE:0.00369x10^(-5),	SQNR:74.64469dB 

02/28/2024 03:38:41 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:38:45 - INFO - __main__ -   MSE:0.00079x10^(-5),	SQNR:80.86859dB 

02/28/2024 03:38:45 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:38:50 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.54034dB 

02/28/2024 03:38:50 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:38:55 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.29926dB 

02/28/2024 03:38:55 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:39:02 - INFO - __main__ -   MSE:0.00047x10^(-5),	SQNR:83.05714dB 

02/28/2024 03:39:02 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:39:06 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65909dB 

02/28/2024 03:39:06 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:39:12 - INFO - __main__ -   MSE:0.00140x10^(-5),	SQNR:78.44489dB 

02/28/2024 03:39:12 - INFO - __main__ -   model.down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:39:18 - INFO - __main__ -   MSE:0.00125x10^(-5),	SQNR:79.41589dB 

02/28/2024 03:39:18 - INFO - __main__ -   model.down_blocks.1.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:39:24 - INFO - __main__ -   MSE:0.02208x10^(-5),	SQNR:66.37639dB 

02/28/2024 03:39:24 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 03:39:30 - INFO - __main__ -   MSE:0.00492x10^(-5),	SQNR:73.00266dB 

02/28/2024 03:39:30 - INFO - __main__ -   model.down_blocks.1.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:39:37 - INFO - __main__ -   MSE:0.00530x10^(-5),	SQNR:72.59827dB 

02/28/2024 03:39:37 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 03:39:43 - INFO - __main__ -   MSE:0.00737x10^(-5),	SQNR:71.34383dB 

02/28/2024 03:39:43 - INFO - __main__ -   model.down_blocks.1.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 03:39:49 - INFO - __main__ -   MSE:0.01519x10^(-5),	SQNR:68.48515dB 

02/28/2024 03:39:49 - INFO - __main__ -   model.down_blocks.1.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 03:39:54 - INFO - __main__ -   MSE:0.00711x10^(-5),	SQNR:71.53251dB 

02/28/2024 03:39:54 - INFO - __main__ -   model.down_blocks.1.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 03:40:02 - INFO - __main__ -   MSE:0.00123x10^(-5),	SQNR:79.03340dB 

02/28/2024 03:40:02 - INFO - __main__ -   model.down_blocks.1.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 03:40:08 - INFO - __main__ -   MSE:0.00746x10^(-5),	SQNR:71.31419dB 

02/28/2024 03:40:08 - INFO - __main__ -   model.down_blocks.1.downsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 03:40:13 - INFO - __main__ -   MSE:0.02800x10^(-5),	SQNR:65.37340dB 

02/28/2024 03:40:13 - INFO - __main__ -   model.down_blocks.2.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:40:21 - INFO - __main__ -   MSE:0.00656x10^(-5),	SQNR:72.00731dB 

02/28/2024 03:40:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:40:26 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.64238dB 

02/28/2024 03:40:26 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:40:31 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.81850dB 

02/28/2024 03:40:31 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:40:36 - INFO - __main__ -   MSE:0.00095x10^(-5),	SQNR:80.27029dB 

02/28/2024 03:40:36 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:40:42 - INFO - __main__ -   MSE:0.00171x10^(-5),	SQNR:77.58655dB 

02/28/2024 03:40:42 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:40:47 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.32774dB 

02/28/2024 03:40:47 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:40:54 - INFO - __main__ -   MSE:0.00075x10^(-5),	SQNR:81.50293dB 

02/28/2024 03:40:54 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:40:59 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.68785dB 

02/28/2024 03:40:59 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:41:05 - INFO - __main__ -   MSE:0.00054x10^(-5),	SQNR:82.51492dB 

02/28/2024 03:41:05 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:41:10 - INFO - __main__ -   MSE:0.00084x10^(-5),	SQNR:80.68553dB 

02/28/2024 03:41:10 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:41:17 - INFO - __main__ -   MSE:0.00117x10^(-5),	SQNR:79.17363dB 

02/28/2024 03:41:17 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:41:23 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.69175dB 

02/28/2024 03:41:23 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:41:30 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.47195dB 

02/28/2024 03:41:30 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:41:34 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.55884dB 

02/28/2024 03:41:34 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:41:40 - INFO - __main__ -   MSE:0.00054x10^(-5),	SQNR:82.55341dB 

02/28/2024 03:41:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:41:47 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.62513dB 

02/28/2024 03:41:47 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:41:52 - INFO - __main__ -   MSE:0.00057x10^(-5),	SQNR:82.48911dB 

02/28/2024 03:41:52 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:41:58 - INFO - __main__ -   MSE:0.00088x10^(-5),	SQNR:80.38568dB 

02/28/2024 03:41:58 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:42:05 - INFO - __main__ -   MSE:0.00078x10^(-5),	SQNR:81.13671dB 

02/28/2024 03:42:06 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:42:10 - INFO - __main__ -   MSE:0.00105x10^(-5),	SQNR:79.96010dB 

02/28/2024 03:42:10 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:42:15 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.15735dB 

02/28/2024 03:42:15 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:42:23 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.51839dB 

02/28/2024 03:42:23 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:42:28 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.82191dB 

02/28/2024 03:42:28 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:42:32 - INFO - __main__ -   MSE:0.00054x10^(-5),	SQNR:82.48648dB 

02/28/2024 03:42:32 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:42:37 - INFO - __main__ -   MSE:0.00083x10^(-5),	SQNR:80.72256dB 

02/28/2024 03:42:37 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:42:43 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.92770dB 

02/28/2024 03:42:43 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:42:48 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.45000dB 

02/28/2024 03:42:48 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:42:54 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.20269dB 

02/28/2024 03:42:54 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:42:59 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.62608dB 

02/28/2024 03:42:59 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:43:05 - INFO - __main__ -   MSE:0.00090x10^(-5),	SQNR:80.43135dB 

02/28/2024 03:43:05 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:43:12 - INFO - __main__ -   MSE:0.00079x10^(-5),	SQNR:80.90215dB 

02/28/2024 03:43:12 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:43:19 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.44428dB 

02/28/2024 03:43:19 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:43:24 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.07466dB 

02/28/2024 03:43:24 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:43:30 - INFO - __main__ -   MSE:0.00124x10^(-5),	SQNR:79.31456dB 

02/28/2024 03:43:30 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:43:35 - INFO - __main__ -   MSE:0.00076x10^(-5),	SQNR:81.07159dB 

02/28/2024 03:43:35 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:43:40 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.67393dB 

02/28/2024 03:43:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:43:48 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.01606dB 

02/28/2024 03:43:48 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:43:53 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.82406dB 

02/28/2024 03:43:53 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:44:00 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.66567dB 

02/28/2024 03:44:00 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:44:06 - INFO - __main__ -   MSE:0.00100x10^(-5),	SQNR:80.13158dB 

02/28/2024 03:44:06 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:44:11 - INFO - __main__ -   MSE:0.00113x10^(-5),	SQNR:79.60523dB 

02/28/2024 03:44:11 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:44:15 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.84383dB 

02/28/2024 03:44:15 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:44:23 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78162dB 

02/28/2024 03:44:23 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:44:27 - INFO - __main__ -   MSE:0.00080x10^(-5),	SQNR:80.89863dB 

02/28/2024 03:44:27 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:44:32 - INFO - __main__ -   MSE:0.00060x10^(-5),	SQNR:82.12227dB 

02/28/2024 03:44:32 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:44:38 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71267dB 

02/28/2024 03:44:38 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:44:44 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.58080dB 

02/28/2024 03:44:44 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:44:48 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.91405dB 

02/28/2024 03:44:48 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:44:54 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.34022dB 

02/28/2024 03:44:54 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:45:01 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.36070dB 

02/28/2024 03:45:01 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:45:08 - INFO - __main__ -   MSE:0.00077x10^(-5),	SQNR:81.10950dB 

02/28/2024 03:45:08 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:45:14 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71013dB 

02/28/2024 03:45:14 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:45:20 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.88033dB 

02/28/2024 03:45:20 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:45:26 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.68305dB 

02/28/2024 03:45:26 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:45:32 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.51302dB 

02/28/2024 03:45:32 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:45:38 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.67062dB 

02/28/2024 03:45:38 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:45:44 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80630dB 

02/28/2024 03:45:44 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:45:49 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.48540dB 

02/28/2024 03:45:49 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:45:53 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76797dB 

02/28/2024 03:45:53 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:45:58 - INFO - __main__ -   MSE:0.00086x10^(-5),	SQNR:80.52708dB 

02/28/2024 03:45:58 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:46:04 - INFO - __main__ -   MSE:0.00080x10^(-5),	SQNR:80.85175dB 

02/28/2024 03:46:04 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:46:09 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.56921dB 

02/28/2024 03:46:09 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:46:15 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.86901dB 

02/28/2024 03:46:15 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:46:21 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.43027dB 

02/28/2024 03:46:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:46:25 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:82.99443dB 

02/28/2024 03:46:25 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:46:31 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76971dB 

02/28/2024 03:46:31 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:46:38 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.73717dB 

02/28/2024 03:46:38 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:46:44 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.68366dB 

02/28/2024 03:46:44 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:46:49 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.86845dB 

02/28/2024 03:46:49 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:46:56 - INFO - __main__ -   MSE:0.00146x10^(-5),	SQNR:78.83427dB 

02/28/2024 03:46:56 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:47:02 - INFO - __main__ -   MSE:0.00099x10^(-5),	SQNR:80.08657dB 

02/28/2024 03:47:02 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:47:08 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.72398dB 

02/28/2024 03:47:08 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:47:13 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.62778dB 

02/28/2024 03:47:13 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:47:21 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.25942dB 

02/28/2024 03:47:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:47:25 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.17186dB 

02/28/2024 03:47:25 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:47:32 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77007dB 

02/28/2024 03:47:32 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:47:37 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.67400dB 

02/28/2024 03:47:37 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:47:43 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.37995dB 

02/28/2024 03:47:43 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:47:49 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.84499dB 

02/28/2024 03:47:49 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:47:55 - INFO - __main__ -   MSE:0.00106x10^(-5),	SQNR:79.68802dB 

02/28/2024 03:47:55 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:48:02 - INFO - __main__ -   MSE:0.00073x10^(-5),	SQNR:81.19675dB 

02/28/2024 03:48:02 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:48:07 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.93671dB 

02/28/2024 03:48:07 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:48:13 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75618dB 

02/28/2024 03:48:13 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:48:21 - INFO - __main__ -   MSE:0.00057x10^(-5),	SQNR:82.26506dB 

02/28/2024 03:48:21 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:48:26 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.91808dB 

02/28/2024 03:48:26 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:48:32 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80237dB 

02/28/2024 03:48:32 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:48:40 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.68125dB 

02/28/2024 03:48:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:48:45 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.61859dB 

02/28/2024 03:48:45 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:48:50 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.66058dB 

02/28/2024 03:48:50 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:48:57 - INFO - __main__ -   MSE:0.00135x10^(-5),	SQNR:78.62700dB 

02/28/2024 03:48:57 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:49:03 - INFO - __main__ -   MSE:0.00065x10^(-5),	SQNR:81.75716dB 

02/28/2024 03:49:03 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:49:09 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.70298dB 

02/28/2024 03:49:09 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:49:16 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.57468dB 

02/28/2024 03:49:16 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:49:22 - INFO - __main__ -   MSE:0.00072x10^(-5),	SQNR:81.30573dB 

02/28/2024 03:49:22 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:49:27 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.24789dB 

02/28/2024 03:49:27 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:49:32 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.85299dB 

02/28/2024 03:49:32 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:49:40 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.87395dB 

02/28/2024 03:49:40 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:49:46 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.64273dB 

02/28/2024 03:49:46 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:49:50 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.33942dB 

02/28/2024 03:49:50 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:49:56 - INFO - __main__ -   MSE:0.00212x10^(-5),	SQNR:77.18771dB 

02/28/2024 03:49:56 - INFO - __main__ -   model.down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:50:03 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.15884dB 

02/28/2024 03:50:03 - INFO - __main__ -   model.down_blocks.2.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 03:50:08 - INFO - __main__ -   MSE:0.00789x10^(-5),	SQNR:71.30211dB 

02/28/2024 03:50:08 - INFO - __main__ -   model.down_blocks.2.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 03:50:13 - INFO - __main__ -   MSE:0.02745x10^(-5),	SQNR:66.06299dB 

02/28/2024 03:50:13 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:50:21 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.06348dB 

02/28/2024 03:50:21 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:50:25 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.81121dB 

02/28/2024 03:50:25 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:50:30 - INFO - __main__ -   MSE:0.00178x10^(-5),	SQNR:77.34400dB 

02/28/2024 03:50:30 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:50:35 - INFO - __main__ -   MSE:0.00262x10^(-5),	SQNR:75.79137dB 

02/28/2024 03:50:35 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:50:42 - INFO - __main__ -   MSE:0.00060x10^(-5),	SQNR:82.18344dB 

02/28/2024 03:50:42 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:50:46 - INFO - __main__ -   MSE:0.00147x10^(-5),	SQNR:78.74060dB 

02/28/2024 03:50:46 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:50:53 - INFO - __main__ -   MSE:0.01066x10^(-5),	SQNR:69.80434dB 

02/28/2024 03:50:53 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:50:58 - INFO - __main__ -   MSE:0.00722x10^(-5),	SQNR:72.77629dB 

02/28/2024 03:50:58 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:51:04 - INFO - __main__ -   MSE:0.00620x10^(-5),	SQNR:72.44403dB 

02/28/2024 03:51:04 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:51:11 - INFO - __main__ -   MSE:0.00549x10^(-5),	SQNR:72.80920dB 

02/28/2024 03:51:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:51:18 - INFO - __main__ -   MSE:0.00083x10^(-5),	SQNR:81.42559dB 

02/28/2024 03:51:18 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:51:25 - INFO - __main__ -   MSE:0.00078x10^(-5),	SQNR:81.21191dB 

02/28/2024 03:51:25 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:51:31 - INFO - __main__ -   MSE:0.00372x10^(-5),	SQNR:74.40679dB 

02/28/2024 03:51:31 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:51:36 - INFO - __main__ -   MSE:0.00462x10^(-5),	SQNR:73.95801dB 

02/28/2024 03:51:36 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:51:44 - INFO - __main__ -   MSE:0.00196x10^(-5),	SQNR:78.15427dB 

02/28/2024 03:51:44 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:51:49 - INFO - __main__ -   MSE:0.00245x10^(-5),	SQNR:75.92076dB 

02/28/2024 03:51:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:51:53 - INFO - __main__ -   MSE:0.02213x10^(-5),	SQNR:66.44758dB 

02/28/2024 03:51:53 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:52:00 - INFO - __main__ -   MSE:0.01413x10^(-5),	SQNR:68.60007dB 

02/28/2024 03:52:00 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:52:05 - INFO - __main__ -   MSE:0.01041x10^(-5),	SQNR:69.91640dB 

02/28/2024 03:52:05 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:52:10 - INFO - __main__ -   MSE:0.01222x10^(-5),	SQNR:69.60089dB 

02/28/2024 03:52:10 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:52:16 - INFO - __main__ -   MSE:0.00064x10^(-5),	SQNR:81.86657dB 

02/28/2024 03:52:16 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:52:22 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.66444dB 

02/28/2024 03:52:22 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:52:27 - INFO - __main__ -   MSE:0.00544x10^(-5),	SQNR:72.85139dB 

02/28/2024 03:52:27 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:52:33 - INFO - __main__ -   MSE:0.00226x10^(-5),	SQNR:76.44071dB 

02/28/2024 03:52:33 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:52:39 - INFO - __main__ -   MSE:0.00175x10^(-5),	SQNR:77.48123dB 

02/28/2024 03:52:39 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:52:44 - INFO - __main__ -   MSE:0.00781x10^(-5),	SQNR:74.45070dB 

02/28/2024 03:52:44 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:52:49 - INFO - __main__ -   MSE:0.00558x10^(-5),	SQNR:72.41605dB 

02/28/2024 03:52:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:52:55 - INFO - __main__ -   MSE:0.00440x10^(-5),	SQNR:73.51392dB 

02/28/2024 03:52:55 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:53:01 - INFO - __main__ -   MSE:0.01467x10^(-5),	SQNR:68.70692dB 

02/28/2024 03:53:01 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:53:08 - INFO - __main__ -   MSE:0.00888x10^(-5),	SQNR:70.50233dB 

02/28/2024 03:53:08 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:53:15 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.45299dB 

02/28/2024 03:53:16 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:53:20 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.64108dB 

02/28/2024 03:53:20 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:53:26 - INFO - __main__ -   MSE:0.00487x10^(-5),	SQNR:73.33605dB 

02/28/2024 03:53:26 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:53:32 - INFO - __main__ -   MSE:0.00264x10^(-5),	SQNR:75.68526dB 

02/28/2024 03:53:32 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:53:38 - INFO - __main__ -   MSE:0.00193x10^(-5),	SQNR:78.49341dB 

02/28/2024 03:53:38 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:53:44 - INFO - __main__ -   MSE:0.00117x10^(-5),	SQNR:79.50409dB 

02/28/2024 03:53:44 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:53:49 - INFO - __main__ -   MSE:0.00299x10^(-5),	SQNR:75.13647dB 

02/28/2024 03:53:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:53:55 - INFO - __main__ -   MSE:0.00478x10^(-5),	SQNR:74.05272dB 

02/28/2024 03:53:55 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:54:02 - INFO - __main__ -   MSE:0.01638x10^(-5),	SQNR:68.04699dB 

02/28/2024 03:54:02 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:54:06 - INFO - __main__ -   MSE:0.02914x10^(-5),	SQNR:67.28799dB 

02/28/2024 03:54:06 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:54:11 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.20431dB 

02/28/2024 03:54:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:54:19 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.26927dB 

02/28/2024 03:54:19 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:54:24 - INFO - __main__ -   MSE:0.00514x10^(-5),	SQNR:73.55956dB 

02/28/2024 03:54:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:54:28 - INFO - __main__ -   MSE:0.00193x10^(-5),	SQNR:77.31268dB 

02/28/2024 03:54:28 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:54:35 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.49924dB 

02/28/2024 03:54:35 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:54:41 - INFO - __main__ -   MSE:0.00102x10^(-5),	SQNR:80.03603dB 

02/28/2024 03:54:41 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:54:46 - INFO - __main__ -   MSE:0.00408x10^(-5),	SQNR:74.62804dB 

02/28/2024 03:54:46 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:54:52 - INFO - __main__ -   MSE:0.00416x10^(-5),	SQNR:74.69568dB 

02/28/2024 03:54:52 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:54:59 - INFO - __main__ -   MSE:0.05524x10^(-5),	SQNR:64.63518dB 

02/28/2024 03:54:59 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:55:03 - INFO - __main__ -   MSE:0.01787x10^(-5),	SQNR:67.89149dB 

02/28/2024 03:55:03 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:55:09 - INFO - __main__ -   MSE:0.00065x10^(-5),	SQNR:81.72334dB 

02/28/2024 03:55:09 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:55:15 - INFO - __main__ -   MSE:0.00068x10^(-5),	SQNR:81.54141dB 

02/28/2024 03:55:15 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:55:21 - INFO - __main__ -   MSE:0.00460x10^(-5),	SQNR:73.59180dB 

02/28/2024 03:55:21 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:55:28 - INFO - __main__ -   MSE:0.00141x10^(-5),	SQNR:78.34038dB 

02/28/2024 03:55:28 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:55:35 - INFO - __main__ -   MSE:0.00104x10^(-5),	SQNR:80.43445dB 

02/28/2024 03:55:35 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:55:42 - INFO - __main__ -   MSE:0.00127x10^(-5),	SQNR:79.46010dB 

02/28/2024 03:55:42 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:55:47 - INFO - __main__ -   MSE:0.00533x10^(-5),	SQNR:73.42494dB 

02/28/2024 03:55:47 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:55:53 - INFO - __main__ -   MSE:0.00248x10^(-5),	SQNR:75.89997dB 

02/28/2024 03:55:53 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:56:00 - INFO - __main__ -   MSE:0.03304x10^(-5),	SQNR:65.25903dB 

02/28/2024 03:56:00 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:56:06 - INFO - __main__ -   MSE:0.01895x10^(-5),	SQNR:67.08814dB 

02/28/2024 03:56:06 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:56:12 - INFO - __main__ -   MSE:0.00080x10^(-5),	SQNR:81.00429dB 

02/28/2024 03:56:12 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:56:19 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.42868dB 

02/28/2024 03:56:19 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:56:24 - INFO - __main__ -   MSE:0.00296x10^(-5),	SQNR:75.70799dB 

02/28/2024 03:56:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:56:28 - INFO - __main__ -   MSE:0.00173x10^(-5),	SQNR:77.44321dB 

02/28/2024 03:56:28 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:56:34 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.43044dB 

02/28/2024 03:56:34 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:56:40 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.31443dB 

02/28/2024 03:56:40 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:56:44 - INFO - __main__ -   MSE:0.00105x10^(-5),	SQNR:79.72543dB 

02/28/2024 03:56:44 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:56:49 - INFO - __main__ -   MSE:0.00132x10^(-5),	SQNR:78.95303dB 

02/28/2024 03:56:49 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:56:56 - INFO - __main__ -   MSE:0.04983x10^(-5),	SQNR:63.67650dB 

02/28/2024 03:56:56 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:57:01 - INFO - __main__ -   MSE:0.01877x10^(-5),	SQNR:67.53114dB 

02/28/2024 03:57:01 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:57:07 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.27154dB 

02/28/2024 03:57:07 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:57:14 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.32159dB 

02/28/2024 03:57:14 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:57:19 - INFO - __main__ -   MSE:0.00312x10^(-5),	SQNR:75.10116dB 

02/28/2024 03:57:19 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:57:24 - INFO - __main__ -   MSE:0.00213x10^(-5),	SQNR:77.20296dB 

02/28/2024 03:57:24 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:57:29 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.34804dB 

02/28/2024 03:57:29 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:57:35 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.38605dB 

02/28/2024 03:57:35 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:57:41 - INFO - __main__ -   MSE:0.00113x10^(-5),	SQNR:79.40685dB 

02/28/2024 03:57:41 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:57:46 - INFO - __main__ -   MSE:0.00078x10^(-5),	SQNR:80.91925dB 

02/28/2024 03:57:46 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:57:53 - INFO - __main__ -   MSE:0.01646x10^(-5),	SQNR:67.72797dB 

02/28/2024 03:57:53 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:58:02 - INFO - __main__ -   MSE:0.01080x10^(-5),	SQNR:69.55896dB 

02/28/2024 03:58:02 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:58:06 - INFO - __main__ -   MSE:0.00077x10^(-5),	SQNR:81.13040dB 

02/28/2024 03:58:06 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:58:13 - INFO - __main__ -   MSE:0.00086x10^(-5),	SQNR:80.85543dB 

02/28/2024 03:58:13 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:58:19 - INFO - __main__ -   MSE:0.00305x10^(-5),	SQNR:75.07815dB 

02/28/2024 03:58:19 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:58:23 - INFO - __main__ -   MSE:0.00189x10^(-5),	SQNR:77.28387dB 

02/28/2024 03:58:23 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:58:28 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.52400dB 

02/28/2024 03:58:28 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:58:35 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.46976dB 

02/28/2024 03:58:35 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:58:41 - INFO - __main__ -   MSE:0.00090x10^(-5),	SQNR:80.32087dB 

02/28/2024 03:58:41 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:58:45 - INFO - __main__ -   MSE:0.00076x10^(-5),	SQNR:81.10704dB 

02/28/2024 03:58:45 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:58:53 - INFO - __main__ -   MSE:0.02874x10^(-5),	SQNR:65.59750dB 

02/28/2024 03:58:53 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:58:59 - INFO - __main__ -   MSE:0.01082x10^(-5),	SQNR:70.56381dB 

02/28/2024 03:58:59 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 03:59:04 - INFO - __main__ -   MSE:0.00093x10^(-5),	SQNR:80.15509dB 

02/28/2024 03:59:04 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 03:59:11 - INFO - __main__ -   MSE:0.00077x10^(-5),	SQNR:80.95821dB 

02/28/2024 03:59:11 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 03:59:17 - INFO - __main__ -   MSE:0.00184x10^(-5),	SQNR:77.19337dB 

02/28/2024 03:59:17 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:59:22 - INFO - __main__ -   MSE:0.00151x10^(-5),	SQNR:78.04917dB 

02/28/2024 03:59:22 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 03:59:29 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.57800dB 

02/28/2024 03:59:29 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 03:59:36 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.73209dB 

02/28/2024 03:59:36 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 03:59:43 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.19231dB 

02/28/2024 03:59:43 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 03:59:47 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.90054dB 

02/28/2024 03:59:47 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 03:59:52 - INFO - __main__ -   MSE:0.01968x10^(-5),	SQNR:66.99359dB 

02/28/2024 03:59:52 - INFO - __main__ -   model.down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 03:59:59 - INFO - __main__ -   MSE:0.00233x10^(-5),	SQNR:76.27761dB 

02/28/2024 03:59:59 - INFO - __main__ -   model.down_blocks.2.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 04:00:05 - INFO - __main__ -   MSE:0.01267x10^(-5),	SQNR:68.86078dB 

02/28/2024 04:00:05 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 04:00:11 - INFO - __main__ -   MSE:0.00566x10^(-5),	SQNR:72.89780dB 

02/28/2024 04:00:11 - INFO - __main__ -   model.down_blocks.2.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:00:18 - INFO - __main__ -   MSE:0.01264x10^(-5),	SQNR:69.61356dB 

02/28/2024 04:00:18 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 04:00:24 - INFO - __main__ -   MSE:0.00647x10^(-5),	SQNR:72.33810dB 

02/28/2024 04:00:24 - INFO - __main__ -   model.down_blocks.2.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:00:29 - INFO - __main__ -   MSE:0.01142x10^(-5),	SQNR:69.29713dB 

02/28/2024 04:00:29 - INFO - __main__ -   model.down_blocks.2.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 04:00:36 - INFO - __main__ -   MSE:0.00773x10^(-5),	SQNR:71.48018dB 

02/28/2024 04:00:36 - INFO - __main__ -   model.down_blocks.2.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:00:41 - INFO - __main__ -   MSE:0.01692x10^(-5),	SQNR:68.84888dB 

02/28/2024 04:00:41 - INFO - __main__ -   model.down_blocks.2.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 04:00:46 - INFO - __main__ -   MSE:0.00706x10^(-5),	SQNR:71.87050dB 

02/28/2024 04:00:46 - INFO - __main__ -   model.up_blocks.0.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 04:00:53 - INFO - __main__ -   MSE:0.00856x10^(-5),	SQNR:70.63739dB 

02/28/2024 04:00:53 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:00:59 - INFO - __main__ -   MSE:0.00075x10^(-5),	SQNR:81.07916dB 

02/28/2024 04:00:59 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:01:03 - INFO - __main__ -   MSE:0.00073x10^(-5),	SQNR:81.21569dB 

02/28/2024 04:01:03 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:01:09 - INFO - __main__ -   MSE:0.00293x10^(-5),	SQNR:75.28418dB 

02/28/2024 04:01:09 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:01:15 - INFO - __main__ -   MSE:0.00507x10^(-5),	SQNR:72.81586dB 

02/28/2024 04:01:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:01:21 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.37762dB 

02/28/2024 04:01:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:01:27 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.81493dB 

02/28/2024 04:01:27 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:01:33 - INFO - __main__ -   MSE:0.00078x10^(-5),	SQNR:81.01514dB 

02/28/2024 04:01:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:01:39 - INFO - __main__ -   MSE:0.00077x10^(-5),	SQNR:81.05987dB 

02/28/2024 04:01:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:01:45 - INFO - __main__ -   MSE:0.00265x10^(-5),	SQNR:75.72948dB 

02/28/2024 04:01:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:01:51 - INFO - __main__ -   MSE:0.00337x10^(-5),	SQNR:74.81100dB 

02/28/2024 04:01:51 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:01:59 - INFO - __main__ -   MSE:0.00077x10^(-5),	SQNR:81.01082dB 

02/28/2024 04:01:59 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:02:04 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.66304dB 

02/28/2024 04:02:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:02:09 - INFO - __main__ -   MSE:0.00314x10^(-5),	SQNR:75.30994dB 

02/28/2024 04:02:09 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:02:15 - INFO - __main__ -   MSE:0.00323x10^(-5),	SQNR:74.72006dB 

02/28/2024 04:02:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:02:21 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.18313dB 

02/28/2024 04:02:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:02:25 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.70622dB 

02/28/2024 04:02:25 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:02:31 - INFO - __main__ -   MSE:0.00163x10^(-5),	SQNR:78.47486dB 

02/28/2024 04:02:31 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:02:37 - INFO - __main__ -   MSE:0.00109x10^(-5),	SQNR:79.52170dB 

02/28/2024 04:02:37 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:02:41 - INFO - __main__ -   MSE:0.00396x10^(-5),	SQNR:73.84522dB 

02/28/2024 04:02:41 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:02:46 - INFO - __main__ -   MSE:0.00386x10^(-5),	SQNR:73.99899dB 

02/28/2024 04:02:46 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:02:53 - INFO - __main__ -   MSE:0.00068x10^(-5),	SQNR:81.47053dB 

02/28/2024 04:02:53 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:02:58 - INFO - __main__ -   MSE:0.00081x10^(-5),	SQNR:80.80701dB 

02/28/2024 04:02:58 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:03:03 - INFO - __main__ -   MSE:0.00221x10^(-5),	SQNR:76.41864dB 

02/28/2024 04:03:03 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:03:10 - INFO - __main__ -   MSE:0.00224x10^(-5),	SQNR:76.32487dB 

02/28/2024 04:03:10 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:03:16 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.80392dB 

02/28/2024 04:03:16 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:03:22 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.60271dB 

02/28/2024 04:03:22 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:03:28 - INFO - __main__ -   MSE:0.00149x10^(-5),	SQNR:78.75783dB 

02/28/2024 04:03:28 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:03:34 - INFO - __main__ -   MSE:0.00099x10^(-5),	SQNR:79.85278dB 

02/28/2024 04:03:34 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:03:41 - INFO - __main__ -   MSE:0.00428x10^(-5),	SQNR:73.70058dB 

02/28/2024 04:03:41 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:03:47 - INFO - __main__ -   MSE:0.00424x10^(-5),	SQNR:73.58536dB 

02/28/2024 04:03:47 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:03:55 - INFO - __main__ -   MSE:0.00068x10^(-5),	SQNR:81.49918dB 

02/28/2024 04:03:55 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:04:02 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.63060dB 

02/28/2024 04:04:02 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:04:07 - INFO - __main__ -   MSE:0.00263x10^(-5),	SQNR:76.31520dB 

02/28/2024 04:04:07 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:04:15 - INFO - __main__ -   MSE:0.00158x10^(-5),	SQNR:77.84555dB 

02/28/2024 04:04:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:04:20 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.05296dB 

02/28/2024 04:04:20 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:04:25 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.30484dB 

02/28/2024 04:04:25 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:04:31 - INFO - __main__ -   MSE:0.00071x10^(-5),	SQNR:81.28603dB 

02/28/2024 04:04:31 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:04:36 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.62617dB 

02/28/2024 04:04:36 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:04:41 - INFO - __main__ -   MSE:0.00563x10^(-5),	SQNR:72.53903dB 

02/28/2024 04:04:41 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:04:46 - INFO - __main__ -   MSE:0.00454x10^(-5),	SQNR:73.41865dB 

02/28/2024 04:04:46 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:04:52 - INFO - __main__ -   MSE:0.00072x10^(-5),	SQNR:81.25710dB 

02/28/2024 04:04:52 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:04:58 - INFO - __main__ -   MSE:0.00067x10^(-5),	SQNR:81.55939dB 

02/28/2024 04:04:58 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:05:03 - INFO - __main__ -   MSE:0.00182x10^(-5),	SQNR:77.22957dB 

02/28/2024 04:05:03 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:05:08 - INFO - __main__ -   MSE:0.00140x10^(-5),	SQNR:78.35251dB 

02/28/2024 04:05:08 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:05:15 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.70647dB 

02/28/2024 04:05:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:05:22 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.67065dB 

02/28/2024 04:05:22 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:05:27 - INFO - __main__ -   MSE:0.00054x10^(-5),	SQNR:82.46951dB 

02/28/2024 04:05:27 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:05:33 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.44468dB 

02/28/2024 04:05:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:05:39 - INFO - __main__ -   MSE:0.00521x10^(-5),	SQNR:72.68880dB 

02/28/2024 04:05:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:05:45 - INFO - __main__ -   MSE:0.00418x10^(-5),	SQNR:73.71045dB 

02/28/2024 04:05:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:05:50 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.62839dB 

02/28/2024 04:05:50 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:05:56 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.10165dB 

02/28/2024 04:05:56 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:06:02 - INFO - __main__ -   MSE:0.00139x10^(-5),	SQNR:78.41165dB 

02/28/2024 04:06:02 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:06:06 - INFO - __main__ -   MSE:0.00110x10^(-5),	SQNR:79.46936dB 

02/28/2024 04:06:06 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:06:15 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71432dB 

02/28/2024 04:06:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:06:20 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.73087dB 

02/28/2024 04:06:20 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:06:24 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.70520dB 

02/28/2024 04:06:24 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:06:31 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.31096dB 

02/28/2024 04:06:31 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:06:36 - INFO - __main__ -   MSE:0.00520x10^(-5),	SQNR:72.76967dB 

02/28/2024 04:06:36 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:06:41 - INFO - __main__ -   MSE:0.00450x10^(-5),	SQNR:73.45184dB 

02/28/2024 04:06:41 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:06:46 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.18748dB 

02/28/2024 04:06:46 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:06:52 - INFO - __main__ -   MSE:0.00057x10^(-5),	SQNR:82.26873dB 

02/28/2024 04:06:52 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:06:57 - INFO - __main__ -   MSE:0.00105x10^(-5),	SQNR:79.60633dB 

02/28/2024 04:06:57 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:07:03 - INFO - __main__ -   MSE:0.00088x10^(-5),	SQNR:80.40734dB 

02/28/2024 04:07:03 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:07:09 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.74413dB 

02/28/2024 04:07:09 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:07:16 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.69753dB 

02/28/2024 04:07:16 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:07:21 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.41132dB 

02/28/2024 04:07:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:07:26 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65491dB 

02/28/2024 04:07:26 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:07:33 - INFO - __main__ -   MSE:0.00658x10^(-5),	SQNR:71.78891dB 

02/28/2024 04:07:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:07:39 - INFO - __main__ -   MSE:0.00303x10^(-5),	SQNR:75.01891dB 

02/28/2024 04:07:39 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:07:44 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.11478dB 

02/28/2024 04:07:44 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:07:51 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.45947dB 

02/28/2024 04:07:51 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:07:57 - INFO - __main__ -   MSE:0.00106x10^(-5),	SQNR:79.58167dB 

02/28/2024 04:07:57 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:08:01 - INFO - __main__ -   MSE:0.00075x10^(-5),	SQNR:81.05784dB 

02/28/2024 04:08:01 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:08:06 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76511dB 

02/28/2024 04:08:06 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:08:12 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76552dB 

02/28/2024 04:08:12 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:08:18 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.43959dB 

02/28/2024 04:08:18 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:08:23 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.67122dB 

02/28/2024 04:08:23 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:08:29 - INFO - __main__ -   MSE:0.00574x10^(-5),	SQNR:72.28264dB 

02/28/2024 04:08:29 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:08:38 - INFO - __main__ -   MSE:0.00247x10^(-5),	SQNR:75.98969dB 

02/28/2024 04:08:38 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:08:42 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.66370dB 

02/28/2024 04:08:42 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:08:49 - INFO - __main__ -   MSE:0.00061x10^(-5),	SQNR:81.96593dB 

02/28/2024 04:08:49 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:08:57 - INFO - __main__ -   MSE:0.00081x10^(-5),	SQNR:80.70442dB 

02/28/2024 04:08:57 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:09:02 - INFO - __main__ -   MSE:0.00062x10^(-5),	SQNR:81.87726dB 

02/28/2024 04:09:02 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:09:08 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76088dB 

02/28/2024 04:09:08 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:09:15 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76416dB 

02/28/2024 04:09:15 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:09:21 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.63577dB 

02/28/2024 04:09:21 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:09:26 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.63673dB 

02/28/2024 04:09:26 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:09:33 - INFO - __main__ -   MSE:0.00392x10^(-5),	SQNR:73.94514dB 

02/28/2024 04:09:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:09:40 - INFO - __main__ -   MSE:0.00161x10^(-5),	SQNR:77.81963dB 

02/28/2024 04:09:40 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:09:45 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.38964dB 

02/28/2024 04:09:45 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:09:53 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.17876dB 

02/28/2024 04:09:53 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:09:58 - INFO - __main__ -   MSE:0.00082x10^(-5),	SQNR:80.68330dB 

02/28/2024 04:09:58 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:10:04 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.22672dB 

02/28/2024 04:10:04 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:10:09 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80681dB 

02/28/2024 04:10:09 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:10:17 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75500dB 

02/28/2024 04:10:17 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:10:22 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.73315dB 

02/28/2024 04:10:22 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:10:27 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75150dB 

02/28/2024 04:10:27 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:10:33 - INFO - __main__ -   MSE:0.00358x10^(-5),	SQNR:74.36391dB 

02/28/2024 04:10:33 - INFO - __main__ -   model.up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:10:38 - INFO - __main__ -   MSE:0.00098x10^(-5),	SQNR:79.90664dB 

02/28/2024 04:10:38 - INFO - __main__ -   model.up_blocks.0.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 04:10:43 - INFO - __main__ -   MSE:0.00279x10^(-5),	SQNR:75.41246dB 

02/28/2024 04:10:43 - INFO - __main__ -   model.up_blocks.0.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 04:10:48 - INFO - __main__ -   MSE:0.00483x10^(-5),	SQNR:73.21973dB 

02/28/2024 04:10:48 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:10:54 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.56163dB 

02/28/2024 04:10:55 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:10:59 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.60490dB 

02/28/2024 04:10:59 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:11:04 - INFO - __main__ -   MSE:0.00128x10^(-5),	SQNR:79.00020dB 

02/28/2024 04:11:04 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:11:09 - INFO - __main__ -   MSE:0.00166x10^(-5),	SQNR:77.60867dB 

02/28/2024 04:11:09 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:11:15 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.68990dB 

02/28/2024 04:11:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:11:20 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.46347dB 

02/28/2024 04:11:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:11:26 - INFO - __main__ -   MSE:0.00056x10^(-5),	SQNR:82.34172dB 

02/28/2024 04:11:26 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:11:31 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.89496dB 

02/28/2024 04:11:31 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:11:37 - INFO - __main__ -   MSE:0.00158x10^(-5),	SQNR:77.81624dB 

02/28/2024 04:11:37 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:11:43 - INFO - __main__ -   MSE:0.00209x10^(-5),	SQNR:76.83752dB 

02/28/2024 04:11:43 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:11:50 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.68855dB 

02/28/2024 04:11:50 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:11:55 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.94872dB 

02/28/2024 04:11:55 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:12:02 - INFO - __main__ -   MSE:0.00110x10^(-5),	SQNR:79.37943dB 

02/28/2024 04:12:02 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:12:06 - INFO - __main__ -   MSE:0.00139x10^(-5),	SQNR:78.44987dB 

02/28/2024 04:12:06 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:12:14 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.18975dB 

02/28/2024 04:12:14 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:12:20 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.74945dB 

02/28/2024 04:12:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:12:25 - INFO - __main__ -   MSE:0.00096x10^(-5),	SQNR:80.02959dB 

02/28/2024 04:12:25 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:12:29 - INFO - __main__ -   MSE:0.00121x10^(-5),	SQNR:79.57432dB 

02/28/2024 04:12:29 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:12:36 - INFO - __main__ -   MSE:0.00180x10^(-5),	SQNR:77.31567dB 

02/28/2024 04:12:36 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:12:41 - INFO - __main__ -   MSE:0.00162x10^(-5),	SQNR:77.73766dB 

02/28/2024 04:12:41 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:12:46 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.00385dB 

02/28/2024 04:12:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:12:52 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.29509dB 

02/28/2024 04:12:52 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:12:57 - INFO - __main__ -   MSE:0.00143x10^(-5),	SQNR:78.26653dB 

02/28/2024 04:12:57 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:13:01 - INFO - __main__ -   MSE:0.00102x10^(-5),	SQNR:79.76907dB 

02/28/2024 04:13:01 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:13:08 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.36932dB 

02/28/2024 04:13:08 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:13:15 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.70030dB 

02/28/2024 04:13:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:13:20 - INFO - __main__ -   MSE:0.00099x10^(-5),	SQNR:79.90178dB 

02/28/2024 04:13:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:13:26 - INFO - __main__ -   MSE:0.00073x10^(-5),	SQNR:81.18810dB 

02/28/2024 04:13:26 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:13:33 - INFO - __main__ -   MSE:0.00214x10^(-5),	SQNR:76.52632dB 

02/28/2024 04:13:33 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:13:39 - INFO - __main__ -   MSE:0.00160x10^(-5),	SQNR:77.79166dB 

02/28/2024 04:13:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:13:45 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.64121dB 

02/28/2024 04:13:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:13:52 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.65291dB 

02/28/2024 04:13:52 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:13:59 - INFO - __main__ -   MSE:0.00127x10^(-5),	SQNR:78.78448dB 

02/28/2024 04:13:59 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:14:03 - INFO - __main__ -   MSE:0.00088x10^(-5),	SQNR:80.38274dB 

02/28/2024 04:14:03 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:14:08 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.80637dB 

02/28/2024 04:14:08 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:14:15 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.82587dB 

02/28/2024 04:14:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:14:20 - INFO - __main__ -   MSE:0.00078x10^(-5),	SQNR:80.87402dB 

02/28/2024 04:14:20 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:14:24 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.62251dB 

02/28/2024 04:14:24 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:14:31 - INFO - __main__ -   MSE:0.00259x10^(-5),	SQNR:75.70407dB 

02/28/2024 04:14:31 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:14:37 - INFO - __main__ -   MSE:0.00172x10^(-5),	SQNR:77.46450dB 

02/28/2024 04:14:37 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:14:41 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.76389dB 

02/28/2024 04:14:41 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:14:47 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.88951dB 

02/28/2024 04:14:47 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:14:52 - INFO - __main__ -   MSE:0.00104x10^(-5),	SQNR:79.63746dB 

02/28/2024 04:14:52 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:14:57 - INFO - __main__ -   MSE:0.00081x10^(-5),	SQNR:80.75217dB 

02/28/2024 04:14:57 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:15:02 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.44128dB 

02/28/2024 04:15:02 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:15:10 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.20555dB 

02/28/2024 04:15:10 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:15:15 - INFO - __main__ -   MSE:0.00064x10^(-5),	SQNR:81.76655dB 

02/28/2024 04:15:15 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:15:21 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.61645dB 

02/28/2024 04:15:21 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:15:27 - INFO - __main__ -   MSE:0.00262x10^(-5),	SQNR:75.63281dB 

02/28/2024 04:15:27 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:15:34 - INFO - __main__ -   MSE:0.00184x10^(-5),	SQNR:77.19398dB 

02/28/2024 04:15:34 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:15:41 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.80465dB 

02/28/2024 04:15:41 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:15:46 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.74548dB 

02/28/2024 04:15:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:15:51 - INFO - __main__ -   MSE:0.00100x10^(-5),	SQNR:79.82135dB 

02/28/2024 04:15:51 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:15:58 - INFO - __main__ -   MSE:0.00076x10^(-5),	SQNR:81.00774dB 

02/28/2024 04:15:58 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:16:03 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.63755dB 

02/28/2024 04:16:03 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:16:09 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.54338dB 

02/28/2024 04:16:09 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:16:17 - INFO - __main__ -   MSE:0.00057x10^(-5),	SQNR:82.24744dB 

02/28/2024 04:16:17 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:16:21 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.68086dB 

02/28/2024 04:16:21 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:16:26 - INFO - __main__ -   MSE:0.00231x10^(-5),	SQNR:76.16510dB 

02/28/2024 04:16:26 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:16:34 - INFO - __main__ -   MSE:0.00180x10^(-5),	SQNR:77.26292dB 

02/28/2024 04:16:34 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:16:39 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.67330dB 

02/28/2024 04:16:39 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:16:43 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.83613dB 

02/28/2024 04:16:43 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:16:49 - INFO - __main__ -   MSE:0.00083x10^(-5),	SQNR:80.59573dB 

02/28/2024 04:16:49 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:16:55 - INFO - __main__ -   MSE:0.00075x10^(-5),	SQNR:81.05053dB 

02/28/2024 04:16:55 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:17:00 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.66925dB 

02/28/2024 04:17:00 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:17:06 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.53047dB 

02/28/2024 04:17:06 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:17:13 - INFO - __main__ -   MSE:0.00047x10^(-5),	SQNR:83.04880dB 

02/28/2024 04:17:13 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:17:18 - INFO - __main__ -   MSE:0.00047x10^(-5),	SQNR:83.11752dB 

02/28/2024 04:17:18 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:17:24 - INFO - __main__ -   MSE:0.00219x10^(-5),	SQNR:76.39928dB 

02/28/2024 04:17:24 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:17:30 - INFO - __main__ -   MSE:0.00151x10^(-5),	SQNR:78.05145dB 

02/28/2024 04:17:30 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:17:37 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.67003dB 

02/28/2024 04:17:37 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:17:42 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.01155dB 

02/28/2024 04:17:42 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:17:46 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.42907dB 

02/28/2024 04:17:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:17:52 - INFO - __main__ -   MSE:0.00062x10^(-5),	SQNR:81.90744dB 

02/28/2024 04:17:52 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:17:58 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.81879dB 

02/28/2024 04:17:58 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:18:02 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77572dB 

02/28/2024 04:18:02 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:18:07 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.34382dB 

02/28/2024 04:18:07 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:18:13 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.47542dB 

02/28/2024 04:18:13 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:18:18 - INFO - __main__ -   MSE:0.00218x10^(-5),	SQNR:76.48251dB 

02/28/2024 04:18:18 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:18:23 - INFO - __main__ -   MSE:0.00144x10^(-5),	SQNR:78.27008dB 

02/28/2024 04:18:23 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:18:31 - INFO - __main__ -   MSE:0.00063x10^(-5),	SQNR:81.83904dB 

02/28/2024 04:18:31 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:18:36 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.52916dB 

02/28/2024 04:18:36 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:18:41 - INFO - __main__ -   MSE:0.00070x10^(-5),	SQNR:81.38840dB 

02/28/2024 04:18:41 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:18:46 - INFO - __main__ -   MSE:0.00065x10^(-5),	SQNR:81.64589dB 

02/28/2024 04:18:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:18:53 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.82069dB 

02/28/2024 04:18:53 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:18:59 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79073dB 

02/28/2024 04:18:59 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:19:04 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65244dB 

02/28/2024 04:19:04 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:19:10 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.69812dB 

02/28/2024 04:19:10 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:19:17 - INFO - __main__ -   MSE:0.00194x10^(-5),	SQNR:76.95436dB 

02/28/2024 04:19:17 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:19:22 - INFO - __main__ -   MSE:0.00105x10^(-5),	SQNR:79.61990dB 

02/28/2024 04:19:22 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:19:29 - INFO - __main__ -   MSE:0.00055x10^(-5),	SQNR:82.36929dB 

02/28/2024 04:19:29 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:19:36 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.79737dB 

02/28/2024 04:19:36 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:19:41 - INFO - __main__ -   MSE:0.00065x10^(-5),	SQNR:81.67712dB 

02/28/2024 04:19:41 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:19:46 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.69391dB 

02/28/2024 04:19:46 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:19:54 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79662dB 

02/28/2024 04:19:54 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:19:59 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78128dB 

02/28/2024 04:19:59 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:20:05 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77683dB 

02/28/2024 04:20:05 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:20:11 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71706dB 

02/28/2024 04:20:11 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:20:19 - INFO - __main__ -   MSE:0.00152x10^(-5),	SQNR:77.99558dB 

02/28/2024 04:20:19 - INFO - __main__ -   model.up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:20:25 - INFO - __main__ -   MSE:0.00070x10^(-5),	SQNR:81.37057dB 

02/28/2024 04:20:25 - INFO - __main__ -   model.up_blocks.0.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 04:20:33 - INFO - __main__ -   MSE:0.00192x10^(-5),	SQNR:77.00722dB 

02/28/2024 04:20:33 - INFO - __main__ -   model.up_blocks.0.attentions.2.proj_in: weight_quant=True, act_quant=False
02/28/2024 04:20:41 - INFO - __main__ -   MSE:0.00314x10^(-5),	SQNR:74.90545dB 

02/28/2024 04:20:41 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:20:46 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.58018dB 

02/28/2024 04:20:46 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:20:52 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.85094dB 

02/28/2024 04:20:52 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:20:58 - INFO - __main__ -   MSE:0.00077x10^(-5),	SQNR:80.97200dB 

02/28/2024 04:20:58 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:21:02 - INFO - __main__ -   MSE:0.00125x10^(-5),	SQNR:78.87128dB 

02/28/2024 04:21:02 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:21:07 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78943dB 

02/28/2024 04:21:07 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:21:15 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79141dB 

02/28/2024 04:21:15 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:21:19 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.63861dB 

02/28/2024 04:21:19 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:21:25 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75288dB 

02/28/2024 04:21:25 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:21:31 - INFO - __main__ -   MSE:0.00132x10^(-5),	SQNR:78.60353dB 

02/28/2024 04:21:31 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:21:37 - INFO - __main__ -   MSE:0.00109x10^(-5),	SQNR:79.42607dB 

02/28/2024 04:21:37 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:21:43 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.30397dB 

02/28/2024 04:21:43 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:21:48 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.29578dB 

02/28/2024 04:21:48 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:21:55 - INFO - __main__ -   MSE:0.00070x10^(-5),	SQNR:81.36600dB 

02/28/2024 04:21:55 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:22:00 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.42619dB 

02/28/2024 04:22:00 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:22:05 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80964dB 

02/28/2024 04:22:05 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:22:10 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76511dB 

02/28/2024 04:22:10 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:22:17 - INFO - __main__ -   MSE:0.00047x10^(-5),	SQNR:83.08228dB 

02/28/2024 04:22:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:22:22 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.57590dB 

02/28/2024 04:22:22 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:22:27 - INFO - __main__ -   MSE:0.00107x10^(-5),	SQNR:79.51085dB 

02/28/2024 04:22:27 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:22:35 - INFO - __main__ -   MSE:0.00090x10^(-5),	SQNR:80.24316dB 

02/28/2024 04:22:35 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:22:40 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.34207dB 

02/28/2024 04:22:40 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:22:44 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.34325dB 

02/28/2024 04:22:44 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:22:51 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.61217dB 

02/28/2024 04:22:51 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:22:56 - INFO - __main__ -   MSE:0.00060x10^(-5),	SQNR:81.99363dB 

02/28/2024 04:22:56 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:23:02 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78009dB 

02/28/2024 04:23:02 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:23:08 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.73418dB 

02/28/2024 04:23:08 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:23:14 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.15514dB 

02/28/2024 04:23:14 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:23:20 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.58974dB 

02/28/2024 04:23:20 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:23:26 - INFO - __main__ -   MSE:0.00099x10^(-5),	SQNR:79.86530dB 

02/28/2024 04:23:26 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:23:32 - INFO - __main__ -   MSE:0.00087x10^(-5),	SQNR:80.41233dB 

02/28/2024 04:23:32 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:23:39 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.31694dB 

02/28/2024 04:23:39 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:23:43 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.39282dB 

02/28/2024 04:23:43 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:23:48 - INFO - __main__ -   MSE:0.00063x10^(-5),	SQNR:81.78564dB 

02/28/2024 04:23:48 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:23:54 - INFO - __main__ -   MSE:0.00054x10^(-5),	SQNR:82.46037dB 

02/28/2024 04:23:54 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:24:00 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.82068dB 

02/28/2024 04:24:00 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:24:05 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77867dB 

02/28/2024 04:24:05 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:24:13 - INFO - __main__ -   MSE:0.00044x10^(-5),	SQNR:83.40203dB 

02/28/2024 04:24:13 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:24:17 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.69387dB 

02/28/2024 04:24:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:24:22 - INFO - __main__ -   MSE:0.00093x10^(-5),	SQNR:80.12572dB 

02/28/2024 04:24:22 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:24:27 - INFO - __main__ -   MSE:0.00085x10^(-5),	SQNR:80.51109dB 

02/28/2024 04:24:27 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:24:34 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.50576dB 

02/28/2024 04:24:34 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:24:39 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.52827dB 

02/28/2024 04:24:39 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:24:44 - INFO - __main__ -   MSE:0.00056x10^(-5),	SQNR:82.30758dB 

02/28/2024 04:24:44 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:24:51 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.67850dB 

02/28/2024 04:24:51 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:24:56 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79060dB 

02/28/2024 04:24:56 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:25:03 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79339dB 

02/28/2024 04:25:03 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:25:09 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77023dB 

02/28/2024 04:25:09 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:25:14 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75620dB 

02/28/2024 04:25:14 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:25:20 - INFO - __main__ -   MSE:0.00097x10^(-5),	SQNR:79.92719dB 

02/28/2024 04:25:20 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:25:26 - INFO - __main__ -   MSE:0.00085x10^(-5),	SQNR:80.49190dB 

02/28/2024 04:25:26 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:25:32 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.57263dB 

02/28/2024 04:25:32 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:25:38 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.58833dB 

02/28/2024 04:25:38 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:25:43 - INFO - __main__ -   MSE:0.00050x10^(-5),	SQNR:82.86100dB 

02/28/2024 04:25:43 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:25:48 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.03571dB 

02/28/2024 04:25:48 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:25:56 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80882dB 

02/28/2024 04:25:56 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:26:00 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79091dB 

02/28/2024 04:26:00 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:26:06 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77868dB 

02/28/2024 04:26:06 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:26:12 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80028dB 

02/28/2024 04:26:12 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:26:17 - INFO - __main__ -   MSE:0.00092x10^(-5),	SQNR:80.16216dB 

02/28/2024 04:26:17 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:26:22 - INFO - __main__ -   MSE:0.00079x10^(-5),	SQNR:80.83061dB 

02/28/2024 04:26:22 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:26:29 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.53363dB 

02/28/2024 04:26:29 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:26:34 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.49571dB 

02/28/2024 04:26:34 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:26:39 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.71944dB 

02/28/2024 04:26:39 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:26:43 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.17914dB 

02/28/2024 04:26:43 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:26:50 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77650dB 

02/28/2024 04:26:50 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:26:55 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79694dB 

02/28/2024 04:26:55 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:27:01 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76450dB 

02/28/2024 04:27:01 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:27:07 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76161dB 

02/28/2024 04:27:07 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:27:12 - INFO - __main__ -   MSE:0.00089x10^(-5),	SQNR:80.31215dB 

02/28/2024 04:27:12 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:27:18 - INFO - __main__ -   MSE:0.00076x10^(-5),	SQNR:81.03296dB 

02/28/2024 04:27:18 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:27:23 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.61176dB 

02/28/2024 04:27:24 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:27:30 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.61317dB 

02/28/2024 04:27:30 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:27:35 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.00360dB 

02/28/2024 04:27:35 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:27:40 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.20918dB 

02/28/2024 04:27:40 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:27:46 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79859dB 

02/28/2024 04:27:46 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:27:51 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78394dB 

02/28/2024 04:27:51 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:27:57 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75160dB 

02/28/2024 04:27:57 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:28:01 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77810dB 

02/28/2024 04:28:01 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:28:08 - INFO - __main__ -   MSE:0.00099x10^(-5),	SQNR:79.83960dB 

02/28/2024 04:28:08 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:28:14 - INFO - __main__ -   MSE:0.00072x10^(-5),	SQNR:81.25500dB 

02/28/2024 04:28:14 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:28:19 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.51459dB 

02/28/2024 04:28:19 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:28:26 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.55316dB 

02/28/2024 04:28:26 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:28:31 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.02934dB 

02/28/2024 04:28:31 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:28:35 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.24800dB 

02/28/2024 04:28:35 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:28:40 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.81607dB 

02/28/2024 04:28:40 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:28:46 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79553dB 

02/28/2024 04:28:46 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:28:52 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77576dB 

02/28/2024 04:28:52 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:28:56 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80787dB 

02/28/2024 04:28:56 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:29:02 - INFO - __main__ -   MSE:0.00095x10^(-5),	SQNR:80.02824dB 

02/28/2024 04:29:02 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:29:09 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.44373dB 

02/28/2024 04:29:09 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:29:14 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.73819dB 

02/28/2024 04:29:14 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:29:21 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.73235dB 

02/28/2024 04:29:21 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:29:27 - INFO - __main__ -   MSE:0.00045x10^(-5),	SQNR:83.24187dB 

02/28/2024 04:29:27 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:29:32 - INFO - __main__ -   MSE:0.00043x10^(-5),	SQNR:83.50757dB 

02/28/2024 04:29:32 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:29:39 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79794dB 

02/28/2024 04:29:39 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:29:45 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80589dB 

02/28/2024 04:29:45 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:29:52 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78589dB 

02/28/2024 04:29:52 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:29:57 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78596dB 

02/28/2024 04:29:57 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:30:03 - INFO - __main__ -   MSE:0.00089x10^(-5),	SQNR:80.32388dB 

02/28/2024 04:30:03 - INFO - __main__ -   model.up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:30:10 - INFO - __main__ -   MSE:0.00073x10^(-5),	SQNR:81.16760dB 

02/28/2024 04:30:10 - INFO - __main__ -   model.up_blocks.0.attentions.2.proj_out: weight_quant=True, act_quant=False
02/28/2024 04:30:16 - INFO - __main__ -   MSE:0.00187x10^(-5),	SQNR:77.08897dB 

02/28/2024 04:30:16 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 04:30:22 - INFO - __main__ -   MSE:0.00516x10^(-5),	SQNR:72.69969dB 

02/28/2024 04:30:22 - INFO - __main__ -   model.up_blocks.0.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:30:30 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.08113dB 

02/28/2024 04:30:30 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 04:30:36 - INFO - __main__ -   MSE:0.00346x10^(-5),	SQNR:74.51437dB 

02/28/2024 04:30:36 - INFO - __main__ -   model.up_blocks.0.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:30:41 - INFO - __main__ -   MSE:0.00691x10^(-5),	SQNR:71.44139dB 

02/28/2024 04:30:41 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 04:30:49 - INFO - __main__ -   MSE:0.00311x10^(-5),	SQNR:74.90648dB 

02/28/2024 04:30:50 - INFO - __main__ -   model.up_blocks.0.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:30:56 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.15291dB 

02/28/2024 04:30:56 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 04:31:01 - INFO - __main__ -   MSE:0.00200x10^(-5),	SQNR:76.80238dB 

02/28/2024 04:31:01 - INFO - __main__ -   model.up_blocks.0.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:31:09 - INFO - __main__ -   MSE:0.00491x10^(-5),	SQNR:72.93605dB 

02/28/2024 04:31:09 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 04:31:14 - INFO - __main__ -   MSE:0.00193x10^(-5),	SQNR:76.99603dB 

02/28/2024 04:31:14 - INFO - __main__ -   model.up_blocks.0.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:31:21 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.06816dB 

02/28/2024 04:31:21 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 04:31:28 - INFO - __main__ -   MSE:0.00131x10^(-5),	SQNR:78.66897dB 

02/28/2024 04:31:28 - INFO - __main__ -   model.up_blocks.0.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:31:33 - INFO - __main__ -   MSE:0.00519x10^(-5),	SQNR:72.68110dB 

02/28/2024 04:31:33 - INFO - __main__ -   model.up_blocks.0.upsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 04:31:39 - INFO - __main__ -   MSE:0.00685x10^(-5),	SQNR:71.45459dB 

02/28/2024 04:31:39 - INFO - __main__ -   model.up_blocks.1.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 04:31:45 - INFO - __main__ -   MSE:0.00285x10^(-5),	SQNR:75.26203dB 

02/28/2024 04:31:45 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:31:50 - INFO - __main__ -   MSE:0.00064x10^(-5),	SQNR:81.72104dB 

02/28/2024 04:31:50 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:31:56 - INFO - __main__ -   MSE:0.00064x10^(-5),	SQNR:81.70877dB 

02/28/2024 04:31:56 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:32:01 - INFO - __main__ -   MSE:0.00162x10^(-5),	SQNR:77.70511dB 

02/28/2024 04:32:01 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:32:06 - INFO - __main__ -   MSE:0.00183x10^(-5),	SQNR:77.19150dB 

02/28/2024 04:32:06 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:32:13 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71214dB 

02/28/2024 04:32:13 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:32:18 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77507dB 

02/28/2024 04:32:18 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:32:24 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71257dB 

02/28/2024 04:32:24 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:32:30 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65569dB 

02/28/2024 04:32:30 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:32:35 - INFO - __main__ -   MSE:0.00155x10^(-5),	SQNR:77.90351dB 

02/28/2024 04:32:35 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:32:39 - INFO - __main__ -   MSE:0.00155x10^(-5),	SQNR:77.90396dB 

02/28/2024 04:32:39 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:32:47 - INFO - __main__ -   MSE:0.00063x10^(-5),	SQNR:81.83485dB 

02/28/2024 04:32:47 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:32:52 - INFO - __main__ -   MSE:0.00065x10^(-5),	SQNR:81.66321dB 

02/28/2024 04:32:52 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:32:56 - INFO - __main__ -   MSE:0.00141x10^(-5),	SQNR:78.32043dB 

02/28/2024 04:32:56 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:33:02 - INFO - __main__ -   MSE:0.00125x10^(-5),	SQNR:78.83195dB 

02/28/2024 04:33:02 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:33:08 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.72841dB 

02/28/2024 04:33:08 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:33:13 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77083dB 

02/28/2024 04:33:13 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:33:18 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.72356dB 

02/28/2024 04:33:18 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:33:25 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.70364dB 

02/28/2024 04:33:25 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:33:30 - INFO - __main__ -   MSE:0.00144x10^(-5),	SQNR:78.23195dB 

02/28/2024 04:33:30 - INFO - __main__ -   model.up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:33:36 - INFO - __main__ -   MSE:0.00089x10^(-5),	SQNR:80.32666dB 

02/28/2024 04:33:36 - INFO - __main__ -   model.up_blocks.1.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 04:33:43 - INFO - __main__ -   MSE:0.00101x10^(-5),	SQNR:79.75096dB 

02/28/2024 04:33:43 - INFO - __main__ -   model.up_blocks.1.attentions.1.proj_in: weight_quant=True, act_quant=False
02/28/2024 04:33:49 - INFO - __main__ -   MSE:0.00188x10^(-5),	SQNR:77.07632dB 

02/28/2024 04:33:49 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:33:56 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.90263dB 

02/28/2024 04:33:56 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:34:01 - INFO - __main__ -   MSE:0.00047x10^(-5),	SQNR:83.04398dB 

02/28/2024 04:34:02 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:34:08 - INFO - __main__ -   MSE:0.00090x10^(-5),	SQNR:80.24065dB 

02/28/2024 04:34:08 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:34:13 - INFO - __main__ -   MSE:0.00096x10^(-5),	SQNR:79.98213dB 

02/28/2024 04:34:13 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:34:17 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65852dB 

02/28/2024 04:34:17 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:34:24 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78521dB 

02/28/2024 04:34:24 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:34:30 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.77116dB 

02/28/2024 04:34:30 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:34:34 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65005dB 

02/28/2024 04:34:34 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:34:39 - INFO - __main__ -   MSE:0.00114x10^(-5),	SQNR:79.23156dB 

02/28/2024 04:34:39 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:34:47 - INFO - __main__ -   MSE:0.00100x10^(-5),	SQNR:79.82702dB 

02/28/2024 04:34:47 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:34:52 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.15234dB 

02/28/2024 04:34:52 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:34:56 - INFO - __main__ -   MSE:0.00046x10^(-5),	SQNR:83.17171dB 

02/28/2024 04:34:56 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:35:02 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.08506dB 

02/28/2024 04:35:02 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:35:07 - INFO - __main__ -   MSE:0.00074x10^(-5),	SQNR:81.11830dB 

02/28/2024 04:35:07 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:35:12 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65997dB 

02/28/2024 04:35:12 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:35:20 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78410dB 

02/28/2024 04:35:20 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:35:26 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.72437dB 

02/28/2024 04:35:26 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:35:30 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.70151dB 

02/28/2024 04:35:30 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:35:37 - INFO - __main__ -   MSE:0.00115x10^(-5),	SQNR:79.18621dB 

02/28/2024 04:35:37 - INFO - __main__ -   model.up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:35:43 - INFO - __main__ -   MSE:0.00071x10^(-5),	SQNR:81.31161dB 

02/28/2024 04:35:43 - INFO - __main__ -   model.up_blocks.1.attentions.1.proj_out: weight_quant=True, act_quant=False
02/28/2024 04:35:50 - INFO - __main__ -   MSE:0.00094x10^(-5),	SQNR:80.05610dB 

02/28/2024 04:35:50 - INFO - __main__ -   model.up_blocks.1.attentions.2.proj_in: weight_quant=True, act_quant=False
02/28/2024 04:35:55 - INFO - __main__ -   MSE:0.00162x10^(-5),	SQNR:77.71655dB 

02/28/2024 04:35:55 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:36:01 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.54980dB 

02/28/2024 04:36:01 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:36:06 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.60670dB 

02/28/2024 04:36:06 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:36:12 - INFO - __main__ -   MSE:0.00079x10^(-5),	SQNR:80.80724dB 

02/28/2024 04:36:12 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:36:16 - INFO - __main__ -   MSE:0.00074x10^(-5),	SQNR:81.12602dB 

02/28/2024 04:36:16 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:36:23 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.73244dB 

02/28/2024 04:36:23 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:36:28 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78018dB 

02/28/2024 04:36:28 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:36:33 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71723dB 

02/28/2024 04:36:33 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:36:37 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.68456dB 

02/28/2024 04:36:37 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:36:45 - INFO - __main__ -   MSE:0.00115x10^(-5),	SQNR:79.19817dB 

02/28/2024 04:36:45 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:36:50 - INFO - __main__ -   MSE:0.00080x10^(-5),	SQNR:80.77132dB 

02/28/2024 04:36:50 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:36:55 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.55856dB 

02/28/2024 04:36:55 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:37:02 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.64511dB 

02/28/2024 04:37:02 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:37:07 - INFO - __main__ -   MSE:0.00082x10^(-5),	SQNR:80.64980dB 

02/28/2024 04:37:07 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:37:11 - INFO - __main__ -   MSE:0.00060x10^(-5),	SQNR:82.01524dB 

02/28/2024 04:37:11 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:37:18 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.70879dB 

02/28/2024 04:37:18 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:37:24 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76907dB 

02/28/2024 04:37:24 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:37:29 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65164dB 

02/28/2024 04:37:29 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:37:35 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65972dB 

02/28/2024 04:37:35 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:37:41 - INFO - __main__ -   MSE:0.00082x10^(-5),	SQNR:80.66248dB 

02/28/2024 04:37:41 - INFO - __main__ -   model.up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:37:47 - INFO - __main__ -   MSE:0.00065x10^(-5),	SQNR:81.66452dB 

02/28/2024 04:37:47 - INFO - __main__ -   model.up_blocks.1.attentions.2.proj_out: weight_quant=True, act_quant=False
02/28/2024 04:37:53 - INFO - __main__ -   MSE:0.00130x10^(-5),	SQNR:78.64926dB 

02/28/2024 04:37:53 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 04:37:58 - INFO - __main__ -   MSE:0.00821x10^(-5),	SQNR:70.67686dB 

02/28/2024 04:37:58 - INFO - __main__ -   model.up_blocks.1.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:38:06 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.02007dB 

02/28/2024 04:38:06 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 04:38:12 - INFO - __main__ -   MSE:0.00338x10^(-5),	SQNR:74.51868dB 

02/28/2024 04:38:12 - INFO - __main__ -   model.up_blocks.1.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:38:18 - INFO - __main__ -   MSE:0.00473x10^(-5),	SQNR:73.06907dB 

02/28/2024 04:38:18 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 04:38:25 - INFO - __main__ -   MSE:0.00322x10^(-5),	SQNR:74.74130dB 

02/28/2024 04:38:25 - INFO - __main__ -   model.up_blocks.1.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:38:29 - INFO - __main__ -   MSE:0.00056x10^(-5),	SQNR:82.29601dB 

02/28/2024 04:38:29 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 04:38:34 - INFO - __main__ -   MSE:0.00240x10^(-5),	SQNR:76.00179dB 

02/28/2024 04:38:34 - INFO - __main__ -   model.up_blocks.1.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:38:42 - INFO - __main__ -   MSE:0.00260x10^(-5),	SQNR:75.66476dB 

02/28/2024 04:38:42 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 04:38:47 - INFO - __main__ -   MSE:0.00157x10^(-5),	SQNR:77.84599dB 

02/28/2024 04:38:47 - INFO - __main__ -   model.up_blocks.1.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:38:52 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.63913dB 

02/28/2024 04:38:52 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 04:38:59 - INFO - __main__ -   MSE:0.00177x10^(-5),	SQNR:77.32745dB 

02/28/2024 04:38:59 - INFO - __main__ -   model.up_blocks.1.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:39:04 - INFO - __main__ -   MSE:0.00216x10^(-5),	SQNR:76.46204dB 

02/28/2024 04:39:04 - INFO - __main__ -   model.up_blocks.1.upsamplers.0.conv: weight_quant=True, act_quant=False
02/28/2024 04:39:09 - INFO - __main__ -   MSE:0.00324x10^(-5),	SQNR:74.70079dB 

02/28/2024 04:39:09 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 04:39:16 - INFO - __main__ -   MSE:0.00983x10^(-5),	SQNR:69.87978dB 

02/28/2024 04:39:16 - INFO - __main__ -   model.up_blocks.2.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:39:22 - INFO - __main__ -   MSE:0.00054x10^(-5),	SQNR:82.47806dB 

02/28/2024 04:39:22 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 04:39:28 - INFO - __main__ -   MSE:0.01086x10^(-5),	SQNR:69.44966dB 

02/28/2024 04:39:28 - INFO - __main__ -   model.up_blocks.2.resnets.0.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:39:34 - INFO - __main__ -   MSE:0.00548x10^(-5),	SQNR:72.41797dB 

02/28/2024 04:39:34 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 04:39:40 - INFO - __main__ -   MSE:0.00924x10^(-5),	SQNR:70.14819dB 

02/28/2024 04:39:40 - INFO - __main__ -   model.up_blocks.2.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:39:46 - INFO - __main__ -   MSE:0.00061x10^(-5),	SQNR:81.95031dB 

02/28/2024 04:39:46 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 04:39:51 - INFO - __main__ -   MSE:0.01645x10^(-5),	SQNR:67.64001dB 

02/28/2024 04:39:51 - INFO - __main__ -   model.up_blocks.2.resnets.1.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:39:57 - INFO - __main__ -   MSE:0.00937x10^(-5),	SQNR:70.08566dB 

02/28/2024 04:39:57 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv1: weight_quant=True, act_quant=False
02/28/2024 04:40:03 - INFO - __main__ -   MSE:0.05345x10^(-5),	SQNR:62.52612dB 

02/28/2024 04:40:03 - INFO - __main__ -   model.up_blocks.2.resnets.2.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:40:09 - INFO - __main__ -   MSE:0.00074x10^(-5),	SQNR:81.08215dB 

02/28/2024 04:40:09 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv2: weight_quant=True, act_quant=False
02/28/2024 04:40:18 - INFO - __main__ -   MSE:0.05486x10^(-5),	SQNR:62.40996dB 

02/28/2024 04:40:18 - INFO - __main__ -   model.up_blocks.2.resnets.2.conv_shortcut: weight_quant=True, act_quant=False
02/28/2024 04:40:25 - INFO - __main__ -   MSE:0.00964x10^(-5),	SQNR:69.96371dB 

02/28/2024 04:40:25 - INFO - __main__ -   model.mid_block.attentions.0.proj_in: weight_quant=True, act_quant=False
02/28/2024 04:40:30 - INFO - __main__ -   MSE:0.01960x10^(-5),	SQNR:67.48898dB 

02/28/2024 04:40:30 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:40:37 - INFO - __main__ -   MSE:0.00081x10^(-5),	SQNR:80.77496dB 

02/28/2024 04:40:37 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:40:43 - INFO - __main__ -   MSE:0.00126x10^(-5),	SQNR:79.46247dB 

02/28/2024 04:40:43 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:40:48 - INFO - __main__ -   MSE:0.00183x10^(-5),	SQNR:77.22320dB 

02/28/2024 04:40:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:40:53 - INFO - __main__ -   MSE:0.00396x10^(-5),	SQNR:74.10149dB 

02/28/2024 04:40:53 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:40:59 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71791dB 

02/28/2024 04:41:00 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:41:05 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.64544dB 

02/28/2024 04:41:05 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:41:10 - INFO - __main__ -   MSE:0.00052x10^(-5),	SQNR:82.69761dB 

02/28/2024 04:41:10 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:41:17 - INFO - __main__ -   MSE:0.00051x10^(-5),	SQNR:82.76203dB 

02/28/2024 04:41:17 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:41:22 - INFO - __main__ -   MSE:0.00380x10^(-5),	SQNR:74.02190dB 

02/28/2024 04:41:22 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.0.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:41:27 - INFO - __main__ -   MSE:0.00452x10^(-5),	SQNR:73.49133dB 

02/28/2024 04:41:27 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:41:34 - INFO - __main__ -   MSE:0.00125x10^(-5),	SQNR:78.92740dB 

02/28/2024 04:41:34 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:41:41 - INFO - __main__ -   MSE:0.00106x10^(-5),	SQNR:79.65802dB 

02/28/2024 04:41:41 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:41:46 - INFO - __main__ -   MSE:0.00269x10^(-5),	SQNR:75.66830dB 

02/28/2024 04:41:46 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:41:52 - INFO - __main__ -   MSE:0.00275x10^(-5),	SQNR:75.78035dB 

02/28/2024 04:41:52 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:41:58 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.10175dB 

02/28/2024 04:41:58 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:42:03 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.74335dB 

02/28/2024 04:42:03 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:42:08 - INFO - __main__ -   MSE:0.00058x10^(-5),	SQNR:82.22513dB 

02/28/2024 04:42:08 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:42:14 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.67722dB 

02/28/2024 04:42:14 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:42:19 - INFO - __main__ -   MSE:0.00373x10^(-5),	SQNR:74.59380dB 

02/28/2024 04:42:19 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.1.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:42:25 - INFO - __main__ -   MSE:0.00258x10^(-5),	SQNR:76.04110dB 

02/28/2024 04:42:25 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:42:30 - INFO - __main__ -   MSE:0.00071x10^(-5),	SQNR:81.34331dB 

02/28/2024 04:42:30 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:42:36 - INFO - __main__ -   MSE:0.00081x10^(-5),	SQNR:80.79903dB 

02/28/2024 04:42:36 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:42:42 - INFO - __main__ -   MSE:0.00223x10^(-5),	SQNR:76.40372dB 

02/28/2024 04:42:42 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:42:47 - INFO - __main__ -   MSE:0.00216x10^(-5),	SQNR:76.59692dB 

02/28/2024 04:42:47 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:42:52 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.65910dB 

02/28/2024 04:42:52 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:42:59 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.85643dB 

02/28/2024 04:42:59 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:43:04 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:82.98096dB 

02/28/2024 04:43:04 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:43:08 - INFO - __main__ -   MSE:0.00048x10^(-5),	SQNR:83.05930dB 

02/28/2024 04:43:08 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:43:15 - INFO - __main__ -   MSE:0.00259x10^(-5),	SQNR:75.80529dB 

02/28/2024 04:43:15 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.2.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:43:20 - INFO - __main__ -   MSE:0.00251x10^(-5),	SQNR:75.86929dB 

02/28/2024 04:43:20 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:43:25 - INFO - __main__ -   MSE:0.00078x10^(-5),	SQNR:80.91447dB 

02/28/2024 04:43:25 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:43:32 - INFO - __main__ -   MSE:0.00098x10^(-5),	SQNR:80.29977dB 

02/28/2024 04:43:32 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:43:37 - INFO - __main__ -   MSE:0.00252x10^(-5),	SQNR:75.88701dB 

02/28/2024 04:43:38 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:43:42 - INFO - __main__ -   MSE:0.00180x10^(-5),	SQNR:77.39202dB 

02/28/2024 04:43:42 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:43:48 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75853dB 

02/28/2024 04:43:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:43:54 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.84741dB 

02/28/2024 04:43:54 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:43:59 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.64751dB 

02/28/2024 04:43:59 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:44:06 - INFO - __main__ -   MSE:0.00049x10^(-5),	SQNR:82.96502dB 

02/28/2024 04:44:06 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:44:12 - INFO - __main__ -   MSE:0.00333x10^(-5),	SQNR:74.83253dB 

02/28/2024 04:44:12 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.3.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:44:17 - INFO - __main__ -   MSE:0.00201x10^(-5),	SQNR:76.85246dB 

02/28/2024 04:44:17 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:44:23 - INFO - __main__ -   MSE:0.00100x10^(-5),	SQNR:79.91965dB 

02/28/2024 04:44:23 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:44:29 - INFO - __main__ -   MSE:0.00092x10^(-5),	SQNR:80.32785dB 

02/28/2024 04:44:29 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:44:35 - INFO - __main__ -   MSE:0.00219x10^(-5),	SQNR:76.62222dB 

02/28/2024 04:44:35 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:44:41 - INFO - __main__ -   MSE:0.00193x10^(-5),	SQNR:77.20409dB 

02/28/2024 04:44:41 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:44:46 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.83327dB 

02/28/2024 04:44:46 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:44:52 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.82007dB 

02/28/2024 04:44:52 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:44:58 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.63831dB 

02/28/2024 04:44:58 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:45:02 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.81965dB 

02/28/2024 04:45:02 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:45:07 - INFO - __main__ -   MSE:0.00241x10^(-5),	SQNR:76.03915dB 

02/28/2024 04:45:07 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.4.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:45:12 - INFO - __main__ -   MSE:0.00176x10^(-5),	SQNR:77.36676dB 

02/28/2024 04:45:12 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:45:18 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.66855dB 

02/28/2024 04:45:18 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:45:23 - INFO - __main__ -   MSE:0.00069x10^(-5),	SQNR:81.49784dB 

02/28/2024 04:45:23 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:45:28 - INFO - __main__ -   MSE:0.00127x10^(-5),	SQNR:78.82819dB 

02/28/2024 04:45:28 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:45:35 - INFO - __main__ -   MSE:0.00116x10^(-5),	SQNR:79.19135dB 

02/28/2024 04:45:35 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:45:39 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78024dB 

02/28/2024 04:45:39 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:45:45 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79369dB 

02/28/2024 04:45:45 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:45:51 - INFO - __main__ -   MSE:0.00042x10^(-5),	SQNR:83.61790dB 

02/28/2024 04:45:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:45:56 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.84620dB 

02/28/2024 04:45:56 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:46:01 - INFO - __main__ -   MSE:0.00281x10^(-5),	SQNR:75.46794dB 

02/28/2024 04:46:01 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.5.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:46:07 - INFO - __main__ -   MSE:0.00186x10^(-5),	SQNR:77.19714dB 

02/28/2024 04:46:07 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:46:14 - INFO - __main__ -   MSE:0.00059x10^(-5),	SQNR:82.19121dB 

02/28/2024 04:46:14 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:46:19 - INFO - __main__ -   MSE:0.00053x10^(-5),	SQNR:82.57887dB 

02/28/2024 04:46:19 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:46:25 - INFO - __main__ -   MSE:0.00105x10^(-5),	SQNR:79.72513dB 

02/28/2024 04:46:25 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:46:30 - INFO - __main__ -   MSE:0.00081x10^(-5),	SQNR:80.78550dB 

02/28/2024 04:46:30 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:46:38 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79173dB 

02/28/2024 04:46:38 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:46:43 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.83649dB 

02/28/2024 04:46:43 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:46:49 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.73415dB 

02/28/2024 04:46:49 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:46:55 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75211dB 

02/28/2024 04:46:55 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:47:00 - INFO - __main__ -   MSE:0.00249x10^(-5),	SQNR:75.88437dB 

02/28/2024 04:47:00 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.6.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:47:05 - INFO - __main__ -   MSE:0.00144x10^(-5),	SQNR:78.28993dB 

02/28/2024 04:47:05 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:47:13 - INFO - __main__ -   MSE:0.00070x10^(-5),	SQNR:81.36085dB 

02/28/2024 04:47:13 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:47:19 - INFO - __main__ -   MSE:0.00065x10^(-5),	SQNR:81.70583dB 

02/28/2024 04:47:19 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:47:23 - INFO - __main__ -   MSE:0.00086x10^(-5),	SQNR:80.53165dB 

02/28/2024 04:47:23 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:47:29 - INFO - __main__ -   MSE:0.00083x10^(-5),	SQNR:80.68930dB 

02/28/2024 04:47:29 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:47:35 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79321dB 

02/28/2024 04:47:35 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:47:39 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.86999dB 

02/28/2024 04:47:39 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:47:45 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.74621dB 

02/28/2024 04:47:45 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:47:51 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79988dB 

02/28/2024 04:47:51 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:47:56 - INFO - __main__ -   MSE:0.00241x10^(-5),	SQNR:76.01302dB 

02/28/2024 04:47:56 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.7.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:48:02 - INFO - __main__ -   MSE:0.00116x10^(-5),	SQNR:79.17289dB 

02/28/2024 04:48:02 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:48:09 - INFO - __main__ -   MSE:0.00073x10^(-5),	SQNR:81.18916dB 

02/28/2024 04:48:09 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:48:14 - INFO - __main__ -   MSE:0.00063x10^(-5),	SQNR:81.86388dB 

02/28/2024 04:48:14 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:48:21 - INFO - __main__ -   MSE:0.00097x10^(-5),	SQNR:80.05871dB 

02/28/2024 04:48:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:48:25 - INFO - __main__ -   MSE:0.00082x10^(-5),	SQNR:80.64650dB 

02/28/2024 04:48:25 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:48:32 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.76253dB 

02/28/2024 04:48:32 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:48:37 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.79918dB 

02/28/2024 04:48:37 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:48:43 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.80587dB 

02/28/2024 04:48:43 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:48:48 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.70881dB 

02/28/2024 04:48:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:48:53 - INFO - __main__ -   MSE:0.00185x10^(-5),	SQNR:77.20264dB 

02/28/2024 04:48:53 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.8.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:48:59 - INFO - __main__ -   MSE:0.00100x10^(-5),	SQNR:79.93683dB 

02/28/2024 04:48:59 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_q: weight_quant=True, act_quant=False
02/28/2024 04:49:04 - INFO - __main__ -   MSE:0.00066x10^(-5),	SQNR:81.59564dB 

02/28/2024 04:49:04 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_k: weight_quant=True, act_quant=False
02/28/2024 04:49:12 - INFO - __main__ -   MSE:0.00067x10^(-5),	SQNR:81.59621dB 

02/28/2024 04:49:12 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_v: weight_quant=True, act_quant=False
02/28/2024 04:49:17 - INFO - __main__ -   MSE:0.00085x10^(-5),	SQNR:80.58254dB 

02/28/2024 04:49:17 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:49:21 - INFO - __main__ -   MSE:0.00054x10^(-5),	SQNR:82.50882dB 

02/28/2024 04:49:21 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_q: weight_quant=True, act_quant=False
02/28/2024 04:49:28 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.78467dB 

02/28/2024 04:49:28 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_k: weight_quant=True, act_quant=False
02/28/2024 04:49:33 - INFO - __main__ -   MSE:0.00041x10^(-5),	SQNR:83.71877dB 

02/28/2024 04:49:33 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_v: weight_quant=True, act_quant=False
02/28/2024 04:49:37 - INFO - __main__ -   MSE:0.00039x10^(-5),	SQNR:83.90937dB 

02/28/2024 04:49:37 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0: weight_quant=True, act_quant=False
02/28/2024 04:49:42 - INFO - __main__ -   MSE:0.00040x10^(-5),	SQNR:83.75807dB 

02/28/2024 04:49:42 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj: weight_quant=True, act_quant=False
02/28/2024 04:49:48 - INFO - __main__ -   MSE:0.00192x10^(-5),	SQNR:77.00128dB 

02/28/2024 04:49:48 - INFO - __main__ -   model.mid_block.attentions.0.transformer_blocks.9.ff.net.2: weight_quant=True, act_quant=False
02/28/2024 04:49:54 - INFO - __main__ -   MSE:0.00082x10^(-5),	SQNR:80.69143dB 

02/28/2024 04:49:54 - INFO - __main__ -   model.mid_block.attentions.0.proj_out: weight_quant=True, act_quant=False
02/28/2024 04:49:59 - INFO - __main__ -   MSE:0.00344x10^(-5),	SQNR:74.48259dB 

02/28/2024 04:49:59 - INFO - __main__ -   model.mid_block.resnets.0.conv1: weight_quant=True, act_quant=False
02/28/2024 04:50:06 - INFO - __main__ -   MSE:0.00631x10^(-5),	SQNR:71.94920dB 

02/28/2024 04:50:06 - INFO - __main__ -   model.mid_block.resnets.0.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:50:11 - INFO - __main__ -   MSE:0.00127x10^(-5),	SQNR:78.89563dB 

02/28/2024 04:50:11 - INFO - __main__ -   model.mid_block.resnets.0.conv2: weight_quant=True, act_quant=False
02/28/2024 04:50:16 - INFO - __main__ -   MSE:0.00375x10^(-5),	SQNR:74.06923dB 

02/28/2024 04:50:16 - INFO - __main__ -   model.mid_block.resnets.1.conv1: weight_quant=True, act_quant=False
02/28/2024 04:50:23 - INFO - __main__ -   MSE:0.00488x10^(-5),	SQNR:73.14192dB 

02/28/2024 04:50:23 - INFO - __main__ -   model.mid_block.resnets.1.time_emb_proj: weight_quant=True, act_quant=False
02/28/2024 04:50:30 - INFO - __main__ -   MSE:0.00082x10^(-5),	SQNR:80.64655dB 

02/28/2024 04:50:30 - INFO - __main__ -   model.mid_block.resnets.1.conv2: weight_quant=True, act_quant=False
02/28/2024 04:50:36 - INFO - __main__ -   MSE:0.00235x10^(-5),	SQNR:76.19051dB 

02/28/2024 04:50:36 - INFO - __main__ -   model.conv_out: weight_quant=True, act_quant=False
02/28/2024 04:50:42 - INFO - __main__ -   MSE:0.92882x10^(-5),	SQNR:50.12276dB 

